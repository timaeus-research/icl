{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small-model report\n",
    "\n",
    "On the small model (L=2, H=4):\n",
    "\n",
    "- Replication of RaventÃ³s et al. (2023) + fitting the various algorithms\n",
    "- All the analyses (RLCT, PCA, Attention Entropies, Covariance, Weight-staring). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "if not \"AWS_ACCESS_KEY_ID\" in os.environ or not \"AWS_SECRET_ACCESS_KEY\" in os.environ:\n",
    "    raise Exception(\"AWS_ACCESS_KEY_ID or AWS_SECRET_ACCESS_KEY not found in environment variables. Please set them in .env file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pp\n",
    "from pathlib import Path\n",
    "from typing import Optional, Iterable, List, Tuple, Dict, Union, Callable\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch \n",
    "from torch import nn\n",
    "\n",
    "import devinterp\n",
    "import devinfra\n",
    "\n",
    "from icl.analysis.utils import get_unique_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "SWEEP_ID = \"6g954fkg\"\n",
    "SWEEP_FILENAME = \"small-sweep-2.yaml\"\n",
    "FIGURES=Path(\"../figures\")\n",
    "ANALYSIS = Path(\"../analysis\")\n",
    "\n",
    "DEVICE = devinfra.utils.device.get_default_device()\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from icl.analysis.utils import get_sweep_configs\n",
    "\n",
    "filters = {\"task_config\": {\"num_layers\": 2, \"num_heads\": 4}, \"optimizer_config\": {\"lr\": 0.01}}  # TODO: Where are the H=2 runs?\n",
    "configs = list(get_sweep_configs(f\"../sweeps/{SWEEP_FILENAME}\", **filters))\n",
    "\n",
    "print(f\"Found {len(configs)} runs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure out which checkpoints are available\n",
    "\n",
    "checkpointers = [config.checkpointer_config.factory() for config in tqdm(configs, desc=\"Reading checkpoints\")]\n",
    "\n",
    "for checkpointer in tqdm(checkpointers, desc=\"Loading checkpoints\"):\n",
    "    print(f\"Found {len(checkpointer.file_ids)} checkpoints for {checkpointer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replication "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from devinfra.utils.iterables import filter_objs\n",
    "\n",
    "api= wandb.Api()\n",
    "sweep = api.sweep(f\"devinterp/icl/{SWEEP_ID}\")\n",
    "runs = list(filter_objs([r for r in sweep.runs], config=filters))\n",
    "\n",
    "print(f\"Found {len(runs)} runs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from devinfra.utils.iterables import flatten_dict\n",
    "from icl.analysis.utils import wandb_runs_to_df\n",
    "\n",
    "df = wandb_runs_to_df(runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp(list(df.columns))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recreate_fig_2(df, title=\"\"):\n",
    "    # Create a 2x3 grid of subplots\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "    # Set title\n",
    "\n",
    "    # Set common labels\n",
    "    fig.text(0.08, 0.5, r'$\\mathcal{T}_\\mathrm{Pretrain}$', va='center', rotation='vertical', fontsize=14)\n",
    "    fig.text(0.08, 0.26, r'$\\mathcal{T}_\\mathrm{True}$', va='center', rotation='vertical', fontsize=14)\n",
    "\n",
    "    grouped_by_num_tasks = df.groupby('task_config/num_tasks')\n",
    "\n",
    "    # Within each group, find the row with the last step\n",
    "    last_rows = grouped_by_num_tasks.apply(lambda g: g[g._step == g._step.max() & g[\"pretrain/mse\"].notna()])\n",
    "\n",
    "    # Ungroup\n",
    "    last_rows = last_rows.reset_index(drop=True)\n",
    "    print(last_rows)\n",
    "\n",
    "    # Top row\n",
    "    sns.lineplot(x='task_config/num_tasks', y='pretrain/mse', data=last_rows, ax=axs[0, 0], hue='_step')\n",
    "    sns.lineplot(x='task_config/num_tasks', y='pretrain/delta_dmmse', data=last_rows, ax=axs[0, 1], hue='_step')\n",
    "    sns.lineplot(x='task_config/num_tasks', y='pretrain/delta_ridge', data=last_rows, ax=axs[0, 2], hue='_step')\n",
    "\n",
    "    # Bottom row\n",
    "    sns.lineplot(x='task_config/num_tasks', y='true/mse', data=last_rows, ax=axs[1, 0], hue='_step')\n",
    "    sns.lineplot(x='task_config/num_tasks', y='true/delta_dmmse', data=last_rows, ax=axs[1, 1], hue='_step')\n",
    "    sns.lineplot(x='task_config/num_tasks', y='true/delta_ridge', data=last_rows, ax=axs[1, 2], hue='_step')\n",
    "\n",
    "    # Y-labels for first column\n",
    "    axs[0, 0].set_ylabel('MSE')\n",
    "    axs[1, 0].set_ylabel('MSE')\n",
    "\n",
    "    # Y-labels for second column\n",
    "    axs[0, 1].set_ylabel(r'$\\Delta_\\mathrm{PT dMMSE}$')\n",
    "    axs[1, 1].set_ylabel(r'$\\Delta_\\mathrm{PT dMMSE}$')\n",
    "\n",
    "    # Y-labels for third column\n",
    "    axs[0, 2].set_ylabel(r'$\\Delta_\\mathrm{PT Ridge}$')\n",
    "    axs[1, 2].set_ylabel(r'$\\Delta_\\mathrm{PT Ridge}$')\n",
    "\n",
    "    for i in range(3):\n",
    "        axs[1, i].set_xlabel(\"# Pretraining Tasks\")\n",
    "\n",
    "    for ax in axs.flat:\n",
    "        ax.set_xscale(\"log\")\n",
    "\n",
    "    # Hide x-labels for the top row\n",
    "    for ax in axs[0, :]:\n",
    "        ax.set_xlabel('')\n",
    "\n",
    "    plt.tight_layout(rect=[0.1, 0.1, 1, 1])\n",
    "    plt.show()\n",
    "\n",
    "def recreate_fig_2_over_time(df, title=\"\"):\n",
    "    # Create a 2x3 grid of subplots\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "    # Set title\n",
    "    plt.suptitle(title)\n",
    "\n",
    "    # Set common labels\n",
    "    fig.text(0.08, 0.5, r'$\\mathcal{T}_\\mathrm{Pretrain}$', va='center', rotation='vertical', fontsize=14)\n",
    "    fig.text(0.08, 0.26, r'$\\mathcal{T}_\\mathrm{True}$', va='center', rotation='vertical', fontsize=14)\n",
    "\n",
    "    cmap = sns.color_palette(\"viridis\", as_cmap=True)\n",
    "\n",
    "    # Top row\n",
    "    sns.scatterplot(x='task_config/num_tasks', y='pretrain/mse', data=df, ax=axs[0, 0], hue='_step', palette=cmap)\n",
    "    sns.scatterplot(x='task_config/num_tasks', y='pretrain/delta_dmmse', data=df, ax=axs[0, 1], hue='_step', palette=cmap)\n",
    "    sns.scatterplot(x='task_config/num_tasks', y='pretrain/delta_ridge', data=df, ax=axs[0, 2], hue='_step', palette=cmap)\n",
    "\n",
    "    # Bottom row\n",
    "    sns.scatterplot(x='task_config/num_tasks', y='true/mse', data=df, ax=axs[1, 0], hue='_step', palette=cmap)\n",
    "    sns.scatterplot(x='task_config/num_tasks', y='true/delta_dmmse', data=df, ax=axs[1, 1], hue='_step', palette=cmap)\n",
    "    sns.scatterplot(x='task_config/num_tasks', y='true/delta_ridge', data=df, ax=axs[1, 2], hue='_step', palette=cmap)\n",
    "\n",
    "    # Y-labels for first column\n",
    "    axs[0, 0].set_ylabel('MSE')\n",
    "    axs[1, 0].set_ylabel('MSE')\n",
    "\n",
    "    # Y-labels for second column\n",
    "    axs[0, 1].set_ylabel(r'$\\Delta_\\mathrm{PT dMMSE}$')\n",
    "    axs[1, 1].set_ylabel(r'$\\Delta_\\mathrm{PT dMMSE}$')\n",
    "\n",
    "    # Y-labels for third column\n",
    "    axs[0, 2].set_ylabel(r'$\\Delta_\\mathrm{PT Ridge}$')\n",
    "    axs[1, 2].set_ylabel(r'$\\Delta_\\mathrm{PT Ridge}$')\n",
    "\n",
    "    for i in range(3):\n",
    "        axs[1, i].set_xlabel(\"# Pretraining Tasks\")\n",
    "\n",
    "    for ax in axs.flat:\n",
    "        ax.set_xscale(\"log\")\n",
    "\n",
    "    # Hide x-labels for the top row\n",
    "    for ax in axs[0, :]:\n",
    "        ax.set_xlabel('')\n",
    "\n",
    "    plt.tight_layout(rect=[0.1, 0.1, 1, 1])\n",
    "    plt.show()\n",
    "\n",
    "# TODO: Add baselines (also make comparisons for other hyperparameters besides batch_size). \n",
    "# recreate_fig_2_over_time(df, title=\"Over training\")\n",
    "# recreate_fig_2(df, title=\"At the end\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raise NotImplementedError(\"TODO: Fit noise terms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_enumerated_models(model, checkpointer, verbose=False):\n",
    "    for file_id in tqdm(checkpointer.file_ids, desc=\"Iterating over checkpoints\", disable=not verbose):\n",
    "        model.load_state_dict(checkpointer.load_file(file_id)[\"model\"])\n",
    "        yield file_id, model\n",
    "\n",
    "def iter_models(model, checkpointer, verbose=False):\n",
    "    for file_id in tqdm(checkpointer.file_ids, desc=\"Iterating over checkpoints\", disable=not verbose):\n",
    "        model.load_state_dict(checkpointer.load_file(file_id)[\"model\"])\n",
    "        yield model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Iterable, Tuple\n",
    "from sklearn.decomposition import PCA\n",
    "from collections import defaultdict\n",
    "from devinterp.mechinterp.hooks import hook\n",
    "import numpy as np\n",
    "from icl.analysis.utils import map_evals_over_checkpoints, get_unique_run\n",
    "from icl.train import Run\n",
    "from devinfra.utils.tensors import convert_tensor, ReturnTensor\n",
    "\n",
    "\n",
    "def extract_activations_over_checkpoints(models: Iterable[nn.Module], xs, ys, *paths, return_type: ReturnTensor=\"np\"):\n",
    "    def eval_activations(model):\n",
    "        hooked_model = hook(model, *paths)\n",
    "        return {k: convert_tensor(v, return_type) for k, v in hooked_model.run_with_cache(xs, ys)[1].items() if k in paths and v is not None}\n",
    "    \n",
    "    for model in models:\n",
    "        yield eval_activations(model)\n",
    "\n",
    "\n",
    "def get_vectorized_activations_trace(models: Iterable[nn.Module], xs, ys, *paths):\n",
    "    evals: Dict[str, list] = defaultdict(list)\n",
    "    \n",
    "    for activations in extract_activations_over_checkpoints(models, xs, ys, *paths):\n",
    "        for path, activation in activations.items():\n",
    "            evals[path].append(activation)\n",
    "\n",
    "    return {\n",
    "        k: np.array(v).reshape(len(v), -1) for k, v in evals.items()\n",
    "    }\n",
    "\n",
    "\n",
    "def get_pca_activations_trace(models: Iterable[nn.Module], xs, ys, *paths, num_components=3) -> Dict[str, Tuple[PCA, np.ndarray]]:\n",
    "    results = {}\n",
    "\n",
    "    for path, activations in get_vectorized_activations_trace(models, xs, ys, *paths).items():\n",
    "        pca = PCA(n_components=num_components)\n",
    "        activations_reduced = pca.fit_transform(activations)\n",
    "        results[path] = pca, activations_reduced\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo = Run(configs[2])\n",
    "# demo_models = iter_models(demo.model, demo.checkpointer, verbose=True)\n",
    "\n",
    "# demo_logits_pca_3, demo_logits_reduced_3  = get_pca_activations_trace(\n",
    "#     demo_models, \n",
    "#     demo.evaluator.pretrain_xs, \n",
    "#     demo.evaluator.pretrain_ys, \n",
    "#     \"token_sequence_transformer\",\n",
    "#     num_components=3\n",
    "# )['token_sequence_transformer']\n",
    "\n",
    "# steps = demo.checkpointer.file_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "def plot_sample_evolution(steps, samples, title=\"Sample Evolution in 2D Plane\", num_points_to_label=10, save: Optional[str] = None, ax: Optional = None, connect_dots=False):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(15, 8))\n",
    "    \n",
    "    # Main plot\n",
    "    sc = ax.scatter(samples[:, 0], samples[:, 1], c=steps, cmap='viridis', s=50, alpha=0.6)\n",
    "\n",
    "    if connect_dots:\n",
    "        ax.plot(samples[:, 0], samples[:, 1], c='black', alpha=0.2)\n",
    "\n",
    "    plt.colorbar(sc, ax=ax, label='Steps')\n",
    "    \n",
    "    # Label some points\n",
    "    total_samples = len(samples)\n",
    "    step = total_samples // num_points_to_label\n",
    "    for i in range(0, total_samples, step):\n",
    "        sample_step = steps[i]\n",
    "        ax.text(samples[i, 0], samples[i, 1], str(sample_step), fontsize=12, ha='right', va='bottom')\n",
    "        \n",
    "    ax.set_xlabel('Feature 1')\n",
    "    ax.set_ylabel('Feature 2')\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    # Inset for explained variance at the bottom right corner with slight transparency\n",
    "    if save:\n",
    "        parent_dir = os.path.dirname(save)\n",
    "\n",
    "        if not os.path.exists(parent_dir):\n",
    "            os.makedirs(parent_dir)\n",
    "\n",
    "        plt.savefig(save)\n",
    "\n",
    "\n",
    "def plot_explained_variance(pca, title=\"Explained Variance\", ax: Optional[plt.Axes] = None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "    ax.bar(range(len(pca.explained_variance_ratio_)), pca.explained_variance_ratio_)\n",
    "\n",
    "    for i, ratio in enumerate(pca.explained_variance_ratio_):\n",
    "        ax.text(i, ratio, f\"{ratio:.2f}\", fontsize=12, ha='center', va='bottom')\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Component')\n",
    "    ax.set_ylabel('Variance')\n",
    "\n",
    "\n",
    "def plot_sample_evolution_with_inset(steps, samples, pca, title=\"Sample Evolution in 2D Plane\", num_points_to_label=10, save: Optional[str] = None, ax: Optional = None, connect_dots=False):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(15, 8))\n",
    "    \n",
    "    plot_sample_evolution(steps, samples, title=title, num_points_to_label=num_points_to_label, ax=ax, connect_dots=connect_dots)\n",
    "\n",
    "    axins = ax.inset_axes([0.7, 0.05, 0.25, 0.25])  # x, y, width, height\n",
    "    axins.patch.set_alpha(0.5)\n",
    "    plot_explained_variance(pca, ax=axins)\n",
    "    \n",
    "    # Inset for explained variance at the bottom right corner with slight transparency\n",
    "    if save:\n",
    "        parent_dir = os.path.dirname(save)\n",
    "\n",
    "        if not os.path.exists(parent_dir):\n",
    "            os.makedirs(parent_dir)\n",
    "\n",
    "        plt.savefig(save)\n",
    "\n",
    "    \n",
    "def plot_multiple_slices(steps, samples, pca, title=\"Sample Evolution in 2D Plane\", num_points_to_label=10, save: Optional[str] = None, ax: Optional = None, connect_dots=False):\n",
    "    num_pca_components = samples.shape[-1]\n",
    "    num_rows = num_pca_components - 1\n",
    "    fig, ax = plt.subplots(num_rows, num_rows, figsize=(20, 20))\n",
    "\n",
    "    fig.suptitle(title)\n",
    "\n",
    "    for i in range(num_pca_components):\n",
    "        for j in range(i):\n",
    "            sc = ax[i-1, j].scatter(samples[:, i], samples[:, j], c=steps, cmap='viridis', s=50, alpha=0.6)\n",
    "            ax[i-1, j].set_xlabel(f'Feature {i}')\n",
    "            ax[i-1, j].set_ylabel(f'Feature {j}')\n",
    "            ax[i-1, j].set_title(f'Feature {i} vs Feature {j}')\n",
    "\n",
    "            if connect_dots:\n",
    "                ax[i-1, j].plot(samples[:, i], samples[:, j], c='black', alpha=0.2)\n",
    "\n",
    "            # Label some points\n",
    "            total_samples = len(samples)\n",
    "            step = total_samples // num_points_to_label\n",
    "            for k in range(0, total_samples, step):\n",
    "                sample_step = steps[k]\n",
    "                ax[i-1, j].text(samples[k, i], samples[k, j], str(sample_step), fontsize=12, ha='right', va='bottom')\n",
    "\n",
    "        for j in range(i + 1, num_rows):\n",
    "            ax[i, j].axis('off')\n",
    "\n",
    "\n",
    "    ax[0, -1].axis('on')\n",
    "    plot_explained_variance(pca, ax=ax[0, -1])\n",
    "\n",
    "    plt.colorbar(sc, ax=ax[0, -1], label='Steps')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save:\n",
    "        parent_dir = os.path.dirname(save)\n",
    "\n",
    "        if not os.path.exists(parent_dir):\n",
    "            os.makedirs(parent_dir)\n",
    "\n",
    "        plt.savefig(save)\n",
    "\n",
    "# plot_multiple_slices(steps, demo_logits_reduced_3, demo_logits_pca_3, title=demo.config.to_latex(), connect_dots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for config, checkpointer in zip(configs, checkpointers):\n",
    "    run = Run(config)\n",
    "    _steps = checkpointer.file_ids\n",
    "\n",
    "    _pca, _logits_reduced = get_pca_activations_trace(\n",
    "        iter_models(run.model, run.checkpointer, verbose=True), \n",
    "        run.evaluator.pretrain_xs, \n",
    "        run.evaluator.pretrain_ys, \n",
    "        \"token_sequence_transformer\",\n",
    "        num_components=3\n",
    "    )['token_sequence_transformer']\n",
    "    \n",
    "    plot_multiple_slices(\n",
    "        _steps, \n",
    "        _logits_reduced, \n",
    "        _pca, \n",
    "        connect_dots=True, \n",
    "        title=config.to_latex(), \n",
    "        save=FIGURES / (\"pca3-logits-\" + config.to_slug(delimiter=\"-\") + \".png\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention Entropies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Union\n",
    "from torchtyping import TensorType\n",
    "from devinfra.utils.iterables import map_nested\n",
    "\n",
    "def compute_attention_entropies(attn: TensorType[\"B\", \"H\", \"2K\", \"2K\"]):\n",
    "    \"\"\"\n",
    "    Computes the entropy of each token in each head, averaged across the batch, \n",
    "    then averages this over heads. \n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # Threshold attention weights to avoid log(0)\n",
    "    log_attention = torch.where(attn > 0, torch.log(attn), torch.tensor(0.0).to(attn.device))\n",
    "    entropy_per_token = - torch.sum(attn * log_attention, dim=-1).mean(dim=0).squeeze(-1) # TensorType[\"H\", \"2K\"]\n",
    "\n",
    "    num_heads, num_tokens = entropy_per_token.shape\n",
    "\n",
    "    entropy_per_head = entropy_per_token.mean(dim=-1) # TensorType[\"H\"]\n",
    "    entropy = entropy_per_head.mean() # TensorType[]    \n",
    "    \n",
    "    # Each token computes entropy over a variable context length, so we normalize by the maximum possible entropy\n",
    "    # for a token with a fixed context length.\n",
    "\n",
    "    max_entropy_per_token = torch.log2(torch.arange(1, num_tokens + 1).to(attn.device)) # TensorType[\"H\", \"2K\"]\n",
    "    max_entropy_per_token[0] = 1. # Special case for the first token to avoid dividing by 0\n",
    "\n",
    "    entropy_per_token_normalized = entropy_per_token / max_entropy_per_token\n",
    "    entropy_per_head_normalized = entropy_per_token_normalized.mean(dim=-1) # TensorType[\"H\"]\n",
    "    entropy_normalized = entropy_per_head_normalized.mean() # TensorType[]    \n",
    "\n",
    "    results: Dict[str, Union[torch.Tensor, Dict[str, torch.Tensor]]] = {\"mean\": entropy, \"mean_normalized\": entropy_normalized}\n",
    "\n",
    "    for i in range(num_heads):\n",
    "        head_results = {\"mean\": entropy_per_head[i], \"mean_normalized\": entropy_per_head_normalized[i]}\n",
    "\n",
    "        for j in range(num_tokens):\n",
    "            head_results[f\"token_{j}\"] = entropy_per_token[i, j]\n",
    "            head_results[f\"token_{j}_normalized\"] = entropy_per_token_normalized[i, j]\n",
    "\n",
    "        results[f\"head_{i}\"] = head_results\n",
    "\n",
    "    return map_nested(lambda x: convert_tensor(x, \"np\"), results)\n",
    "\n",
    "\n",
    "def get_attention_entropies_trace(\n",
    "    steps: List[int],\n",
    "    models: Iterable[nn.Module],\n",
    "    xs: torch.Tensor,\n",
    "    ys: torch.Tensor,\n",
    "    **paths,\n",
    "):\n",
    "    results = defaultdict(list)\n",
    "    reverse_paths = {v: k for k, v in paths.items()}\n",
    "\n",
    "    for activations in extract_activations_over_checkpoints(models, xs, ys, *paths.values(), return_type=\"pt\"):\n",
    "        for k, v in activations.items():\n",
    "            path = reverse_paths[k]\n",
    "            results[path].append(compute_attention_entropies(v))\n",
    "\n",
    "    values = []\n",
    "\n",
    "    for i in range(len(steps)):\n",
    "        value = {}\n",
    "\n",
    "        for block in results.keys():\n",
    "            value[block] = results[block][i]\n",
    "        \n",
    "        value[\"step\"] = steps[i]\n",
    "        values.append(flatten_dict(value, flatten_lists=True))\n",
    "\n",
    "    return pd.DataFrame(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention_patterns(df: pd.DataFrame, num_blocks: int, num_heads: int, num_tokens: int, title=\"\", save: Optional[str] = None, normalized=False, figsize=(20, 25), logx=False, logy=False):\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    plt.suptitle(title)\n",
    "\n",
    "    num_cols = num_blocks * 2\n",
    "    num_rows = 1 + 1 + num_heads\n",
    "\n",
    "    suffix = \"\" if not normalized else \"_normalized\"\n",
    "    suffix_title = \"\" if not normalized else \" (Normalized)\"\n",
    "\n",
    "    # Create subplot for mean entropy of first two blocks\n",
    "    ax0 = plt.subplot2grid((num_rows, num_cols), (0, 0), colspan=num_cols)\n",
    "    block_cmap = sns.color_palette(\"viridis\", num_blocks)\n",
    "\n",
    "    for b in range(num_blocks):\n",
    "        ax0.plot(df.step, df[f\"block_{b}/mean{suffix}\"], label=f\"block_{b}\", color=block_cmap[b])\n",
    "\n",
    "    ax0.set_title(\"Blocks\")\n",
    "    ax0.set_xlabel(\"Step\")\n",
    "    ax0.set_ylabel(f\"Entropy{suffix_title}\")\n",
    "    ax0.legend()\n",
    "\n",
    "    # Create subplots for each block, showing entropy in different heads\n",
    "    ax1 = [plt.subplot2grid((num_rows, num_cols), (1, i*2), colspan=2) for i in range(num_blocks)]\n",
    "    head_cmap = sns.color_palette(\"viridis\", num_heads)\n",
    "    \n",
    "    for b in range(num_blocks):\n",
    "        ax1[b].set_title(f\"Block {b}\")\n",
    "        ax1[b].set_xlabel(\"Step\")\n",
    "        ax1[b].set_ylabel(f\"Entropy{suffix_title}\")\n",
    "        for h in range(num_heads):\n",
    "            series = df[f\"block_{b}/head_{h}/mean{suffix}\"]\n",
    "            ax1[b].plot(df.step, series, label=f\"Head {h}\", color=head_cmap[h])\n",
    "\n",
    "    ax1[0].legend()\n",
    "\n",
    "    # Create subplots for each head in each block, detailing entropy for each token\n",
    "    ax2 = [plt.subplot2grid((num_rows, num_cols), (i//(num_cols) + 2, i%(num_cols))) for i in range(num_heads * num_blocks * 2)]\n",
    "    ax_idx = 0\n",
    "    token_cmap = sns.color_palette(\"viridis\", num_tokens)\n",
    "\n",
    "\n",
    "    for h in range(num_heads):\n",
    "        for b in range(num_blocks):\n",
    "            for x_or_y in (1, 0):\n",
    "                ax2[ax_idx].set_title(f\"Block {b} Head {h}\")\n",
    "                ax2[ax_idx].set_xlabel(\"Step\")\n",
    "                ax2[ax_idx].set_ylabel(f\"Entropy{suffix_title}\")\n",
    "\n",
    "                for t in range(1-int(x_or_y), num_tokens, 2):\n",
    "                    series = df[f\"block_{b}/head_{h}/token_{t}{suffix}\"]\n",
    "                    ax2[ax_idx].plot(df.step, series, label=f\"Token {t}\", color=token_cmap[t])\n",
    "                    \n",
    "                ax_idx += 1\n",
    "\n",
    "    ax2[0].legend()\n",
    "    ax2[1].legend()\n",
    "\n",
    "    for ax in [ax0, *ax1, *ax2]:\n",
    "        if logx:\n",
    "            ax.set_xscale(\"log\")\n",
    "        if logy:\n",
    "            ax.set_yscale(\"log\")\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "    if save:\n",
    "        parent_dir = os.path.dirname(save)\n",
    "        if not os.path.exists(parent_dir):\n",
    "            os.makedirs(parent_dir)\n",
    "        plt.savefig(save)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = Run(configs[2])\n",
    "\n",
    "num_blocks = demo.config.task_config.num_layers\n",
    "num_heads = demo.config.task_config.num_heads\n",
    "num_tokens = demo.config.task_config.max_examples\n",
    "\n",
    "df = get_attention_entropies_trace(\n",
    "    demo.checkpointer.file_ids,\n",
    "    iter_models(demo.model, demo.checkpointer, verbose=True), \n",
    "    demo.evaluator.pretrain_xs, \n",
    "    demo.evaluator.pretrain_ys, \n",
    "    **{f\"block_{b}\": f\"token_sequence_transformer.blocks.{b}.attention.attention_softmax\" for b in range(num_blocks)}\n",
    ")\n",
    "\n",
    "demo_attn_entropy_slug = \"attn-S-\" + demo.config.to_slug(delimiter=\"-\")\n",
    "\n",
    "for normalized in (True, False):\n",
    "    plot_attention_patterns(\n",
    "        df, \n",
    "        num_blocks=num_blocks, \n",
    "        num_heads=num_heads, \n",
    "        num_tokens=num_tokens, \n",
    "        title=demo.config.to_latex(), \n",
    "        save=FIGURES / (demo_attn_entropy_slug + \".png\"),\n",
    "        figsize=(25, 25),\n",
    "        normalized=normalized\n",
    "    )\n",
    "\n",
    "# df.to_csv(ANALYSIS / (demo_attn_entropy_slug + \".csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for config, checkpointer in zip(configs, checkpointers):\n",
    "    run = Run(config)\n",
    "    \n",
    "    num_blocks = run.config.task_config.num_layers\n",
    "    num_heads = run.config.task_config.num_heads\n",
    "    num_tokens = run.config.task_config.max_examples\n",
    "\n",
    "    df = get_attention_entropies_trace(\n",
    "        checkpointer.file_ids,\n",
    "        iter_models(run.model, checkpointer, verbose=True), \n",
    "        run.evaluator.pretrain_xs, \n",
    "        run.evaluator.pretrain_ys, \n",
    "        **{f\"block_{b}\": f\"token_sequence_transformer.blocks.{b}.attention.attention_softmax\" for b in range(num_blocks)}\n",
    "    )\n",
    "    \n",
    "    slug = \"attn-S-\" + run.config.to_slug(delimiter=\"-\")\n",
    "\n",
    "    plot_attention_patterns(\n",
    "        df, \n",
    "        num_blocks=num_blocks, \n",
    "        num_heads=num_heads, \n",
    "        num_tokens=num_tokens, \n",
    "        title=run.config.to_latex(), \n",
    "        save=FIGURES / (slug + \".png\"),\n",
    "        figsize=(25, 25),\n",
    "        normalized=True\n",
    "    )\n",
    "\n",
    "    df.to_csv(ANALYSIS / (slug + \".csv\"))\n",
    "\n",
    "os.system('say \"Your program has finished.\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RLCTs & Covariance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from icl.train import Run\n",
    "demo = Run(configs[2])\n",
    "attn_weights = demo.model.token_sequence_transformer.blocks[0].attention.attention.weight\n",
    "attn_weights.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numel_per_layer = attn_weights.numel()\n",
    "\n",
    "def num_params_to_gb(num: int):\n",
    "    return f\"{num * (32 / 8) / (10 ** 9):.2f} Gb\"\n",
    "\n",
    "for num_blocks in [2, 4, 8]:\n",
    "    for num_heads in [2, 4]:\n",
    "        numel_per_head = numel_per_layer // num_heads\n",
    "\n",
    "        within_head_cov_size = (numel_per_head ** 2)  * num_heads * num_blocks\n",
    "        between_head_cov_size = (numel_per_head ** 2) * num_heads * num_heads * (num_blocks-1)\n",
    "\n",
    "        full_cov_size = (numel_per_layer * num_blocks) ** 2\n",
    "\n",
    "        reduction = full_cov_size - within_head_cov_size - between_head_cov_size\n",
    "\n",
    "        print(f\"\\nL{num_blocks}H{num_heads}\")\n",
    "        print(\"Full:\", f\"{full_cov_size:,} ({num_params_to_gb(full_cov_size)})\")\n",
    "        print(\"Within heads:\", f\"{within_head_cov_size:,} ({num_params_to_gb(within_head_cov_size)})\")\n",
    "        print(\"Between heads:\", f\"{between_head_cov_size:,} ({num_params_to_gb(between_head_cov_size)})\")\n",
    "        print(\"Reduction:\", f\"-{reduction:,} (-{reduction/full_cov_size * 100:.2f}%)\")\n",
    "\n",
    "# attn_weights.numel(), f\"{(32 // 8 * (attn_weights.numel() * 2 ) ** 2):,}\", attn_weights.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_attn_weights(W: torch.Tensor, num_heads: int, embed_dim: int, head_size: int):\n",
    "    W_split = W.view((embed_dim, num_heads, head_size * 3))\n",
    "    \n",
    "    for h in range(num_heads):\n",
    "        yield tuple(W_split[:, h, i*head_size:(i+1)*head_size] for i in range(3))\n",
    "\n",
    "\n",
    "def plot_attn_weights(W: torch.Tensor, num_heads: int, embed_dim: int, head_size: int, subtitles=(\"$W_Q^{(h)}$\", \"$W_K^{(h)}$\", \"$W_V^{(h)}$\"), title=\"\", save: Optional[str] = None):\n",
    "    heads = list(split_attn_weights(W, num_heads, embed_dim, head_size))\n",
    "\n",
    "    fig, axs = plt.subplots(num_heads, 3, figsize=(25, 10))\n",
    "    plt.suptitle(title)\n",
    "\n",
    "    for h, head in enumerate(heads):\n",
    "        axs[h, 0].set_ylabel(f\"Head {h}\\nHead Size\")\n",
    "\n",
    "        for i, mat in enumerate(head):\n",
    "            axs[h, i].matshow(mat.detach().cpu().numpy().T, cmap='viridis') \n",
    "\n",
    "    for i, subtitle in enumerate(subtitles):\n",
    "        axs[0, i].set_title(subtitle)\n",
    "        axs[-1, i].set_xlabel(\"Embedding Dimension\")\n",
    "\n",
    "    if save:\n",
    "        parent_dir = os.path.dirname(save)\n",
    "        if not os.path.exists(parent_dir):\n",
    "            os.makedirs(parent_dir)\n",
    "        plt.savefig(save)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_attn_head_weights(head: torch.Tensor, embed_dim, head_size: int, title=\"\", subtitles=(\"$W_Q$\", \"$W_K$\", \"$W_V$\"), save: Optional[str] = None):\n",
    "    head_Ex3c = head.view((embed_dim, head_size * 3))\n",
    "    q, k, v = tuple(head_Ex3c[:, i*head_size:(i+1)*head_size].detach().cpu().numpy() for i in range(3))\n",
    "\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(30, 3.5))\n",
    "    plt.suptitle(title)\n",
    "\n",
    "    for i, (mat, subtitle) in enumerate(zip((q, k, v), subtitles)):\n",
    "        ax[i].set_title(subtitle)\n",
    "        ax[i].matshow(mat.T, cmap='viridis')\n",
    "        ax[i].set_xlabel(\"Embedding Dimension\")\n",
    "        ax[i].set_ylabel(\"Head Size\")\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "    if save:\n",
    "        parent_dir = os.path.dirname(save)\n",
    "        if not os.path.exists(parent_dir):\n",
    "            os.makedirs(parent_dir)\n",
    "        plt.savefig(save)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attn_eigencomponents(evecs, evals, slug: Optional[str] = None):\n",
    "    for i in range(1, 4):\n",
    "        attn0, attn1 = evecs[:evecs.shape[0]//2, -i], evecs[evecs.shape[0]//2:, -i]\n",
    "\n",
    "        for layer, attn in enumerate((attn0, attn1)):\n",
    "            plot_attn_weights(\n",
    "                torch.Tensor(attn), \n",
    "                num_heads=4,\n",
    "                embed_dim=64, \n",
    "                head_size=16, \n",
    "                title=f\"Eigenvector {i-1} of covariance matrix within attention layer 0 ($\\lambda_{i-1}={evals[-i]}$)\",\n",
    "                subtitles=(f\"$u_{{Q,{i-1}}}^{{({layer})}}$\", f\"$u_{{K,{i-1}}}^{{({layer})}}$\", f\"$u_{{V,{i-1}}}^{{({layer})}}$\"),\n",
    "                save=(FIGURES / (f\"cov-attn{layer}-evec{i-1}-\" + slug + \".png\") if slug else None)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attn_weights(attn0, 4, 64, 16, title=\"Attention layer 0\")\n",
    "\n",
    "num_heads = 4\n",
    "attn0_view = attn0.view((64, num_heads, 16 * 3))\n",
    "heads = [attn0_view[:, h, :] for h in range(num_heads)]\n",
    "full_head_size = 16 * 3 * 64\n",
    "pseudo_cov = heads[0].reshape((full_head_size, 1)) * heads[1].reshape((1, full_head_size)) \n",
    "head_evals, head_evecs = eigsh(pseudo_cov.detach().cpu().numpy(), k=3, which=\"LM\")\n",
    "del pseudo_cov\n",
    "\n",
    "\n",
    "print(head_evals)\n",
    "plot_attn_head_weights(\n",
    "    torch.Tensor(head_evecs[:, -1]), \n",
    "    64, \n",
    "    16, \n",
    "    title=\"Principal eigenvalue of covariance matrix within head 1\",\n",
    "    subtitles=(\"$u_{Q,1}^{(1)}$\", \"$u_{K,1}^{(1)}$\", \"$u_{V,1}^{(1)}$\")   \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from icl.analysis.rlct import make_slt_evals\n",
    "\n",
    "def generate_slt_observables(\n",
    "    steps: List[int],\n",
    "    models: Iterable[nn.Module],\n",
    "    xs: torch.Tensor,\n",
    "    ys: torch.Tensor,\n",
    "    **kwargs\n",
    "):\n",
    "    trainset = torch.utils.data.TensorDataset(xs, ys)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=len(xs))\n",
    "    slt_evals = make_slt_evals(\n",
    "        dataset=trainset,\n",
    "        loader=trainloader,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "    for step, model in zip(steps, models):\n",
    "        yield step, slt_evals(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import multiprocessing\n",
    "from copy import deepcopy\n",
    "from dataclasses import dataclass\n",
    "from functools import partial\n",
    "from logging import Logger\n",
    "from typing import Callable, Dict, List, Literal, Optional, Type, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import yaml\n",
    "from devinfra.evals import Criterion\n",
    "from devinterp.optim.sgld import SGLD\n",
    "from torch import nn\n",
    "from torch.multiprocessing import Pool, cpu_count, get_context, set_start_method\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# set_start_method('spawn')  # Required for sharing CUDA tensors\n",
    "\n",
    "\n",
    "def get_weights(model, paths):\n",
    "    for path in paths:\n",
    "        full_path = path.split(\".\")\n",
    "        layer = model\n",
    "\n",
    "        for p in full_path:\n",
    "            layer = getattr(layer, p)\n",
    "\n",
    "        yield layer.weight.view((-1,))\n",
    "\n",
    "        if layer.bias is not None:\n",
    "            yield layer.bias.view((-1,))\n",
    " \n",
    " \n",
    "def sample_single_chain(\n",
    "    ref_model: nn.Module,\n",
    "    loader: DataLoader,\n",
    "    criterion: Callable,\n",
    "    num_draws=100,\n",
    "    num_burnin_steps=0,\n",
    "    num_steps_bw_draws=1,\n",
    "    sampling_method: Type[torch.optim.Optimizer] = SGLD,\n",
    "    optimizer_kwargs: Optional[Dict] = None,\n",
    "    chain: int = 0,\n",
    "    seed: Optional[int] = None,\n",
    "    verbose=True,\n",
    "    device: Union[str, torch.device] = torch.device(\"cpu\"),\n",
    "    callbacks: List[Callable] = []\n",
    "):\n",
    "    # Initialize new model and optimizer for this chain\n",
    "    model = deepcopy(ref_model).to(device)\n",
    "\n",
    "    optimizer_kwargs = optimizer_kwargs or {}\n",
    "    optimizer = sampling_method(model.parameters(), **optimizer_kwargs)\n",
    "\n",
    "    if seed is not None:\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "    num_steps = num_draws * num_steps_bw_draws + num_burnin_steps\n",
    "\n",
    "    local_draws = pd.DataFrame(\n",
    "        index=range(num_draws),\n",
    "        columns=[\"chain\", \"step\", \"loss\"],\n",
    "    )\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for i, (xs, ys) in  tqdm(zip(range(num_steps), itertools.cycle(loader)), desc=f\"Chain {chain}\", total=num_steps, disable=not verbose):\n",
    "        optimizer.zero_grad()\n",
    "        xs, ys = xs.to(device), ys.to(device)\n",
    "        y_preds = model(xs, ys)\n",
    "        loss = criterion(y_preds, ys)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i >= num_burnin_steps and (i - num_burnin_steps) % num_steps_bw_draws == 0:\n",
    "            draw_idx = (i - num_burnin_steps) // num_steps_bw_draws\n",
    "            local_draws.loc[draw_idx, \"step\"] = i\n",
    "            local_draws.loc[draw_idx, \"chain\"] = chain\n",
    "            local_draws.loc[draw_idx, \"loss\"] = loss.detach().item()\n",
    "            \n",
    "            for callback in callbacks:\n",
    "                callback(model)\n",
    "\n",
    "    return local_draws\n",
    "\n",
    "\n",
    "def _sample_single_chain(kwargs):\n",
    "    return sample_single_chain(**kwargs)\n",
    "\n",
    "\n",
    "def sample(\n",
    "    model: torch.nn.Module,\n",
    "    loader: DataLoader,\n",
    "    criterion: Callable,\n",
    "    sampling_method: Type[torch.optim.Optimizer] = SGLD,\n",
    "    optimizer_kwargs: Optional[Dict[str, Union[float, Literal[\"adaptive\"]]]] = None,\n",
    "    num_draws: int = 100,\n",
    "    num_chains: int = 10,\n",
    "    num_burnin_steps: int = 0,\n",
    "    num_steps_bw_draws: int = 1,\n",
    "    cores: int = 1,\n",
    "    seed: Optional[Union[int, List[int]]] = None,\n",
    "    device: torch.device = torch.device(\"cpu\"),\n",
    "    verbose: bool = True,\n",
    "    callbacks: List[Callable] = []\n",
    "):\n",
    "    \"\"\"\n",
    "    Sample model weights using a given optimizer, supporting multiple chains.\n",
    "\n",
    "    Parameters:\n",
    "        model (torch.nn.Module): The neural network model.\n",
    "        step (Literal['sgld']): The name of the optimizer to use to step.\n",
    "        loader (DataLoader): DataLoader for input data.\n",
    "        criterion (torch.nn.Module): Loss function.\n",
    "        num_draws (int): Number of samples to draw.\n",
    "        num_chains (int): Number of chains to run.\n",
    "        num_burnin_steps (int): Number of burn-in steps before sampling.\n",
    "        num_steps_bw_draws (int): Number of steps between each draw.\n",
    "        cores (Optional[int]): Number of cores for parallel execution.\n",
    "        seed (Optional[Union[int, List[int]]]): Random seed(s) for sampling.\n",
    "        optimizer_kwargs (Optional[Dict[str, Union[float, Literal['adaptive']]]]): Keyword arguments for the optimizer.\n",
    "    \"\"\"\n",
    "    if cores is None:\n",
    "        cores = min(4, cpu_count())\n",
    "\n",
    "    if seed is not None:\n",
    "        if isinstance(seed, int):\n",
    "            seeds = [seed + i for i in range(num_chains)]\n",
    "        elif len(seed) != num_chains:\n",
    "            raise ValueError(\"Length of seed list must match number of chains\")\n",
    "        else:\n",
    "            seeds = seed\n",
    "    else:\n",
    "        seeds = [None] * num_chains\n",
    "\n",
    "    def get_args(i):\n",
    "        return dict(\n",
    "            chain=i,\n",
    "            seed=seeds[i],\n",
    "            ref_model=model,\n",
    "            loader=loader,\n",
    "            criterion=criterion,\n",
    "            num_draws=num_draws,\n",
    "            num_burnin_steps=num_burnin_steps,\n",
    "            num_steps_bw_draws=num_steps_bw_draws,\n",
    "            sampling_method=sampling_method,\n",
    "            optimizer_kwargs=optimizer_kwargs,\n",
    "            device=device,\n",
    "            verbose=verbose,\n",
    "            callbacks=callbacks\n",
    "        )\n",
    "\n",
    "    results = []\n",
    "\n",
    "    if cores > 1:\n",
    "        ctx = get_context(\"spawn\")\n",
    "        with ctx.Pool(cores) as pool:\n",
    "            results = pool.map(_sample_single_chain, [get_args(i) for i in range(num_chains)])\n",
    "    else:\n",
    "        for i in range(num_chains):\n",
    "            results.append(_sample_single_chain(get_args(i)))\n",
    "\n",
    "    results_df = pd.concat([r for r in results], ignore_index=True)\n",
    "\n",
    "    for callback in callbacks:\n",
    "        if hasattr(callback, \"finalize\"):\n",
    "            callback.finalize()\n",
    "\n",
    "    return results_df\n",
    "\n",
    "\n",
    "class CovarianceCallback:\n",
    "    def __init__(self, num_weights: int, device = \"cpu\", paths: List[str] = []):\n",
    "        self._weights = torch.zeros(num_weights, device=device).share_memory_()\n",
    "        self.first_moment = torch.zeros(num_weights, device=device).share_memory_()\n",
    "        self.second_moment = torch.zeros(num_weights, num_weights, device=device).share_memory_()\n",
    "        self.num_draws = 0\n",
    "        self.paths = paths\n",
    "\n",
    "        # within_head_cov_size = (numel_per_head ** 2)  * num_heads * num_blocks\n",
    "        # between_head_cov_size = (numel_per_head ** 2) * num_heads * num_heads * (num_blocks-1)\n",
    "        # self.within_head = torch.zeros(num_weights, num_weights, device=device).share_memory_()\n",
    "        # self.between_head = torch.zeros(num_weights, num_weights, device=device).share_memory_()\n",
    "\n",
    "    def accumulate(self, model):\n",
    "        i = 0\n",
    "        for weights in get_weights(model, self.paths):\n",
    "            self._weights[i:i+len(weights)] = weights\n",
    "\n",
    "        self.first_moment.add_(self._weights)\n",
    "        self.second_moment.add_(self._weights.unsqueeze(0) @ self._weights.unsqueeze(-1))\n",
    "        self.num_draws += 1\n",
    "\n",
    "    def finalize(self):\n",
    "        self.first_moment /= self.num_draws\n",
    "        self.second_moment /= self.num_draws\n",
    "\n",
    "    def reset(self):\n",
    "        self.first_moment.zero_()\n",
    "        self.second_moment.zero_()\n",
    "        self.num_draws = 0\n",
    "\n",
    "    def __call__(self, model):\n",
    "        self.accumulate(model)\n",
    "\n",
    "    def to_matrix(self):\n",
    "        return self.second_moment - self.first_moment.unsqueeze(0) @ self.first_moment.unsqueeze(-1)\n",
    "\n",
    "\n",
    "def estimate_slt_observabls(\n",
    "    model: torch.nn.Module,\n",
    "    loader: DataLoader,\n",
    "    criterion: Criterion,\n",
    "    sampling_method: Type[torch.optim.Optimizer] = SGLD,\n",
    "    optimizer_kwargs: Optional[Dict[str, Union[float, Literal[\"adaptive\"]]]] = None,\n",
    "    num_draws: int = 100,\n",
    "    num_chains: int = 10,\n",
    "    num_burnin_steps: int = 0,\n",
    "    num_steps_bw_draws: int = 1,\n",
    "    cores: int = 1,\n",
    "    seed: Optional[Union[int, List[int]]] = None,\n",
    "    verbose: bool = True,\n",
    "    device: str = \"cpu\",\n",
    "    covariance_paths: List[str] = []\n",
    "):\n",
    "    callbacks = [\n",
    "        CovarianceCallback(\n",
    "            num_weights=sum(p.numel() for p in get_weights(model, covariance_paths)),\n",
    "            device=device,\n",
    "            paths=covariance_paths\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    trace = sample(\n",
    "        model=model,\n",
    "        loader=loader,\n",
    "        criterion=criterion,\n",
    "        sampling_method=sampling_method,\n",
    "        optimizer_kwargs=optimizer_kwargs,\n",
    "        num_draws=num_draws,\n",
    "        num_chains=num_chains,\n",
    "        num_burnin_steps=num_burnin_steps,\n",
    "        num_steps_bw_draws=num_steps_bw_draws,\n",
    "        cores=cores,\n",
    "        seed=seed,\n",
    "        verbose=verbose,\n",
    "        device=device,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "\n",
    "    baseline_loss = trace.loc[trace[\"chain\"] == 0, \"loss\"].iloc[0]\n",
    "    num_samples = len(loader.dataset)\n",
    "    avg_losses = trace.groupby(\"chain\")[\"loss\"].mean()\n",
    "    results = torch.zeros(num_chains, device=device)\n",
    "\n",
    "    for i in range(num_chains):\n",
    "        chain_avg_loss = avg_losses.iloc[i]\n",
    "        results[i] = (chain_avg_loss - baseline_loss) * num_samples / np.log(num_samples)\n",
    "\n",
    "    avg_loss = results.mean()\n",
    "    std_loss = results.std()\n",
    "\n",
    "    return {\n",
    "        \"mean\": avg_loss.item(),\n",
    "        \"std\": std_loss.item(),\n",
    "        **{f\"chain_{i}\": results[i].item() for i in range(num_chains)},\n",
    "        \"trace\": trace,\n",
    "        \"covariance\": callbacks[0].to_matrix().detach().cpu().numpy()\n",
    "    }\n",
    "\n",
    "\n",
    "def make_slt_evals(\n",
    "    dataset: torch.utils.data.Dataset,\n",
    "    loader: torch.utils.data.DataLoader,\n",
    "    lr: float = 1e-4,\n",
    "    noise_level: float = 1.0,\n",
    "    weight_decay: float = 0.0,\n",
    "    elasticity: float = 1.0,\n",
    "    num_draws: int = 10,\n",
    "    num_chains: int = 25,\n",
    "    num_burnin_steps: int = 0,\n",
    "    num_steps_bw_draws: int = 1,\n",
    "    cores: int = 1,\n",
    "    covariance_paths: List[str] = [],\n",
    "    device: str = \"cpu\",\n",
    "):\n",
    "    def eval_rlct(model: nn.Module):\n",
    "        optimizer_kwargs = dict(\n",
    "            lr=lr,\n",
    "            noise_level=noise_level,\n",
    "            weight_decay=weight_decay,\n",
    "            elasticity=elasticity,\n",
    "            temperature=\"adaptive\",\n",
    "            num_samples=len(dataset),\n",
    "        )\n",
    "        return estimate_slt_observabls(\n",
    "            model,\n",
    "            loader,\n",
    "            F.mse_loss,\n",
    "            SGLD,\n",
    "            optimizer_kwargs,\n",
    "            num_draws=num_draws,\n",
    "            num_chains=num_chains,\n",
    "            num_burnin_steps=num_burnin_steps,\n",
    "            num_steps_bw_draws=num_steps_bw_draws,\n",
    "            cores=cores,\n",
    "            device=device,\n",
    "            covariance_paths=covariance_paths,\n",
    "        )\n",
    "\n",
    "    return eval_rlct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(checkpointer.file_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_coeff_over_time(steps, lcs, lc_stds, title=\"\", save: Optional[str] = None):\n",
    "\n",
    "    # Initialize the figure\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(18, 12))\n",
    "    ax.set_title(title)\n",
    "\n",
    "    # Plot mean values as a line\n",
    "    ax.plot(steps, lcs, 'o-', linewidth=2)\n",
    "    \n",
    "    # Add shaded area for error\n",
    "    ax.fill_between(steps, lcs - lc_stds, lcs + lc_stds, color='gray', alpha=0.4)\n",
    "\n",
    "    # Labels and scales\n",
    "    ax.set_xlabel(\"Steps\")\n",
    "    ax.set_ylabel(r\"$\\hat\\lambda$\")\n",
    "    \n",
    "    fig.tight_layout()\n",
    "\n",
    "    if save:\n",
    "        parent_dir = os.path.dirname(save)\n",
    "        if not os.path.exists(parent_dir):\n",
    "            os.makedirs(parent_dir)\n",
    "        plt.savefig(save)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_cov_evals_over_time(steps, *eval_traces, title=\"\", save: Optional[str] = None):\n",
    "\n",
    "    # Initialize the figure\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(18, 12))\n",
    "    ax.set_title(title)\n",
    "\n",
    "    # Plot mean values as a line\n",
    "    for i, eval_trace in enumerate(eval_traces):\n",
    "        ax.plot(steps, eval_trace, 'o-', label=f\"Eigenvalue {i}\", linewidth=2)\n",
    "    \n",
    "    # Labels and scales\n",
    "    ax.set_xlabel(\"Steps\")\n",
    "    ax.set_ylabel(r\"$\\hat\\lambda$\")\n",
    "    \n",
    "    # Show legend\n",
    "    ax.legend()\n",
    "\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    if save:\n",
    "        parent_dir = os.path.dirname(save)\n",
    "        if not os.path.exists(parent_dir):\n",
    "            os.makedirs(parent_dir)\n",
    "        plt.savefig(save)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from scipy.sparse.linalg import eigsh\n",
    "\n",
    "\n",
    "MS = [1, 4, 64, 2**10, 2**20]\n",
    "STEPS = [9003, 10204, 11767, 15381, 20104, 20408, 26279, 30612] #[0, 1_805, 3_084, 15_381, 26_279, 100_262, 153_061, 193_877, 255_102, 306_122, 408_163]\n",
    "\n",
    "for m in MS:\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    log2_m = int(np.log2(m))\n",
    "    config, checkpointer = configs[log2_m], checkpointers[log2_m]\n",
    "    run = Run(config)\n",
    "\n",
    "    xs, ys = run.evaluator.pretrain_xs, run.evaluator.pretrain_ys\n",
    "    trainset = torch.utils.data.TensorDataset(xs, ys)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=len(xs))\n",
    "    observables_over_time = []\n",
    "    \n",
    "    slt_evals = make_slt_evals(\n",
    "        dataset=trainset,\n",
    "        loader=trainloader,\n",
    "        cores=1,\n",
    "        lr=1e-5,\n",
    "        num_draws=100,\n",
    "        elasticity=1.,\n",
    "        num_chains=20,\n",
    "        device=\"cuda\",\n",
    "        covariance_paths=[\n",
    "            f\"token_sequence_transformer.blocks.{b}.attention.attention\"\n",
    "            for b in range(run.config.task_config.num_layers)\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    slug = run.config.to_slug(delimiter=\"-\")\n",
    "\n",
    "    min_step = -1\n",
    "\n",
    "    if os.path.exists(ANALYSIS / f\"cov-tmp-{slug}.pt\"):\n",
    "        min_step, observables = torch.load(ANALYSIS / f\"cov-tmp-{slug}.pt\")\n",
    "        print(f\"Loaded observables from previous step {min_step} from {ANALYSIS / f'cov-tmp-{slug}.pt'}\")\n",
    "    \n",
    "    for step in STEPS:\n",
    "        if step > min_step:\n",
    "            run.model.load_state_dict(checkpointer.load_file(step)[\"model\"])\n",
    "            observables = slt_evals(run.model)\n",
    "            torch.save((step, observables), ANALYSIS / f\"cov-tmp-{slug}.pt\")\n",
    "\n",
    "        cov = observables.pop(\"covariance\")\n",
    "        evals, evecs = eigsh(cov, k=3, which='LM')\n",
    "\n",
    "        for i in range(1, 4):\n",
    "            observables[f\"cov-eval/{i-1}\"] = evals[-i]\n",
    "\n",
    "        observables_over_time.append(observables)\n",
    "        del cov\n",
    "        pp(observables)\n",
    "        plot_attn_eigencomponents(evecs, evals, slug=slug + f\"@t={step}\")\n",
    "\n",
    "    plot_cov_evals_over_time(\n",
    "        STEPS,\n",
    "        [o[\"cov-eval/0\"] for o in observables_over_time],\n",
    "        [o[\"cov-eval/1\"] for o in observables_over_time],\n",
    "        [o[\"cov-eval/2\"] for o in observables_over_time],\n",
    "        title=run.config.to_latex(),\n",
    "        save=FIGURES / f\"cov-eval-of-t-{slug}.png\"\n",
    "    )\n",
    "\n",
    "    plot_learning_coeff_over_time(\n",
    "        STEPS,\n",
    "        [o[\"mean\"] for o in observables_over_time],\n",
    "        [o[\"std\"] for o in observables_over_time],\n",
    "        title=run.config.to_latex(),\n",
    "        save=FIGURES / f\"lc-of-t-{slug}.png\"\n",
    "    )\n",
    "\n",
    "    observables_df = pd.DataFrame(observables_over_time)\n",
    "    observables_df.to_csv(ANALYSIS / f\"cov/cov-{slug}.csv\")\n",
    "    os.remove(ANALYSIS / f\"cov-tmp-{slug}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(observables_over_time[0].keys())\n",
    "plot_cov_evals_over_time(\n",
    "    STEPS,\n",
    "    [o[\"cov-eval/0\"] for o in observables_over_time],\n",
    "    [o[\"cov-eval/1\"] for o in observables_over_time],\n",
    "    title=run.config.to_latex(),\n",
    "    save=FIGURES / f\"cov-eval-of-t-{slug}.png\"\n",
    ")\n",
    "\n",
    "plot_learning_coeff_over_time(\n",
    "    STEPS,\n",
    "    np.array([o[\"mean\"] for o in observables_over_time]),\n",
    "    np.array([o[\"std\"] for o in observables_over_time]),\n",
    "    title=run.config.to_latex(),\n",
    "    save=FIGURES / f\"lc-of-t-{slug}.png\"\n",
    ")\n",
    "\n",
    "observables_df = pd.DataFrame(observables_over_time)\n",
    "observables_df.to_csv(ANALYSIS / f\"cov/cov-{slug}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "del run, trainset, trainloader\n",
    "del slt_evals\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariances = observables.pop(\"covariances\")\n",
    "evals, evecs = eigsh(covariances, k=3, which='LM')\n",
    "\n",
    "for i, (eval, evec) in enumerate(zip(evals, evecs.T)):\n",
    "    slug = f\"cov-u{i}\" + run.config.to_slug(delimiter=\"-\") + f\"@t={step}\"\n",
    "    attn0, attn1 = evec.split(64 * 16 * 3)\n",
    "    \n",
    "\n",
    "# TODO: Need to rename the new files otherwise you can't tell easily tell what step they come from.\n",
    "\n",
    "\n",
    "os.system('say \"Your program has finished.\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from scipy.sparse.linalg import eigsh\n",
    "\n",
    "\n",
    "# wandb.init(entity=\"devinterp\", project=\"icl\")\n",
    "\n",
    "for config, checkpointer in zip(configs, checkpointers):\n",
    "    run = Run(config)\n",
    "    observables_over_time = []\n",
    "    \n",
    "    for step, observables in generate_slt_observables(\n",
    "        checkpointer.file_ids,\n",
    "        iter_models(run.model, checkpointer, verbose=True), \n",
    "        run.evaluator.pretrain_xs, \n",
    "        run.evaluator.pretrain_ys, \n",
    "        cores=4,\n",
    "        lr=1e-5,\n",
    "        num_draws=100,\n",
    "        elasticity=1.,\n",
    "        num_chains=20,\n",
    "        device=\"cuda\",\n",
    "        covariance_paths=[\n",
    "            f\"token_sequence_transformer.blocks.{b}.attention.attention\"\n",
    "            for b in range(run.config.task_config.num_layers)\n",
    "        ]\n",
    "    ):\n",
    "        # wandb.log(observables, step=step)\n",
    "        observables[\"step\"] = step\n",
    "        covariances = observables.pop(\"covariances\")\n",
    "\n",
    "        # I only want the two largest eigenvalues in evals and evecs\n",
    "        covariances = np.linalg.eigvalsh(covariances)\n",
    "        evals, evecs = eigsh(covariances, k=3, which='LM')\n",
    "        \n",
    "        observables_over_time.append(observables)\n",
    "        print(yaml.dump({\n",
    "            **observables,\n",
    "            \"covariances\": covariances.shape\n",
    "        }))\n",
    "\n",
    "        raise NotImplementedError(\"TODO: Save covariances\")\n",
    "\n",
    "    df = pd.DataFrame(observables_over_time)\n",
    "    slug = \"slt-\" + run.config.to_slug(delimiter=\"-\")\n",
    "    df.to_csv(ANALYSIS / (slug + \".csv\"))\n",
    "\n",
    "# wandb.finish()\n",
    "os.system('say \"Your program has finished.\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "from icl.config import ICLConfig\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def gather_images_side_by_side(folder, save: Optional[str] = None, delete: bool = True):\n",
    "    \"\"\"\n",
    "    Assumes folder contains folders that contain pngs. \n",
    "    \"\"\"\n",
    "    folder = Path(folder)\n",
    "    folder_paths = folder.glob(\"*\")\n",
    "\n",
    "    # Create a dictionary to store images by filename\n",
    "    images_by_filename = {}\n",
    "\n",
    "    if save:\n",
    "        save = Path(save)\n",
    "\n",
    "        if not os.path.exists(save):\n",
    "            os.makedirs(save)\n",
    "\n",
    "    # Load images from each folder and organize them by filename\n",
    "    for folder_path in folder_paths:\n",
    "        filenames = [f for f in os.listdir(folder_path) if f.endswith('.png')] \n",
    "        for filename in filenames:\n",
    "            img = Image.open(os.path.join(folder_path, filename))\n",
    "            if filename in images_by_filename:\n",
    "                images_by_filename[filename].append(img)\n",
    "            else:\n",
    "                images_by_filename[filename] = [img]\n",
    "\n",
    "    # Create comparison images for each unique filename\n",
    "    for filename, image_list in images_by_filename.items():\n",
    "        # Calculate the width and height of the result image\n",
    "        width = sum(img.width for img in image_list)\n",
    "        height = max(img.height for img in image_list)\n",
    "\n",
    "        # Create a new image for the comparison\n",
    "        result_image = Image.new('RGB', (width, height))\n",
    "\n",
    "        # Paste images side by side\n",
    "        x_offset = 0\n",
    "        for img in image_list:\n",
    "            result_image.paste(img, (x_offset, 0))\n",
    "            x_offset += img.width\n",
    "\n",
    "        # Display or save the result image\n",
    "        if save: \n",
    "            result_image.save(save / filename)  # You can replace this with result_image.save() to save the comparison images\n",
    "\n",
    "    if delete:\n",
    "        # Delete the temporary folder\n",
    "        shutil.rmtree(folder)\n",
    "\n",
    "\n",
    "def plot_activations(config: ICLConfig, activations: Dict[str, torch.Tensor], save: Optional[str] = None):\n",
    "    B = 1\n",
    "    E = config.task_config.embed_size\n",
    "    T = 2 * config.task_config.max_examples\n",
    "    H = config.task_config.num_heads\n",
    "\n",
    "    def optionally_rotate(x, name):\n",
    "        if len(x.shape) != 2:\n",
    "            raise ValueError(\"Tensor should have two dimensions.\")\n",
    "\n",
    "        if x.shape[0] > x.shape[1]:\n",
    "            return x.T, f\"{name}.T\"\n",
    "        \n",
    "        return x, name \n",
    "\n",
    "    def separate_attention(qkv: TensorType[\"B\", \"T\", \"C\"], num_heads: int, batch_size: int, head_size: int, num_tokens: int):\n",
    "        return (qkv   \n",
    "            .view(batch_size, num_tokens, num_heads, 3*head_size)\n",
    "            .transpose(-2, -3)     \n",
    "            .split(head_size, dim=-1)\n",
    "        )\n",
    "\n",
    "    if save:\n",
    "        save = Path(save)\n",
    "\n",
    "        if not os.path.exists(save):\n",
    "            os.makedirs(save)\n",
    "\n",
    "    for location, v in activations.items():\n",
    "        activation_slice = v[0]\n",
    "\n",
    "        if location.endswith(\"attention.attention\"):\n",
    "            q, k, v = separate_attention(v, num_heads=H, batch_size=B, head_size=E//H, num_tokens=T)\n",
    "            qk = q @ k.transpose(-2, -1)\n",
    "            q, k, qk, v = q[0], k[0], v[0], qk[0]\n",
    "            \n",
    "            fig, axs = plt.subplots(H, 4, figsize=(15, 15))\n",
    "\n",
    "            for j, (name, x) in enumerate(zip([\"Q\", \"K\", \"QK\", \"V\"], [q, k, qk, v])):\n",
    "                for h in range(H):\n",
    "                    ax = axs[h, j]\n",
    "                    im = ax.matshow(x[h].detach().to(\"cpu\").numpy())\n",
    "                    ax.set_title(f\"{h}.{name}\")\n",
    "                    # fig.colorbar(im, ax=ax)\n",
    "\n",
    "            plt.suptitle(location)\n",
    "            plt.tight_layout()\n",
    "\n",
    "            if save:\n",
    "                plt.savefig(save / (location + \".png\"))\n",
    "                plt.close(fig)\n",
    "\n",
    "                del fig\n",
    "                del axs\n",
    "\n",
    "        elif len(activation_slice.shape) == 2:\n",
    "            fig = plt.figure()\n",
    "\n",
    "            x, location = optionally_rotate(activation_slice, location)\n",
    "            plt.matshow(x.detach().to(\"cpu\").numpy())\n",
    "            plt.title(f\"{location}\")\n",
    "            # fig.colorbar(im)\n",
    "\n",
    "            if save:\n",
    "                plt.savefig(save / (location + \".png\"))\n",
    "                plt.close(fig)\n",
    "\n",
    "                del fig\n",
    "\n",
    "\n",
    "        elif len(activation_slice.shape) == 3:  # [heads, xs, ys]\n",
    "            heads, xs, ys = activation_slice.shape\n",
    "            fig, axs = plt.subplots(1, heads, figsize=(15, 15))\n",
    "\n",
    "            for j in range(heads):\n",
    "                ax = axs[j]\n",
    "                x, name = optionally_rotate(activation_slice[j], str(j))\n",
    "                im = ax.matshow(x.detach().to(\"cpu\").numpy())\n",
    "                ax.set_title(f\"{name}\")\n",
    "                # fig.colorbar(im, ax=ax)\n",
    "            \n",
    "            plt.suptitle(f\"{location}.#\")\n",
    "            plt.tight_layout()\n",
    "\n",
    "            if save:\n",
    "                plt.savefig(save / (location + \".png\"))\n",
    "                plt.close(fig)\n",
    "\n",
    "            del fig\n",
    "            del axs\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported number of dimensions.\")\n",
    "\n",
    "\n",
    "def compare_activations(config: ICLConfig, model, x: TensorType[\"B\", \"D\"], y: TensorType[\"B\", 1], save: Optional[str] = None, names: Optional[List[str]] = None):\n",
    "    B = len(x)\n",
    "    hooked_model = hook(model)\n",
    "\n",
    "    activations = {}\n",
    "    output, activations_ = hooked_model.run_with_cache(x, y)\n",
    "    activations[\"x\"] = x\n",
    "    activations[\"y\"] = y\n",
    "    activations[\"output\"] = output\n",
    "    activations.update(activations_)\n",
    "\n",
    "    def activations_per_sample(activations, index, keep_batch_dim=False):\n",
    "        if keep_batch_dim:\n",
    "            print({k: type(v) for k, v in activations.items()})\n",
    "            return {k: v[index].unsqueeze(0) for k, v in activations.items() if v is not None}\n",
    "        \n",
    "        return {k: v[index] for k, v in activations.items() if v is not None}\n",
    "\n",
    "    tmp_folder = Path(\"tmp\")\n",
    "\n",
    "    names = names or list(map(str, range(B)))\n",
    "\n",
    "    for (name, b) in zip(names, range(B)):\n",
    "        activations_b = activations_per_sample(activations, b, keep_batch_dim=True)\n",
    "        plot_activations(config, activations_b, save=tmp_folder / str(name))\n",
    "\n",
    "    gather_images_side_by_side(tmp_folder, save=save, delete=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = Run.create_and_restore(configs[2])\n",
    "compare_activations(demo.config, demo.model, demo.evaluator.pretrain_xs[:3], demo.evaluator.pretrain_ys[:3], save=FIGURES / \"demo\", names=[\"$x_0$\", \"$x_1$\", \"$x_2$\"])\n",
    "# gather_images_side_by_side(\"tmp\", save=FIGURES/\"demo\", delete=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a few samples for each model at the end of training\n",
    "from icl.train import Run\n",
    "\n",
    "NUM_SAMPLES = 4\n",
    "\n",
    "for config, checkpointer in zip(configs, checkpointers):\n",
    "    run = Run.create_and_restore(config)\n",
    "    \n",
    "    sample_names = [f\"$x_{i}$\" for i in range(NUM_SAMPLES)]\n",
    "    slug = \"activations-\" + run.config.to_slug(delimiter=\"-\")\n",
    "\n",
    "    compare_activations(\n",
    "        run.config, \n",
    "        run.model, \n",
    "        run.evaluator.pretrain_xs[:NUM_SAMPLES], \n",
    "        run.evaluator.pretrain_ys[:NUM_SAMPLES], \n",
    "        save=FIGURES / slug, \n",
    "        names=sample_names\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(checkpointer.file_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a few samples for a subset of models over training\n",
    "\n",
    "MS = [1, 4, 64, 2**10, 2**20]\n",
    "STEPS = [0, 1_805, 3_084, 15_381, 26_279, 100_262, 153_061, 193_877, 255_102, 306_122, 408_163]\n",
    "\n",
    "for m in MS:\n",
    "    log2_m = int(np.log2(m))\n",
    "    config, checkpointer = configs[log2_m], checkpointers[log2_m]\n",
    "    run = Run(config)\n",
    "\n",
    "    for step in STEPS:\n",
    "        run.model.load_state_dict(checkpointer.load_file(step)[\"model\"])\n",
    "\n",
    "        sample_names = [f\"$x_{i}$\" for i in range(NUM_SAMPLES)]\n",
    "        slug = \"activations-\" + run.config.to_slug(delimiter=\"-\") + f\"@t={step}\"\n",
    "\n",
    "        # TODO: Need to rename the new files otherwise you can't tell easily tell what step they come from.\n",
    "        compare_activations(\n",
    "            run.config, \n",
    "            run.model, \n",
    "            run.evaluator.pretrain_xs[:NUM_SAMPLES], \n",
    "            run.evaluator.pretrain_ys[:NUM_SAMPLES], \n",
    "            save=FIGURES / slug, \n",
    "            names=sample_names\n",
    "        )\n",
    "        \n",
    "        os.system('say \"Your program has finished.\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get it all on Wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
