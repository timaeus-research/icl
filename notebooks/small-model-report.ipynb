{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small-model report\n",
    "\n",
    "On the small model (L=2, H=4):\n",
    "\n",
    "- Replication of Raventós et al. (2023) + fitting the various algorithms\n",
    "- All the analyses (RLCT, PCA, Attention Entropies, Covariance, Weight-staring). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "if not \"AWS_ACCESS_KEY_ID\" in os.environ or not \"AWS_SECRET_ACCESS_KEY\" in os.environ:\n",
    "    raise Exception(\"AWS_ACCESS_KEY_ID or AWS_SECRET_ACCESS_KEY not found in environment variables. Please set them in .env file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/Projects/icl/.venv/lib/python3.9/site-packages/pydantic/_internal/_fields.py:127: UserWarning: Field \"model_seed\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pp\n",
    "from pathlib import Path\n",
    "from typing import Optional, Iterable, List, Tuple, Dict, Union, Callable\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch \n",
    "from torch import nn\n",
    "\n",
    "import devinterp\n",
    "import devinfra\n",
    "\n",
    "from icl.analysis.utils import get_unique_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "SWEEP_ID = \"6g954fkg\"\n",
    "SWEEP_FILENAME = \"small-sweep-2.yaml\"\n",
    "FIGURES=Path(\"../figures\")\n",
    "ANALYSIS = Path(\"../analysis\")\n",
    "\n",
    "DEVICE = devinfra.utils.device.get_default_device()\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 21 runs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/Projects/devinfra/devinfra/utils/iterables.py:29: UserWarning: Number of steps in int_logspace is not 100, got 91.\n",
      "  warnings.warn(\n",
      "/home/paperspace/Projects/devinfra/devinfra/utils/iterables.py:29: UserWarning: Number of steps in int_logspace is not 50, got 47.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from icl.analysis.utils import get_sweep_configs\n",
    "\n",
    "filters = {\"task_config\": {\"num_layers\": 2, \"num_heads\": 4}, \"optimizer_config\": {\"lr\": 0.01}}  # TODO: Where are the H=2 runs?\n",
    "configs = list(get_sweep_configs(f\"../sweeps/{SWEEP_FILENAME}\", **filters))\n",
    "\n",
    "print(f\"Found {len(configs)} runs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading checkpoints: 100%|██████████| 21/21 [00:08<00:00,  2.44it/s]\n",
      "Loading checkpoints: 100%|██████████| 21/21 [00:00<00:00, 20128.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 96 checkpoints for CompositeStorageProvider([S3StorageProvider(s3://devinterp/checkpoints/icl/ntasks-1-task-c19845-opt-aa689f-sched-1ee2ae)])\n",
      "Found 96 checkpoints for CompositeStorageProvider([S3StorageProvider(s3://devinterp/checkpoints/icl/ntasks-2-task-7ed30b-opt-aa689f-sched-1ee2ae)])\n",
      "Found 96 checkpoints for CompositeStorageProvider([S3StorageProvider(s3://devinterp/checkpoints/icl/ntasks-4-task-871f4f-opt-aa689f-sched-1ee2ae)])\n",
      "Found 96 checkpoints for CompositeStorageProvider([S3StorageProvider(s3://devinterp/checkpoints/icl/ntasks-8-task-6d414c-opt-aa689f-sched-1ee2ae)])\n",
      "Found 96 checkpoints for CompositeStorageProvider([S3StorageProvider(s3://devinterp/checkpoints/icl/ntasks-16-task-fef7aa-opt-aa689f-sched-1ee2ae)])\n",
      "Found 96 checkpoints for CompositeStorageProvider([S3StorageProvider(s3://devinterp/checkpoints/icl/ntasks-32-task-b02901-opt-aa689f-sched-1ee2ae)])\n",
      "Found 96 checkpoints for CompositeStorageProvider([S3StorageProvider(s3://devinterp/checkpoints/icl/ntasks-64-task-48d75c-opt-aa689f-sched-1ee2ae)])\n",
      "Found 96 checkpoints for CompositeStorageProvider([S3StorageProvider(s3://devinterp/checkpoints/icl/ntasks-128-task-6cc650-opt-aa689f-sched-1ee2ae)])\n",
      "Found 96 checkpoints for CompositeStorageProvider([S3StorageProvider(s3://devinterp/checkpoints/icl/ntasks-256-task-69174b-opt-aa689f-sched-1ee2ae)])\n",
      "Found 96 checkpoints for CompositeStorageProvider([S3StorageProvider(s3://devinterp/checkpoints/icl/ntasks-512-task-78b782-opt-aa689f-sched-1ee2ae)])\n",
      "Found 96 checkpoints for CompositeStorageProvider([S3StorageProvider(s3://devinterp/checkpoints/icl/ntasks-1024-task-0fcb82-opt-aa689f-sched-1ee2ae)])\n",
      "Found 96 checkpoints for CompositeStorageProvider([S3StorageProvider(s3://devinterp/checkpoints/icl/ntasks-2048-task-3c92ba-opt-aa689f-sched-1ee2ae)])\n",
      "Found 96 checkpoints for CompositeStorageProvider([S3StorageProvider(s3://devinterp/checkpoints/icl/ntasks-4096-task-f9810d-opt-aa689f-sched-1ee2ae)])\n",
      "Found 96 checkpoints for CompositeStorageProvider([S3StorageProvider(s3://devinterp/checkpoints/icl/ntasks-8192-task-77033f-opt-aa689f-sched-1ee2ae)])\n",
      "Found 96 checkpoints for CompositeStorageProvider([S3StorageProvider(s3://devinterp/checkpoints/icl/ntasks-16384-task-e30fe5-opt-aa689f-sched-1ee2ae)])\n",
      "Found 96 checkpoints for CompositeStorageProvider([S3StorageProvider(s3://devinterp/checkpoints/icl/ntasks-32768-task-13c862-opt-aa689f-sched-1ee2ae)])\n",
      "Found 96 checkpoints for CompositeStorageProvider([S3StorageProvider(s3://devinterp/checkpoints/icl/ntasks-65536-task-2dee6f-opt-aa689f-sched-1ee2ae)])\n",
      "Found 96 checkpoints for CompositeStorageProvider([S3StorageProvider(s3://devinterp/checkpoints/icl/ntasks-131072-task-40304c-opt-aa689f-sched-1ee2ae)])\n",
      "Found 96 checkpoints for CompositeStorageProvider([S3StorageProvider(s3://devinterp/checkpoints/icl/ntasks-262144-task-3abb88-opt-aa689f-sched-1ee2ae)])\n",
      "Found 96 checkpoints for CompositeStorageProvider([S3StorageProvider(s3://devinterp/checkpoints/icl/ntasks-524288-task-ec350d-opt-aa689f-sched-1ee2ae)])\n",
      "Found 96 checkpoints for CompositeStorageProvider([S3StorageProvider(s3://devinterp/checkpoints/icl/ntasks-1048576-task-faf506-opt-aa689f-sched-1ee2ae)])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Figure out which checkpoints are available\n",
    "\n",
    "checkpointers = [config.checkpointer_config.factory() for config in tqdm(configs, desc=\"Reading checkpoints\")]\n",
    "\n",
    "for checkpointer in tqdm(checkpointers, desc=\"Loading checkpoints\"):\n",
    "    print(f\"Found {len(checkpointer.file_ids)} checkpoints for {checkpointer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replication "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 21 runs.\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "from devinfra.utils.iterables import filter_objs\n",
    "\n",
    "api= wandb.Api()\n",
    "sweep = api.sweep(f\"devinterp/icl/{SWEEP_ID}\")\n",
    "runs = list(filter_objs([r for r in sweep.runs], config=filters))\n",
    "\n",
    "print(f\"Found {len(runs)} runs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from devinfra.utils.iterables import flatten_dict\n",
    "from icl.analysis.utils import wandb_runs_to_df\n",
    "\n",
    "df = wandb_runs_to_df(runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp(list(df.columns))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recreate_fig_2(df, title=\"\"):\n",
    "    # Create a 2x3 grid of subplots\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "    # Set title\n",
    "\n",
    "    # Set common labels\n",
    "    fig.text(0.08, 0.5, r'$\\mathcal{T}_\\mathrm{Pretrain}$', va='center', rotation='vertical', fontsize=14)\n",
    "    fig.text(0.08, 0.26, r'$\\mathcal{T}_\\mathrm{True}$', va='center', rotation='vertical', fontsize=14)\n",
    "\n",
    "    grouped_by_num_tasks = df.groupby('task_config/num_tasks')\n",
    "\n",
    "    # Within each group, find the row with the last step\n",
    "    last_rows = grouped_by_num_tasks.apply(lambda g: g[g._step == g._step.max() & g[\"pretrain/mse\"].notna()])\n",
    "\n",
    "    # Ungroup\n",
    "    last_rows = last_rows.reset_index(drop=True)\n",
    "    print(last_rows)\n",
    "\n",
    "    # Top row\n",
    "    sns.lineplot(x='task_config/num_tasks', y='pretrain/mse', data=last_rows, ax=axs[0, 0], hue='_step')\n",
    "    sns.lineplot(x='task_config/num_tasks', y='pretrain/delta_dmmse', data=last_rows, ax=axs[0, 1], hue='_step')\n",
    "    sns.lineplot(x='task_config/num_tasks', y='pretrain/delta_ridge', data=last_rows, ax=axs[0, 2], hue='_step')\n",
    "\n",
    "    # Bottom row\n",
    "    sns.lineplot(x='task_config/num_tasks', y='true/mse', data=last_rows, ax=axs[1, 0], hue='_step')\n",
    "    sns.lineplot(x='task_config/num_tasks', y='true/delta_dmmse', data=last_rows, ax=axs[1, 1], hue='_step')\n",
    "    sns.lineplot(x='task_config/num_tasks', y='true/delta_ridge', data=last_rows, ax=axs[1, 2], hue='_step')\n",
    "\n",
    "    # Y-labels for first column\n",
    "    axs[0, 0].set_ylabel('MSE')\n",
    "    axs[1, 0].set_ylabel('MSE')\n",
    "\n",
    "    # Y-labels for second column\n",
    "    axs[0, 1].set_ylabel(r'$\\Delta_\\mathrm{PT dMMSE}$')\n",
    "    axs[1, 1].set_ylabel(r'$\\Delta_\\mathrm{PT dMMSE}$')\n",
    "\n",
    "    # Y-labels for third column\n",
    "    axs[0, 2].set_ylabel(r'$\\Delta_\\mathrm{PT Ridge}$')\n",
    "    axs[1, 2].set_ylabel(r'$\\Delta_\\mathrm{PT Ridge}$')\n",
    "\n",
    "    for i in range(3):\n",
    "        axs[1, i].set_xlabel(\"# Pretraining Tasks\")\n",
    "\n",
    "    for ax in axs.flat:\n",
    "        ax.set_xscale(\"log\")\n",
    "\n",
    "    # Hide x-labels for the top row\n",
    "    for ax in axs[0, :]:\n",
    "        ax.set_xlabel('')\n",
    "\n",
    "    plt.tight_layout(rect=[0.1, 0.1, 1, 1])\n",
    "    plt.show()\n",
    "\n",
    "def recreate_fig_2_over_time(df, title=\"\"):\n",
    "    # Create a 2x3 grid of subplots\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "    # Set title\n",
    "    plt.suptitle(title)\n",
    "\n",
    "    # Set common labels\n",
    "    fig.text(0.08, 0.5, r'$\\mathcal{T}_\\mathrm{Pretrain}$', va='center', rotation='vertical', fontsize=14)\n",
    "    fig.text(0.08, 0.26, r'$\\mathcal{T}_\\mathrm{True}$', va='center', rotation='vertical', fontsize=14)\n",
    "\n",
    "    cmap = sns.color_palette(\"viridis\", as_cmap=True)\n",
    "\n",
    "    # Top row\n",
    "    sns.scatterplot(x='task_config/num_tasks', y='pretrain/mse', data=df, ax=axs[0, 0], hue='_step', palette=cmap)\n",
    "    sns.scatterplot(x='task_config/num_tasks', y='pretrain/delta_dmmse', data=df, ax=axs[0, 1], hue='_step', palette=cmap)\n",
    "    sns.scatterplot(x='task_config/num_tasks', y='pretrain/delta_ridge', data=df, ax=axs[0, 2], hue='_step', palette=cmap)\n",
    "\n",
    "    # Bottom row\n",
    "    sns.scatterplot(x='task_config/num_tasks', y='true/mse', data=df, ax=axs[1, 0], hue='_step', palette=cmap)\n",
    "    sns.scatterplot(x='task_config/num_tasks', y='true/delta_dmmse', data=df, ax=axs[1, 1], hue='_step', palette=cmap)\n",
    "    sns.scatterplot(x='task_config/num_tasks', y='true/delta_ridge', data=df, ax=axs[1, 2], hue='_step', palette=cmap)\n",
    "\n",
    "    # Y-labels for first column\n",
    "    axs[0, 0].set_ylabel('MSE')\n",
    "    axs[1, 0].set_ylabel('MSE')\n",
    "\n",
    "    # Y-labels for second column\n",
    "    axs[0, 1].set_ylabel(r'$\\Delta_\\mathrm{PT dMMSE}$')\n",
    "    axs[1, 1].set_ylabel(r'$\\Delta_\\mathrm{PT dMMSE}$')\n",
    "\n",
    "    # Y-labels for third column\n",
    "    axs[0, 2].set_ylabel(r'$\\Delta_\\mathrm{PT Ridge}$')\n",
    "    axs[1, 2].set_ylabel(r'$\\Delta_\\mathrm{PT Ridge}$')\n",
    "\n",
    "    for i in range(3):\n",
    "        axs[1, i].set_xlabel(\"# Pretraining Tasks\")\n",
    "\n",
    "    for ax in axs.flat:\n",
    "        ax.set_xscale(\"log\")\n",
    "\n",
    "    # Hide x-labels for the top row\n",
    "    for ax in axs[0, :]:\n",
    "        ax.set_xlabel('')\n",
    "\n",
    "    plt.tight_layout(rect=[0.1, 0.1, 1, 1])\n",
    "    plt.show()\n",
    "\n",
    "# TODO: Add baselines (also make comparisons for other hyperparameters besides batch_size). \n",
    "# recreate_fig_2_over_time(df, title=\"Over training\")\n",
    "# recreate_fig_2(df, title=\"At the end\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raise NotImplementedError(\"TODO: Fit noise terms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_enumerated_models(model, checkpointer, verbose=False):\n",
    "    for file_id in tqdm(checkpointer.file_ids, desc=\"Iterating over checkpoints\", disable=not verbose):\n",
    "        model.load_state_dict(checkpointer.load_file(file_id)[\"model\"])\n",
    "        yield file_id, model\n",
    "\n",
    "def iter_models(model, checkpointer, verbose=False):\n",
    "    for file_id in tqdm(checkpointer.file_ids, desc=\"Iterating over checkpoints\", disable=not verbose):\n",
    "        model.load_state_dict(checkpointer.load_file(file_id)[\"model\"])\n",
    "        yield model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Iterable, Tuple\n",
    "from sklearn.decomposition import PCA\n",
    "from collections import defaultdict\n",
    "from devinterp.mechinterp.hooks import hook\n",
    "import numpy as np\n",
    "from icl.analysis.utils import map_evals_over_checkpoints, get_unique_run\n",
    "from icl.train import Run\n",
    "from devinfra.utils.tensors import convert_tensor, ReturnTensor\n",
    "\n",
    "\n",
    "def extract_activations_over_checkpoints(models: Iterable[nn.Module], xs, ys, *paths, return_type: ReturnTensor=\"np\"):\n",
    "    def eval_activations(model):\n",
    "        hooked_model = hook(model, *paths)\n",
    "        return {k: convert_tensor(v, return_type) for k, v in hooked_model.run_with_cache(xs, ys)[1].items() if k in paths and v is not None}\n",
    "    \n",
    "    for model in models:\n",
    "        yield eval_activations(model)\n",
    "\n",
    "\n",
    "def get_vectorized_activations_trace(models: Iterable[nn.Module], xs, ys, *paths):\n",
    "    evals: Dict[str, list] = defaultdict(list)\n",
    "    \n",
    "    for activations in extract_activations_over_checkpoints(models, xs, ys, *paths):\n",
    "        for path, activation in activations.items():\n",
    "            evals[path].append(activation)\n",
    "\n",
    "    return {\n",
    "        k: np.array(v).reshape(len(v), -1) for k, v in evals.items()\n",
    "    }\n",
    "\n",
    "\n",
    "def get_pca_activations_trace(models: Iterable[nn.Module], xs, ys, *paths, num_components=3) -> Dict[str, Tuple[PCA, np.ndarray]]:\n",
    "    results = {}\n",
    "\n",
    "    for path, activations in get_vectorized_activations_trace(models, xs, ys, *paths).items():\n",
    "        pca = PCA(n_components=num_components)\n",
    "        activations_reduced = pca.fit_transform(activations)\n",
    "        results[path] = pca, activations_reduced\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo = Run(configs[2])\n",
    "# demo_models = iter_models(demo.model, demo.checkpointer, verbose=True)\n",
    "\n",
    "# demo_logits_pca_3, demo_logits_reduced_3  = get_pca_activations_trace(\n",
    "#     demo_models, \n",
    "#     demo.evaluator.pretrain_xs, \n",
    "#     demo.evaluator.pretrain_ys, \n",
    "#     \"token_sequence_transformer\",\n",
    "#     num_components=3\n",
    "# )['token_sequence_transformer']\n",
    "\n",
    "# steps = demo.checkpointer.file_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "def plot_sample_evolution(steps, samples, title=\"Sample Evolution in 2D Plane\", num_points_to_label=10, save: Optional[str] = None, ax: Optional = None, connect_dots=False):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(15, 8))\n",
    "    \n",
    "    # Main plot\n",
    "    sc = ax.scatter(samples[:, 0], samples[:, 1], c=steps, cmap='viridis', s=50, alpha=0.6)\n",
    "\n",
    "    if connect_dots:\n",
    "        ax.plot(samples[:, 0], samples[:, 1], c='black', alpha=0.2)\n",
    "\n",
    "    plt.colorbar(sc, ax=ax, label='Steps')\n",
    "    \n",
    "    # Label some points\n",
    "    total_samples = len(samples)\n",
    "    step = total_samples // num_points_to_label\n",
    "    for i in range(0, total_samples, step):\n",
    "        sample_step = steps[i]\n",
    "        ax.text(samples[i, 0], samples[i, 1], str(sample_step), fontsize=12, ha='right', va='bottom')\n",
    "        \n",
    "    ax.set_xlabel('Feature 1')\n",
    "    ax.set_ylabel('Feature 2')\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    # Inset for explained variance at the bottom right corner with slight transparency\n",
    "    if save:\n",
    "        parent_dir = os.path.dirname(save)\n",
    "\n",
    "        if not os.path.exists(parent_dir):\n",
    "            os.makedirs(parent_dir)\n",
    "\n",
    "        plt.savefig(save)\n",
    "\n",
    "\n",
    "def plot_explained_variance(pca, title=\"Explained Variance\", ax: Optional[plt.Axes] = None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "    ax.bar(range(len(pca.explained_variance_ratio_)), pca.explained_variance_ratio_)\n",
    "\n",
    "    for i, ratio in enumerate(pca.explained_variance_ratio_):\n",
    "        ax.text(i, ratio, f\"{ratio:.2f}\", fontsize=12, ha='center', va='bottom')\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Component')\n",
    "    ax.set_ylabel('Variance')\n",
    "\n",
    "\n",
    "def plot_sample_evolution_with_inset(steps, samples, pca, title=\"Sample Evolution in 2D Plane\", num_points_to_label=10, save: Optional[str] = None, ax: Optional = None, connect_dots=False):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(15, 8))\n",
    "    \n",
    "    plot_sample_evolution(steps, samples, title=title, num_points_to_label=num_points_to_label, ax=ax, connect_dots=connect_dots)\n",
    "\n",
    "    axins = ax.inset_axes([0.7, 0.05, 0.25, 0.25])  # x, y, width, height\n",
    "    axins.patch.set_alpha(0.5)\n",
    "    plot_explained_variance(pca, ax=axins)\n",
    "    \n",
    "    # Inset for explained variance at the bottom right corner with slight transparency\n",
    "    if save:\n",
    "        parent_dir = os.path.dirname(save)\n",
    "\n",
    "        if not os.path.exists(parent_dir):\n",
    "            os.makedirs(parent_dir)\n",
    "\n",
    "        plt.savefig(save)\n",
    "\n",
    "    \n",
    "def plot_multiple_slices(steps, samples, pca, title=\"Sample Evolution in 2D Plane\", num_points_to_label=10, save: Optional[str] = None, ax: Optional = None, connect_dots=False):\n",
    "    num_pca_components = samples.shape[-1]\n",
    "    num_rows = num_pca_components - 1\n",
    "    fig, ax = plt.subplots(num_rows, num_rows, figsize=(20, 20))\n",
    "\n",
    "    fig.suptitle(title)\n",
    "\n",
    "    for i in range(num_pca_components):\n",
    "        for j in range(i):\n",
    "            sc = ax[i-1, j].scatter(samples[:, i], samples[:, j], c=steps, cmap='viridis', s=50, alpha=0.6)\n",
    "            ax[i-1, j].set_xlabel(f'Feature {i}')\n",
    "            ax[i-1, j].set_ylabel(f'Feature {j}')\n",
    "            ax[i-1, j].set_title(f'Feature {i} vs Feature {j}')\n",
    "\n",
    "            if connect_dots:\n",
    "                ax[i-1, j].plot(samples[:, i], samples[:, j], c='black', alpha=0.2)\n",
    "\n",
    "            # Label some points\n",
    "            total_samples = len(samples)\n",
    "            step = total_samples // num_points_to_label\n",
    "            for k in range(0, total_samples, step):\n",
    "                sample_step = steps[k]\n",
    "                ax[i-1, j].text(samples[k, i], samples[k, j], str(sample_step), fontsize=12, ha='right', va='bottom')\n",
    "\n",
    "        for j in range(i + 1, num_rows):\n",
    "            ax[i, j].axis('off')\n",
    "\n",
    "\n",
    "    ax[0, -1].axis('on')\n",
    "    plot_explained_variance(pca, ax=ax[0, -1])\n",
    "\n",
    "    plt.colorbar(sc, ax=ax[0, -1], label='Steps')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save:\n",
    "        parent_dir = os.path.dirname(save)\n",
    "\n",
    "        if not os.path.exists(parent_dir):\n",
    "            os.makedirs(parent_dir)\n",
    "\n",
    "        plt.savefig(save)\n",
    "\n",
    "# plot_multiple_slices(steps, demo_logits_reduced_3, demo_logits_pca_3, title=demo.config.to_latex(), connect_dots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for config, checkpointer in zip(configs, checkpointers):\n",
    "    run = Run(config)\n",
    "    _steps = checkpointer.file_ids\n",
    "\n",
    "    _pca, _logits_reduced = get_pca_activations_trace(\n",
    "        iter_models(run.model, run.checkpointer, verbose=True), \n",
    "        run.evaluator.pretrain_xs, \n",
    "        run.evaluator.pretrain_ys, \n",
    "        \"token_sequence_transformer\",\n",
    "        num_components=3\n",
    "    )['token_sequence_transformer']\n",
    "    \n",
    "    plot_multiple_slices(\n",
    "        _steps, \n",
    "        _logits_reduced, \n",
    "        _pca, \n",
    "        connect_dots=True, \n",
    "        title=config.to_latex(), \n",
    "        save=FIGURES / (\"pca3-logits-\" + config.to_slug(delimiter=\"-\") + \".png\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention Entropies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Union\n",
    "from torchtyping import TensorType\n",
    "from devinfra.utils.iterables import map_nested\n",
    "\n",
    "def compute_attention_entropies(attn: TensorType[\"B\", \"H\", \"2K\", \"2K\"]):\n",
    "    \"\"\"\n",
    "    Computes the entropy of each token in each head, averaged across the batch, \n",
    "    then averages this over heads. \n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # Threshold attention weights to avoid log(0)\n",
    "    log_attention = torch.where(attn > 0, torch.log(attn), torch.tensor(0.0).to(attn.device))\n",
    "    entropy_per_token = - torch.sum(attn * log_attention, dim=-1).mean(dim=0).squeeze(-1) # TensorType[\"H\", \"2K\"]\n",
    "\n",
    "    num_heads, num_tokens = entropy_per_token.shape\n",
    "\n",
    "    entropy_per_head = entropy_per_token.mean(dim=-1) # TensorType[\"H\"]\n",
    "    entropy = entropy_per_head.mean() # TensorType[]    \n",
    "    \n",
    "    # Each token computes entropy over a variable context length, so we normalize by the maximum possible entropy\n",
    "    # for a token with a fixed context length.\n",
    "\n",
    "    max_entropy_per_token = torch.log2(torch.arange(1, num_tokens + 1).to(attn.device)) # TensorType[\"H\", \"2K\"]\n",
    "    max_entropy_per_token[0] = 1. # Special case for the first token to avoid dividing by 0\n",
    "\n",
    "    entropy_per_token_normalized = entropy_per_token / max_entropy_per_token\n",
    "    entropy_per_head_normalized = entropy_per_token_normalized.mean(dim=-1) # TensorType[\"H\"]\n",
    "    entropy_normalized = entropy_per_head_normalized.mean() # TensorType[]    \n",
    "\n",
    "    results: Dict[str, Union[torch.Tensor, Dict[str, torch.Tensor]]] = {\"mean\": entropy, \"mean_normalized\": entropy_normalized}\n",
    "\n",
    "    for i in range(num_heads):\n",
    "        head_results = {\"mean\": entropy_per_head[i], \"mean_normalized\": entropy_per_head_normalized[i]}\n",
    "\n",
    "        for j in range(num_tokens):\n",
    "            head_results[f\"token_{j}\"] = entropy_per_token[i, j]\n",
    "            head_results[f\"token_{j}_normalized\"] = entropy_per_token_normalized[i, j]\n",
    "\n",
    "        results[f\"head_{i}\"] = head_results\n",
    "\n",
    "    return map_nested(lambda x: convert_tensor(x, \"np\"), results)\n",
    "\n",
    "\n",
    "def get_attention_entropies_trace(\n",
    "    steps: List[int],\n",
    "    models: Iterable[nn.Module],\n",
    "    xs: torch.Tensor,\n",
    "    ys: torch.Tensor,\n",
    "    **paths,\n",
    "):\n",
    "    results = defaultdict(list)\n",
    "    reverse_paths = {v: k for k, v in paths.items()}\n",
    "\n",
    "    for activations in extract_activations_over_checkpoints(models, xs, ys, *paths.values(), return_type=\"pt\"):\n",
    "        for k, v in activations.items():\n",
    "            path = reverse_paths[k]\n",
    "            results[path].append(compute_attention_entropies(v))\n",
    "\n",
    "    values = []\n",
    "\n",
    "    for i in range(len(steps)):\n",
    "        value = {}\n",
    "\n",
    "        for block in results.keys():\n",
    "            value[block] = results[block][i]\n",
    "        \n",
    "        value[\"step\"] = steps[i]\n",
    "        values.append(flatten_dict(value, flatten_lists=True))\n",
    "\n",
    "    return pd.DataFrame(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention_patterns(df: pd.DataFrame, num_blocks: int, num_heads: int, num_tokens: int, title=\"\", save: Optional[str] = None, normalized=False, figsize=(20, 25), logx=False, logy=False):\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    plt.suptitle(title)\n",
    "\n",
    "    num_cols = num_blocks * 2\n",
    "    num_rows = 1 + 1 + num_heads\n",
    "\n",
    "    suffix = \"\" if not normalized else \"_normalized\"\n",
    "    suffix_title = \"\" if not normalized else \" (Normalized)\"\n",
    "\n",
    "    # Create subplot for mean entropy of first two blocks\n",
    "    ax0 = plt.subplot2grid((num_rows, num_cols), (0, 0), colspan=num_cols)\n",
    "    block_cmap = sns.color_palette(\"viridis\", num_blocks)\n",
    "\n",
    "    for b in range(num_blocks):\n",
    "        ax0.plot(df.step, df[f\"block_{b}/mean{suffix}\"], label=f\"block_{b}\", color=block_cmap[b])\n",
    "\n",
    "    ax0.set_title(\"Blocks\")\n",
    "    ax0.set_xlabel(\"Step\")\n",
    "    ax0.set_ylabel(f\"Entropy{suffix_title}\")\n",
    "    ax0.legend()\n",
    "\n",
    "    # Create subplots for each block, showing entropy in different heads\n",
    "    ax1 = [plt.subplot2grid((num_rows, num_cols), (1, i*2), colspan=2) for i in range(num_blocks)]\n",
    "    head_cmap = sns.color_palette(\"viridis\", num_heads)\n",
    "    \n",
    "    for b in range(num_blocks):\n",
    "        ax1[b].set_title(f\"Block {b}\")\n",
    "        ax1[b].set_xlabel(\"Step\")\n",
    "        ax1[b].set_ylabel(f\"Entropy{suffix_title}\")\n",
    "        for h in range(num_heads):\n",
    "            series = df[f\"block_{b}/head_{h}/mean{suffix}\"]\n",
    "            ax1[b].plot(df.step, series, label=f\"Head {h}\", color=head_cmap[h])\n",
    "\n",
    "    ax1[0].legend()\n",
    "\n",
    "    # Create subplots for each head in each block, detailing entropy for each token\n",
    "    ax2 = [plt.subplot2grid((num_rows, num_cols), (i//(num_cols) + 2, i%(num_cols))) for i in range(num_heads * num_blocks * 2)]\n",
    "    ax_idx = 0\n",
    "    token_cmap = sns.color_palette(\"viridis\", num_tokens)\n",
    "\n",
    "\n",
    "    for h in range(num_heads):\n",
    "        for b in range(num_blocks):\n",
    "            for x_or_y in (1, 0):\n",
    "                ax2[ax_idx].set_title(f\"Block {b} Head {h}\")\n",
    "                ax2[ax_idx].set_xlabel(\"Step\")\n",
    "                ax2[ax_idx].set_ylabel(f\"Entropy{suffix_title}\")\n",
    "\n",
    "                for t in range(1-int(x_or_y), num_tokens, 2):\n",
    "                    series = df[f\"block_{b}/head_{h}/token_{t}{suffix}\"]\n",
    "                    ax2[ax_idx].plot(df.step, series, label=f\"Token {t}\", color=token_cmap[t])\n",
    "                    \n",
    "                ax_idx += 1\n",
    "\n",
    "    ax2[0].legend()\n",
    "    ax2[1].legend()\n",
    "\n",
    "    for ax in [ax0, *ax1, *ax2]:\n",
    "        if logx:\n",
    "            ax.set_xscale(\"log\")\n",
    "        if logy:\n",
    "            ax.set_yscale(\"log\")\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "    if save:\n",
    "        parent_dir = os.path.dirname(save)\n",
    "        if not os.path.exists(parent_dir):\n",
    "            os.makedirs(parent_dir)\n",
    "        plt.savefig(save)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = Run(configs[2])\n",
    "\n",
    "num_blocks = demo.config.task_config.num_layers\n",
    "num_heads = demo.config.task_config.num_heads\n",
    "num_tokens = demo.config.task_config.max_examples\n",
    "\n",
    "df = get_attention_entropies_trace(\n",
    "    demo.checkpointer.file_ids,\n",
    "    iter_models(demo.model, demo.checkpointer, verbose=True), \n",
    "    demo.evaluator.pretrain_xs, \n",
    "    demo.evaluator.pretrain_ys, \n",
    "    **{f\"block_{b}\": f\"token_sequence_transformer.blocks.{b}.attention.attention_softmax\" for b in range(num_blocks)}\n",
    ")\n",
    "\n",
    "demo_attn_entropy_slug = \"attn-S-\" + demo.config.to_slug(delimiter=\"-\")\n",
    "\n",
    "for normalized in (True, False):\n",
    "    plot_attention_patterns(\n",
    "        df, \n",
    "        num_blocks=num_blocks, \n",
    "        num_heads=num_heads, \n",
    "        num_tokens=num_tokens, \n",
    "        title=demo.config.to_latex(), \n",
    "        save=FIGURES / (demo_attn_entropy_slug + \".png\"),\n",
    "        figsize=(25, 25),\n",
    "        normalized=normalized\n",
    "    )\n",
    "\n",
    "# df.to_csv(ANALYSIS / (demo_attn_entropy_slug + \".csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for config, checkpointer in zip(configs, checkpointers):\n",
    "    run = Run(config)\n",
    "    \n",
    "    num_blocks = run.config.task_config.num_layers\n",
    "    num_heads = run.config.task_config.num_heads\n",
    "    num_tokens = run.config.task_config.max_examples\n",
    "\n",
    "    df = get_attention_entropies_trace(\n",
    "        checkpointer.file_ids,\n",
    "        iter_models(run.model, checkpointer, verbose=True), \n",
    "        run.evaluator.pretrain_xs, \n",
    "        run.evaluator.pretrain_ys, \n",
    "        **{f\"block_{b}\": f\"token_sequence_transformer.blocks.{b}.attention.attention_softmax\" for b in range(num_blocks)}\n",
    "    )\n",
    "    \n",
    "    slug = \"attn-S-\" + run.config.to_slug(delimiter=\"-\")\n",
    "\n",
    "    plot_attention_patterns(\n",
    "        df, \n",
    "        num_blocks=num_blocks, \n",
    "        num_heads=num_heads, \n",
    "        num_tokens=num_tokens, \n",
    "        title=run.config.to_latex(), \n",
    "        save=FIGURES / (slug + \".png\"),\n",
    "        figsize=(25, 25),\n",
    "        normalized=True\n",
    "    )\n",
    "\n",
    "    df.to_csv(ANALYSIS / (slug + \".csv\"))\n",
    "\n",
    "os.system('say \"Your program has finished.\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RLCTs & Covariance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([192, 64])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from icl.train import Run\n",
    "demo = Run(configs[2])\n",
    "attn_weights = demo.model.token_sequence_transformer.blocks[0].attention.attention.weight\n",
    "attn_weights.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "L2H2\n",
      "Full: 603,979,776 (2.42 Gb)\n",
      "Within heads: 150,994,944 (0.60 Gb)\n",
      "Between heads: 150,994,944 (0.60 Gb)\n",
      "Reduction: -301,989,888 (-50.00%)\n",
      "\n",
      "L2H4\n",
      "Full: 603,979,776 (2.42 Gb)\n",
      "Within heads: 75,497,472 (0.30 Gb)\n",
      "Between heads: 150,994,944 (0.60 Gb)\n",
      "Reduction: -377,487,360 (-62.50%)\n",
      "\n",
      "L4H2\n",
      "Full: 2,415,919,104 (9.66 Gb)\n",
      "Within heads: 301,989,888 (1.21 Gb)\n",
      "Between heads: 452,984,832 (1.81 Gb)\n",
      "Reduction: -1,660,944,384 (-68.75%)\n",
      "\n",
      "L4H4\n",
      "Full: 2,415,919,104 (9.66 Gb)\n",
      "Within heads: 150,994,944 (0.60 Gb)\n",
      "Between heads: 452,984,832 (1.81 Gb)\n",
      "Reduction: -1,811,939,328 (-75.00%)\n",
      "\n",
      "L8H2\n",
      "Full: 9,663,676,416 (38.65 Gb)\n",
      "Within heads: 603,979,776 (2.42 Gb)\n",
      "Between heads: 1,056,964,608 (4.23 Gb)\n",
      "Reduction: -8,002,732,032 (-82.81%)\n",
      "\n",
      "L8H4\n",
      "Full: 9,663,676,416 (38.65 Gb)\n",
      "Within heads: 301,989,888 (1.21 Gb)\n",
      "Between heads: 1,056,964,608 (4.23 Gb)\n",
      "Reduction: -8,304,721,920 (-85.94%)\n"
     ]
    }
   ],
   "source": [
    "numel_per_layer = attn_weights.numel()\n",
    "\n",
    "def num_params_to_gb(num: int):\n",
    "    return f\"{num * (32 / 8) / (10 ** 9):.2f} Gb\"\n",
    "\n",
    "for num_blocks in [2, 4, 8]:\n",
    "    for num_heads in [2, 4]:\n",
    "        numel_per_head = numel_per_layer // num_heads\n",
    "\n",
    "        within_head_cov_size = (numel_per_head ** 2)  * num_heads * num_blocks\n",
    "        between_head_cov_size = (numel_per_head ** 2) * num_heads * num_heads * (num_blocks-1)\n",
    "\n",
    "        full_cov_size = (numel_per_layer * num_blocks) ** 2\n",
    "\n",
    "        reduction = full_cov_size - within_head_cov_size - between_head_cov_size\n",
    "\n",
    "        print(f\"\\nL{num_blocks}H{num_heads}\")\n",
    "        print(\"Full:\", f\"{full_cov_size:,} ({num_params_to_gb(full_cov_size)})\")\n",
    "        print(\"Within heads:\", f\"{within_head_cov_size:,} ({num_params_to_gb(within_head_cov_size)})\")\n",
    "        print(\"Between heads:\", f\"{between_head_cov_size:,} ({num_params_to_gb(between_head_cov_size)})\")\n",
    "        print(\"Reduction:\", f\"-{reduction:,} (-{reduction/full_cov_size * 100:.2f}%)\")\n",
    "\n",
    "# attn_weights.numel(), f\"{(32 // 8 * (attn_weights.numel() * 2 ) ** 2):,}\", attn_weights.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_attn_weights(W: torch.Tensor, num_heads: int, embed_dim: int, head_size: int):\n",
    "    W_split = W.view((embed_dim, num_heads, head_size * 3))\n",
    "    \n",
    "    for h in range(num_heads):\n",
    "        yield tuple(W_split[:, h, i*head_size:(i+1)*head_size] for i in range(3))\n",
    "\n",
    "\n",
    "def plot_attn_weights(W: torch.Tensor, num_heads: int, embed_dim: int, head_size: int, subtitles=(\"$W_Q^{(h)}$\", \"$W_K^{(h)}$\", \"$W_V^{(h)}$\"), title=\"\", save: Optional[str] = None):\n",
    "    heads = list(split_attn_weights(W, num_heads, embed_dim, head_size))\n",
    "\n",
    "    fig, axs = plt.subplots(num_heads, 3, figsize=(25, 10))\n",
    "    plt.suptitle(title)\n",
    "\n",
    "    for h, head in enumerate(heads):\n",
    "        axs[h, 0].set_ylabel(f\"Head {h}\\nHead Size\")\n",
    "\n",
    "        for i, mat in enumerate(head):\n",
    "            axs[h, i].matshow(mat.detach().cpu().numpy().T, cmap='viridis') \n",
    "\n",
    "    for i, subtitle in enumerate(subtitles):\n",
    "        axs[0, i].set_title(subtitle)\n",
    "        axs[-1, i].set_xlabel(\"Embedding Dimension\")\n",
    "\n",
    "    if save:\n",
    "        parent_dir = os.path.dirname(save)\n",
    "        if not os.path.exists(parent_dir):\n",
    "            os.makedirs(parent_dir)\n",
    "        plt.savefig(save)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_attn_head_weights(head: torch.Tensor, embed_dim, head_size: int, title=\"\", subtitles=(\"$W_Q$\", \"$W_K$\", \"$W_V$\"), save: Optional[str] = None):\n",
    "    head_Ex3c = head.view((embed_dim, head_size * 3))\n",
    "    q, k, v = tuple(head_Ex3c[:, i*head_size:(i+1)*head_size].detach().cpu().numpy() for i in range(3))\n",
    "\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(30, 3.5))\n",
    "    plt.suptitle(title)\n",
    "\n",
    "    for i, (mat, subtitle) in enumerate(zip((q, k, v), subtitles)):\n",
    "        ax[i].set_title(subtitle)\n",
    "        ax[i].matshow(mat.T, cmap='viridis')\n",
    "        ax[i].set_xlabel(\"Embedding Dimension\")\n",
    "        ax[i].set_ylabel(\"Head Size\")\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "    if save:\n",
    "        parent_dir = os.path.dirname(save)\n",
    "        if not os.path.exists(parent_dir):\n",
    "            os.makedirs(parent_dir)\n",
    "        plt.savefig(save)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attn_eigencomponents(evecs, evals, slug: Optional[str] = None):\n",
    "    for i in range(1, 1 + len(evals)):\n",
    "        attn0, attn1 = evecs[:evecs.shape[0]//2, -i], evecs[evecs.shape[0]//2:, -i]\n",
    "\n",
    "        for layer, attn in enumerate((attn0, attn1)):\n",
    "            plot_attn_weights(\n",
    "                torch.Tensor(attn), \n",
    "                num_heads=4,\n",
    "                embed_dim=64, \n",
    "                head_size=16, \n",
    "                title=f\"Eigenvector {i-1} of covariance matrix within attention layer 0 ($\\lambda_{i-1}={evals[-i]}$)\",\n",
    "                subtitles=(f\"$u_{{Q,{i-1}}}^{{({layer})}}$\", f\"$u_{{K,{i-1}}}^{{({layer})}}$\", f\"$u_{{V,{i-1}}}^{{({layer})}}$\"),\n",
    "                save=(FIGURES / (f\"cov-attn{layer}-evec{i-1}-\" + slug + \".png\") if slug else None)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'attn0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb Cell 31\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bpaperspace/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m plot_attn_weights(attn0, \u001b[39m4\u001b[39m, \u001b[39m64\u001b[39m, \u001b[39m16\u001b[39m, title\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAttention layer 0\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpaperspace/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m num_heads \u001b[39m=\u001b[39m \u001b[39m4\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpaperspace/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m attn0_view \u001b[39m=\u001b[39m attn0\u001b[39m.\u001b[39mview((\u001b[39m64\u001b[39m, num_heads, \u001b[39m16\u001b[39m \u001b[39m*\u001b[39m \u001b[39m3\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'attn0' is not defined"
     ]
    }
   ],
   "source": [
    "plot_attn_weights(attn0, 4, 64, 16, title=\"Attention layer 0\")\n",
    "\n",
    "num_heads = 4\n",
    "attn0_view = attn0.view((64, num_heads, 16 * 3))\n",
    "heads = [attn0_view[:, h, :] for h in range(num_heads)]\n",
    "full_head_size = 16 * 3 * 64\n",
    "pseudo_cov = heads[0].reshape((full_head_size, 1)) * heads[1].reshape((1, full_head_size)) \n",
    "head_evals, head_evecs = eigsh(pseudo_cov.detach().cpu().numpy(), k=3, which=\"LM\")\n",
    "del pseudo_cov\n",
    "\n",
    "\n",
    "print(head_evals)\n",
    "plot_attn_head_weights(\n",
    "    torch.Tensor(head_evecs[:, -1]), \n",
    "    64, \n",
    "    16, \n",
    "    title=\"Principal eigenvalue of covariance matrix within head 1\",\n",
    "    subtitles=(\"$u_{Q,1}^{(1)}$\", \"$u_{K,1}^{(1)}$\", \"$u_{V,1}^{(1)}$\")   \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../sweeps/small-sweep-2.yaml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb Cell 32\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bpaperspace/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39micl\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39manalysis\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mrlct\u001b[39;00m \u001b[39mimport\u001b[39;00m make_slt_evals\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpaperspace/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_slt_observables\u001b[39m(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpaperspace/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     steps: List[\u001b[39mint\u001b[39m],\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpaperspace/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     models: Iterable[nn\u001b[39m.\u001b[39mModule],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpaperspace/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpaperspace/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m ):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpaperspace/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     trainset \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mTensorDataset(xs, ys)\n",
      "File \u001b[0;32m~/Projects/icl/icl/analysis/rlct.py:150\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39micl\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39manalysis\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m get_sweep_configs\n\u001b[1;32m    149\u001b[0m filters \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mtask_config\u001b[39m\u001b[39m\"\u001b[39m: {\u001b[39m\"\u001b[39m\u001b[39mnum_layers\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m2\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mnum_heads\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m4\u001b[39m}, \u001b[39m\"\u001b[39m\u001b[39moptimizer_config\u001b[39m\u001b[39m\"\u001b[39m: {\u001b[39m\"\u001b[39m\u001b[39mlr\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m0.01\u001b[39m}}  \u001b[39m# TODO: Where are the H=2 runs?\u001b[39;00m\n\u001b[0;32m--> 150\u001b[0m configs \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(get_sweep_configs(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m../../sweeps/\u001b[39;49m\u001b[39m{\u001b[39;49;00mSWEEP_FILENAME\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfilters))\n\u001b[1;32m    152\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFound \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(configs)\u001b[39m}\u001b[39;00m\u001b[39m runs.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    154\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39micl\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39manalysis\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m get_sweep_configs\n",
      "File \u001b[0;32m~/Projects/icl/icl/analysis/utils.py:44\u001b[0m, in \u001b[0;36mget_sweep_configs\u001b[0;34m(sweep, **filters)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_sweep_configs\u001b[39m(sweep: \u001b[39mstr\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfilters):\n\u001b[1;32m     41\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[39m    Generate ICLConfigs for all runs in the specified sweep.\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m     \u001b[39mfor\u001b[39;00m sweep_config_dict \u001b[39min\u001b[39;00m filter_objs(generate_config_dicts_from_path(sweep), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfilters):\n\u001b[1;32m     45\u001b[0m         \u001b[39myield\u001b[39;00m get_config(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39msweep_config_dict)\n",
      "File \u001b[0;32m~/Projects/devinfra/devinfra/utils/iterables.py:223\u001b[0m, in \u001b[0;36mfilter_objs\u001b[0;34m(objs, **filters)\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 223\u001b[0m \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m objs:\n\u001b[1;32m    224\u001b[0m     \u001b[39mif\u001b[39;00m match(obj, filters):\n\u001b[1;32m    225\u001b[0m         \u001b[39myield\u001b[39;00m obj\n",
      "File \u001b[0;32m~/Projects/devinfra/devinfra/integrations/wandb.py:9\u001b[0m, in \u001b[0;36mgenerate_config_dicts_from_path\u001b[0;34m(file_path, **kwargs)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_config_dicts_from_path\u001b[39m(file_path: \u001b[39mstr\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m      8\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Load the ICLConfigs for each of the runs defined in a wandb sweep config at the specified file path.\"\"\"\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(file_path, \u001b[39m\"\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m     10\u001b[0m         config \u001b[39m=\u001b[39m yaml\u001b[39m.\u001b[39msafe_load(f)\n\u001b[1;32m     12\u001b[0m     \u001b[39myield from\u001b[39;00m generate_config_dicts(config, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../sweeps/small-sweep-2.yaml'"
     ]
    }
   ],
   "source": [
    "from icl.analysis.rlct import make_slt_evals\n",
    "\n",
    "def generate_slt_observables(\n",
    "    steps: List[int],\n",
    "    models: Iterable[nn.Module],\n",
    "    xs: torch.Tensor,\n",
    "    ys: torch.Tensor,\n",
    "    **kwargs\n",
    "):\n",
    "    trainset = torch.utils.data.TensorDataset(xs, ys)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=len(xs))\n",
    "    slt_evals = make_slt_evals(\n",
    "        dataset=trainset,\n",
    "        loader=trainloader,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "    for step, model in zip(steps, models):\n",
    "        yield step, slt_evals(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 6, 8, 11, 14, 19, 24, 32, 42, 55, 72, 94, 124, 162, 211, 276, 362, 473, 618, 808, 1056, 1381, 1805, 2359, 3084, 4031, 5269, 6887, 9003, 10204, 11767, 15381, 20104, 20408, 26279, 30612, 34349, 40816, 44897, 51020, 58684, 61224, 71428, 76706, 81632, 91836, 100262, 102040, 112244, 122448, 131051, 132653, 142857, 153061, 163265, 171296, 173469, 183673, 193877, 204081, 214285, 223899, 224489, 234693, 244897, 255102, 265306, 275510, 285714, 292657, 295918, 306122, 316326, 326530, 336734, 346938, 357142, 367346, 377551, 382529, 387755, 397959, 408163, 418367, 428571, 438775, 448979, 459183, 469387, 479591, 489795, 499999]\n"
     ]
    }
   ],
   "source": [
    "print(checkpointer.file_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_coeff_over_time(steps, lcs, lc_stds, title=\"\", save: Optional[str] = None):\n",
    "\n",
    "    # Initialize the figure\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(18, 12))\n",
    "    ax.set_title(title)\n",
    "\n",
    "    # Plot mean values as a line\n",
    "    ax.plot(steps, lcs, 'o-', linewidth=2)\n",
    "    \n",
    "    # Add shaded area for error\n",
    "    ax.fill_between(steps, lcs - lc_stds, lcs + lc_stds, color='gray', alpha=0.4)\n",
    "\n",
    "    # Labels and scales\n",
    "    ax.set_xlabel(\"Steps\")\n",
    "    ax.set_ylabel(r\"$\\hat\\lambda$\")\n",
    "    \n",
    "    fig.tight_layout()\n",
    "\n",
    "    if save:\n",
    "        parent_dir = os.path.dirname(save)\n",
    "        if not os.path.exists(parent_dir):\n",
    "            os.makedirs(parent_dir)\n",
    "        plt.savefig(save)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_cov_evals_over_time(steps, *eval_traces, title=\"\", save: Optional[str] = None):\n",
    "\n",
    "    # Initialize the figure\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(18, 12))\n",
    "    ax.set_title(title)\n",
    "\n",
    "    # Plot mean values as a line\n",
    "    for i, eval_trace in enumerate(eval_traces):\n",
    "        ax.plot(steps, eval_trace, 'o-', label=f\"Eigenvalue {i}\", linewidth=2)\n",
    "    \n",
    "    # Labels and scales\n",
    "    ax.set_xlabel(\"Steps\")\n",
    "    ax.set_ylabel(r\"$\\hat\\lambda$\")\n",
    "    \n",
    "    # Show legend\n",
    "    ax.legend()\n",
    "\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    if save:\n",
    "        parent_dir = os.path.dirname(save)\n",
    "        if not os.path.exists(parent_dir):\n",
    "            os.makedirs(parent_dir)\n",
    "        plt.savefig(save)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:pxajy48t) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aa98a7cb16147dc93ef09196f19ba5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.117 MB of 0.117 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>chain_0</td><td>▁</td></tr><tr><td>chain_1</td><td>▁</td></tr><tr><td>chain_10</td><td>▁</td></tr><tr><td>chain_11</td><td>▁</td></tr><tr><td>chain_12</td><td>▁</td></tr><tr><td>chain_13</td><td>▁</td></tr><tr><td>chain_14</td><td>▁</td></tr><tr><td>chain_15</td><td>▁</td></tr><tr><td>chain_16</td><td>▁</td></tr><tr><td>chain_17</td><td>▁</td></tr><tr><td>chain_18</td><td>▁</td></tr><tr><td>chain_19</td><td>▁</td></tr><tr><td>chain_2</td><td>▁</td></tr><tr><td>chain_3</td><td>▁</td></tr><tr><td>chain_4</td><td>▁</td></tr><tr><td>chain_5</td><td>▁</td></tr><tr><td>chain_6</td><td>▁</td></tr><tr><td>chain_7</td><td>▁</td></tr><tr><td>chain_8</td><td>▁</td></tr><tr><td>chain_9</td><td>▁</td></tr><tr><td>cov-eval/0</td><td>▁</td></tr><tr><td>cov-eval/1</td><td>▁</td></tr><tr><td>mean</td><td>▁</td></tr><tr><td>std</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>chain_0</td><td>1.07733</td></tr><tr><td>chain_1</td><td>2.03227</td></tr><tr><td>chain_10</td><td>1.46087</td></tr><tr><td>chain_11</td><td>1.95004</td></tr><tr><td>chain_12</td><td>1.23002</td></tr><tr><td>chain_13</td><td>1.71757</td></tr><tr><td>chain_14</td><td>1.39526</td></tr><tr><td>chain_15</td><td>1.04182</td></tr><tr><td>chain_16</td><td>1.86334</td></tr><tr><td>chain_17</td><td>2.13917</td></tr><tr><td>chain_18</td><td>2.32092</td></tr><tr><td>chain_19</td><td>0.95966</td></tr><tr><td>chain_2</td><td>1.45406</td></tr><tr><td>chain_3</td><td>1.39109</td></tr><tr><td>chain_4</td><td>1.14815</td></tr><tr><td>chain_5</td><td>3.02908</td></tr><tr><td>chain_6</td><td>1.29418</td></tr><tr><td>chain_7</td><td>1.50094</td></tr><tr><td>chain_8</td><td>2.37642</td></tr><tr><td>chain_9</td><td>1.95417</td></tr><tr><td>cov-eval/0</td><td>145.72784</td></tr><tr><td>cov-eval/1</td><td>-3581832.75</td></tr><tr><td>mean</td><td>1.66682</td></tr><tr><td>std</td><td>0.53556</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">pious-dream-937</strong> at: <a href='https://wandb.ai/devinterp/icl/runs/pxajy48t' target=\"_blank\">https://wandb.ai/devinterp/icl/runs/pxajy48t</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231006_121442-pxajy48t/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:pxajy48t). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87fed831d2ad426b9dadb99abbe29fb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01667133413332825, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.12 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/paperspace/Projects/icl/notebooks/wandb/run-20231006_121737-o1m8jj4l</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/devinterp/icl/runs/o1m8jj4l' target=\"_blank\">volcanic-dream-938</a></strong> to <a href='https://wandb.ai/devinterp/icl' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/devinterp/icl' target=\"_blank\">https://wandb.ai/devinterp/icl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/devinterp/icl/runs/o1m8jj4l' target=\"_blank\">https://wandb.ai/devinterp/icl/runs/o1m8jj4l</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb Cell 36\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpaperspace/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb#X50sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m min_step \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpaperspace/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb#X50sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(ANALYSIS \u001b[39m/\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcov-tmp-\u001b[39m\u001b[39m{\u001b[39;00mslug\u001b[39m}\u001b[39;00m\u001b[39m.pt\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bpaperspace/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb#X50sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m     min_step, observables \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(ANALYSIS \u001b[39m/\u001b[39;49m \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcov-tmp-\u001b[39;49m\u001b[39m{\u001b[39;49;00mslug\u001b[39m}\u001b[39;49;00m\u001b[39m.pt\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpaperspace/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb#X50sdnNjb2RlLXJlbW90ZQ%3D%3D?line=44'>45</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLoaded observables from previous step \u001b[39m\u001b[39m{\u001b[39;00mmin_step\u001b[39m}\u001b[39;00m\u001b[39m from \u001b[39m\u001b[39m{\u001b[39;00mANALYSIS\u001b[39m \u001b[39m\u001b[39m/\u001b[39m\u001b[39m \u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcov-tmp-\u001b[39m\u001b[39m{\u001b[39;00mslug\u001b[39m}\u001b[39;00m\u001b[39m.pt\u001b[39m\u001b[39m'\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpaperspace/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb#X50sdnNjb2RlLXJlbW90ZQ%3D%3D?line=46'>47</a>\u001b[0m \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m STEPS:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpaperspace/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb#X50sdnNjb2RlLXJlbW90ZQ%3D%3D?line=47'>48</a>\u001b[0m     \u001b[39m# if step > min_step:\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpaperspace/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb#X50sdnNjb2RlLXJlbW90ZQ%3D%3D?line=48'>49</a>\u001b[0m     \u001b[39m#     run.model.load_state_dict(checkpointer.load_file(step)[\"model\"])\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpaperspace/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb#X50sdnNjb2RlLXJlbW90ZQ%3D%3D?line=49'>50</a>\u001b[0m     \u001b[39m#     observables = slt_evals(run.model)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpaperspace/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb#X50sdnNjb2RlLXJlbW90ZQ%3D%3D?line=50'>51</a>\u001b[0m     \u001b[39m#     torch.save((step, observables), ANALYSIS / f\"cov-tmp-{slug}.pt\")\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/icl/.venv/lib/python3.9/site-packages/torch/serialization.py:809\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    808\u001b[0m                 \u001b[39mraise\u001b[39;00m pickle\u001b[39m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(e)) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 809\u001b[0m         \u001b[39mreturn\u001b[39;00m _load(opened_zipfile, map_location, pickle_module, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpickle_load_args)\n\u001b[1;32m    810\u001b[0m \u001b[39mif\u001b[39;00m weights_only:\n\u001b[1;32m    811\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Projects/icl/.venv/lib/python3.9/site-packages/torch/serialization.py:1172\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1170\u001b[0m unpickler \u001b[39m=\u001b[39m UnpicklerWrapper(data_file, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1171\u001b[0m unpickler\u001b[39m.\u001b[39mpersistent_load \u001b[39m=\u001b[39m persistent_load\n\u001b[0;32m-> 1172\u001b[0m result \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39;49mload()\n\u001b[1;32m   1174\u001b[0m torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1176\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from scipy.sparse.linalg import eigsh\n",
    "\n",
    "\n",
    "MS = [config.task_config.num_tasks for config in configs] # [1, 4, 64, 2**10, 2**20]\n",
    "STEPS = checkpointer.file_ids\n",
    "K = 2\n",
    "\n",
    "for m in MS:\n",
    "    wandb.init(entity=\"devinterp\", project=\"icl\")\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    log2_m = int(np.log2(m))\n",
    "    config, checkpointer = configs[log2_m], checkpointers[log2_m]\n",
    "    run = Run(config)\n",
    "\n",
    "    xs, ys = run.evaluator.pretrain_xs, run.evaluator.pretrain_ys\n",
    "    trainset = torch.utils.data.TensorDataset(xs, ys)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=len(xs))\n",
    "    observables_over_time = []\n",
    "    \n",
    "    slt_evals = make_slt_evals(\n",
    "        dataset=trainset,\n",
    "        loader=trainloader,\n",
    "        cores=1,\n",
    "        lr=1e-5,\n",
    "        num_draws=100,\n",
    "        elasticity=1.,\n",
    "        num_chains=20,\n",
    "        device=\"cuda\",\n",
    "        covariance_paths=[\n",
    "            f\"token_sequence_transformer.blocks.{b}.attention.attention\"\n",
    "            for b in range(run.config.task_config.num_layers)\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    slug = run.config.to_slug(delimiter=\"-\")\n",
    "\n",
    "    min_step = -1\n",
    "\n",
    "    if os.path.exists(ANALYSIS / f\"cov-tmp-{slug}.pt\"):\n",
    "        min_step, observables = torch.load(ANALYSIS / f\"cov-tmp-{slug}.pt\")\n",
    "        print(f\"Loaded observables from previous step {min_step} from {ANALYSIS / f'cov-tmp-{slug}.pt'}\")\n",
    "    \n",
    "    for step in STEPS:\n",
    "        # if step > min_step:\n",
    "        run.model.load_state_dict(checkpointer.load_file(step)[\"model\"])\n",
    "        observables = slt_evals(run.model)\n",
    "        torch.save((step, observables), ANALYSIS / f\"cov-tmp-{slug}.pt\")\n",
    "\n",
    "        cov = observables.pop(\"covariance\")\n",
    "        evals, evecs = eigsh(cov, k=K, which='LM')\n",
    "\n",
    "        for i in range(1, 1+K):\n",
    "            observables[f\"cov-eval/{i-1}\"] = evals[-i]\n",
    "\n",
    "        observables_over_time.append(observables)\n",
    "        del cov\n",
    "        pp(observables)\n",
    "        plot_attn_eigencomponents(evecs, evals, slug=slug + f\"@t={step}\")\n",
    "\n",
    "    plot_cov_evals_over_time(\n",
    "        STEPS,\n",
    "        *[[o[f\"cov-eval/{k}\"] for o in observables_over_time] for k in K],\n",
    "        title=run.config.to_latex(),\n",
    "        save=FIGURES / f\"cov-eval-of-t-{slug}.png\"\n",
    "    )\n",
    "\n",
    "    plot_learning_coeff_over_time(\n",
    "        STEPS,\n",
    "        [o[\"mean\"] for o in observables_over_time],\n",
    "        [o[\"std\"] for o in observables_over_time],\n",
    "        title=run.config.to_latex(),\n",
    "        save=FIGURES / f\"lc-of-t-{slug}.png\"\n",
    "    )\n",
    "\n",
    "    observables_df = pd.DataFrame(observables_over_time)\n",
    "    observables_df.to_csv(ANALYSIS / f\"cov/cov-{slug}.csv\")\n",
    "    os.remove(ANALYSIS / f\"cov-tmp-{slug}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(observables_over_time[0].keys())\n",
    "plot_cov_evals_over_time(\n",
    "    STEPS,\n",
    "    [o[\"cov-eval/0\"] for o in observables_over_time],\n",
    "    [o[\"cov-eval/1\"] for o in observables_over_time],\n",
    "    title=run.config.to_latex(),\n",
    "    save=FIGURES / f\"cov-eval-of-t-{slug}.png\"\n",
    ")\n",
    "\n",
    "plot_learning_coeff_over_time(\n",
    "    STEPS,\n",
    "    np.array([o[\"mean\"] for o in observables_over_time]),\n",
    "    np.array([o[\"std\"] for o in observables_over_time]),\n",
    "    title=run.config.to_latex(),\n",
    "    save=FIGURES / f\"lc-of-t-{slug}.png\"\n",
    ")\n",
    "\n",
    "observables_df = pd.DataFrame(observables_over_time)\n",
    "observables_df.to_csv(ANALYSIS / f\"cov/cov-{slug}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'run' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb Cell 38\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpaperspace/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m gc\u001b[39m.\u001b[39mcollect()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpaperspace/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mempty_cache()\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bpaperspace/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mdel\u001b[39;00m run, trainset, trainloader\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpaperspace/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mdel\u001b[39;00m slt_evals\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpaperspace/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mgc\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'run' is not defined"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "del run, trainset, trainloader\n",
    "del slt_evals\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariances = observables.pop(\"covariances\")\n",
    "evals, evecs = eigsh(covariances, k=3, which='LM')\n",
    "\n",
    "for i, (eval, evec) in enumerate(zip(evals, evecs.T)):\n",
    "    slug = f\"cov-u{i}\" + run.config.to_slug(delimiter=\"-\") + f\"@t={step}\"\n",
    "    attn0, attn1 = evec.split(64 * 16 * 3)\n",
    "    \n",
    "\n",
    "# TODO: Need to rename the new files otherwise you can't tell easily tell what step they come from.\n",
    "\n",
    "\n",
    "os.system('say \"Your program has finished.\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from scipy.sparse.linalg import eigsh\n",
    "\n",
    "\n",
    "# wandb.init(entity=\"devinterp\", project=\"icl\")\n",
    "\n",
    "for config, checkpointer in zip(configs, checkpointers):\n",
    "    run = Run(config)\n",
    "    observables_over_time = []\n",
    "    \n",
    "    for step, observables in generate_slt_observables(\n",
    "        checkpointer.file_ids,\n",
    "        iter_models(run.model, checkpointer, verbose=True), \n",
    "        run.evaluator.pretrain_xs, \n",
    "        run.evaluator.pretrain_ys, \n",
    "        cores=4,\n",
    "        lr=1e-5,\n",
    "        num_draws=100,\n",
    "        elasticity=1.,\n",
    "        num_chains=20,\n",
    "        device=\"cuda\",\n",
    "        covariance_paths=[\n",
    "            f\"token_sequence_transformer.blocks.{b}.attention.attention\"\n",
    "            for b in range(run.config.task_config.num_layers)\n",
    "        ]\n",
    "    ):\n",
    "        # wandb.log(observables, step=step)\n",
    "        observables[\"step\"] = step\n",
    "        covariances = observables.pop(\"covariances\")\n",
    "\n",
    "        # I only want the two largest eigenvalues in evals and evecs\n",
    "        covariances = np.linalg.eigvalsh(covariances)\n",
    "        evals, evecs = eigsh(covariances, k=3, which='LM')\n",
    "        \n",
    "        observables_over_time.append(observables)\n",
    "        print(yaml.dump({\n",
    "            **observables,\n",
    "            \"covariances\": covariances.shape\n",
    "        }))\n",
    "\n",
    "        raise NotImplementedError(\"TODO: Save covariances\")\n",
    "\n",
    "    df = pd.DataFrame(observables_over_time)\n",
    "    slug = \"slt-\" + run.config.to_slug(delimiter=\"-\")\n",
    "    df.to_csv(ANALYSIS / (slug + \".csv\"))\n",
    "\n",
    "# wandb.finish()\n",
    "os.system('say \"Your program has finished.\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "from icl.config import ICLConfig\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def gather_images_side_by_side(folder, save: Optional[str] = None, delete: bool = True):\n",
    "    \"\"\"\n",
    "    Assumes folder contains folders that contain pngs. \n",
    "    \"\"\"\n",
    "    folder = Path(folder)\n",
    "    folder_paths = folder.glob(\"*\")\n",
    "\n",
    "    # Create a dictionary to store images by filename\n",
    "    images_by_filename = {}\n",
    "\n",
    "    if save:\n",
    "        save = Path(save)\n",
    "\n",
    "        if not os.path.exists(save):\n",
    "            os.makedirs(save)\n",
    "\n",
    "    # Load images from each folder and organize them by filename\n",
    "    for folder_path in folder_paths:\n",
    "        filenames = [f for f in os.listdir(folder_path) if f.endswith('.png')] \n",
    "        for filename in filenames:\n",
    "            img = Image.open(os.path.join(folder_path, filename))\n",
    "            if filename in images_by_filename:\n",
    "                images_by_filename[filename].append(img)\n",
    "            else:\n",
    "                images_by_filename[filename] = [img]\n",
    "\n",
    "    # Create comparison images for each unique filename\n",
    "    for filename, image_list in images_by_filename.items():\n",
    "        # Calculate the width and height of the result image\n",
    "        width = sum(img.width for img in image_list)\n",
    "        height = max(img.height for img in image_list)\n",
    "\n",
    "        # Create a new image for the comparison\n",
    "        result_image = Image.new('RGB', (width, height))\n",
    "\n",
    "        # Paste images side by side\n",
    "        x_offset = 0\n",
    "        for img in image_list:\n",
    "            result_image.paste(img, (x_offset, 0))\n",
    "            x_offset += img.width\n",
    "\n",
    "        # Display or save the result image\n",
    "        if save: \n",
    "            result_image.save(save / filename)  # You can replace this with result_image.save() to save the comparison images\n",
    "\n",
    "    if delete:\n",
    "        # Delete the temporary folder\n",
    "        shutil.rmtree(folder)\n",
    "\n",
    "\n",
    "def plot_activations(config: ICLConfig, activations: Dict[str, torch.Tensor], save: Optional[str] = None):\n",
    "    B = 1\n",
    "    E = config.task_config.embed_size\n",
    "    T = 2 * config.task_config.max_examples\n",
    "    H = config.task_config.num_heads\n",
    "\n",
    "    def optionally_rotate(x, name):\n",
    "        if len(x.shape) != 2:\n",
    "            raise ValueError(\"Tensor should have two dimensions.\")\n",
    "\n",
    "        if x.shape[0] > x.shape[1]:\n",
    "            return x.T, f\"{name}.T\"\n",
    "        \n",
    "        return x, name \n",
    "\n",
    "    def separate_attention(qkv: TensorType[\"B\", \"T\", \"C\"], num_heads: int, batch_size: int, head_size: int, num_tokens: int):\n",
    "        return (qkv   \n",
    "            .view(batch_size, num_tokens, num_heads, 3*head_size)\n",
    "            .transpose(-2, -3)     \n",
    "            .split(head_size, dim=-1)\n",
    "        )\n",
    "\n",
    "    if save:\n",
    "        save = Path(save)\n",
    "\n",
    "        if not os.path.exists(save):\n",
    "            os.makedirs(save)\n",
    "\n",
    "    for location, v in activations.items():\n",
    "        activation_slice = v[0]\n",
    "\n",
    "        if location.endswith(\"attention.attention\"):\n",
    "            q, k, v = separate_attention(v, num_heads=H, batch_size=B, head_size=E//H, num_tokens=T)\n",
    "            qk = q @ k.transpose(-2, -1)\n",
    "            q, k, qk, v = q[0], k[0], v[0], qk[0]\n",
    "            \n",
    "            fig, axs = plt.subplots(H, 4, figsize=(15, 15))\n",
    "\n",
    "            for j, (name, x) in enumerate(zip([\"Q\", \"K\", \"QK\", \"V\"], [q, k, qk, v])):\n",
    "                for h in range(H):\n",
    "                    ax = axs[h, j]\n",
    "                    im = ax.matshow(x[h].detach().to(\"cpu\").numpy())\n",
    "                    ax.set_title(f\"{h}.{name}\")\n",
    "                    # fig.colorbar(im, ax=ax)\n",
    "\n",
    "            plt.suptitle(location)\n",
    "            plt.tight_layout()\n",
    "\n",
    "            if save:\n",
    "                plt.savefig(save / (location + \".png\"))\n",
    "                plt.close(fig)\n",
    "\n",
    "                del fig\n",
    "                del axs\n",
    "\n",
    "        elif len(activation_slice.shape) == 2:\n",
    "            fig = plt.figure()\n",
    "\n",
    "            x, location = optionally_rotate(activation_slice, location)\n",
    "            plt.matshow(x.detach().to(\"cpu\").numpy())\n",
    "            plt.title(f\"{location}\")\n",
    "            # fig.colorbar(im)\n",
    "\n",
    "            if save:\n",
    "                plt.savefig(save / (location + \".png\"))\n",
    "                plt.close(fig)\n",
    "\n",
    "                del fig\n",
    "\n",
    "\n",
    "        elif len(activation_slice.shape) == 3:  # [heads, xs, ys]\n",
    "            heads, xs, ys = activation_slice.shape\n",
    "            fig, axs = plt.subplots(1, heads, figsize=(15, 15))\n",
    "\n",
    "            for j in range(heads):\n",
    "                ax = axs[j]\n",
    "                x, name = optionally_rotate(activation_slice[j], str(j))\n",
    "                im = ax.matshow(x.detach().to(\"cpu\").numpy())\n",
    "                ax.set_title(f\"{name}\")\n",
    "                # fig.colorbar(im, ax=ax)\n",
    "            \n",
    "            plt.suptitle(f\"{location}.#\")\n",
    "            plt.tight_layout()\n",
    "\n",
    "            if save:\n",
    "                plt.savefig(save / (location + \".png\"))\n",
    "                plt.close(fig)\n",
    "\n",
    "            del fig\n",
    "            del axs\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported number of dimensions.\")\n",
    "\n",
    "\n",
    "def compare_activations(config: ICLConfig, model, x: TensorType[\"B\", \"D\"], y: TensorType[\"B\", 1], save: Optional[str] = None, names: Optional[List[str]] = None):\n",
    "    B = len(x)\n",
    "    hooked_model = hook(model)\n",
    "\n",
    "    activations = {}\n",
    "    output, activations_ = hooked_model.run_with_cache(x, y)\n",
    "    activations[\"x\"] = x\n",
    "    activations[\"y\"] = y\n",
    "    activations[\"output\"] = output\n",
    "    activations.update(activations_)\n",
    "\n",
    "    def activations_per_sample(activations, index, keep_batch_dim=False):\n",
    "        if keep_batch_dim:\n",
    "            print({k: type(v) for k, v in activations.items()})\n",
    "            return {k: v[index].unsqueeze(0) for k, v in activations.items() if v is not None}\n",
    "        \n",
    "        return {k: v[index] for k, v in activations.items() if v is not None}\n",
    "\n",
    "    tmp_folder = Path(\"tmp\")\n",
    "\n",
    "    names = names or list(map(str, range(B)))\n",
    "\n",
    "    for (name, b) in zip(names, range(B)):\n",
    "        activations_b = activations_per_sample(activations, b, keep_batch_dim=True)\n",
    "        plot_activations(config, activations_b, save=tmp_folder / str(name))\n",
    "\n",
    "    gather_images_side_by_side(tmp_folder, save=save, delete=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = Run.create_and_restore(configs[2])\n",
    "compare_activations(demo.config, demo.model, demo.evaluator.pretrain_xs[:3], demo.evaluator.pretrain_ys[:3], save=FIGURES / \"demo\", names=[\"$x_0$\", \"$x_1$\", \"$x_2$\"])\n",
    "# gather_images_side_by_side(\"tmp\", save=FIGURES/\"demo\", delete=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a few samples for each model at the end of training\n",
    "from icl.train import Run\n",
    "\n",
    "NUM_SAMPLES = 4\n",
    "\n",
    "for config, checkpointer in zip(configs, checkpointers):\n",
    "    run = Run.create_and_restore(config)\n",
    "    \n",
    "    sample_names = [f\"$x_{i}$\" for i in range(NUM_SAMPLES)]\n",
    "    slug = \"activations-\" + run.config.to_slug(delimiter=\"-\")\n",
    "\n",
    "    compare_activations(\n",
    "        run.config, \n",
    "        run.model, \n",
    "        run.evaluator.pretrain_xs[:NUM_SAMPLES], \n",
    "        run.evaluator.pretrain_ys[:NUM_SAMPLES], \n",
    "        save=FIGURES / slug, \n",
    "        names=sample_names\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(checkpointer.file_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a few samples for a subset of models over training\n",
    "\n",
    "MS = [1, 4, 64, 2**10, 2**20]\n",
    "STEPS = [0, 1_805, 3_084, 15_381, 26_279, 100_262, 153_061, 193_877, 255_102, 306_122, 408_163]\n",
    "\n",
    "for m in MS:\n",
    "    log2_m = int(np.log2(m))\n",
    "    config, checkpointer = configs[log2_m], checkpointers[log2_m]\n",
    "    run = Run(config)\n",
    "\n",
    "    for step in STEPS:\n",
    "        run.model.load_state_dict(checkpointer.load_file(step)[\"model\"])\n",
    "\n",
    "        sample_names = [f\"$x_{i}$\" for i in range(NUM_SAMPLES)]\n",
    "        slug = \"activations-\" + run.config.to_slug(delimiter=\"-\") + f\"@t={step}\"\n",
    "\n",
    "        # TODO: Need to rename the new files otherwise you can't tell easily tell what step they come from.\n",
    "        compare_activations(\n",
    "            run.config, \n",
    "            run.model, \n",
    "            run.evaluator.pretrain_xs[:NUM_SAMPLES], \n",
    "            run.evaluator.pretrain_ys[:NUM_SAMPLES], \n",
    "            save=FIGURES / slug, \n",
    "            names=sample_names\n",
    "        )\n",
    "        \n",
    "        os.system('say \"Your program has finished.\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get it all on Wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
