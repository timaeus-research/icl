{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small-model report\n",
    "\n",
    "On the small model (L=2, H=2):\n",
    "\n",
    "- Replication of Raventós et al. (2023) + fitting the various algorithms\n",
    "- All the analyses (RLCT, PCA, Attention Entropies, Covariance, Weight-staring). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "if not \"AWS_ACCESS_KEY_ID\" in os.environ or not \"AWS_SECRET_ACCESS_KEY\" in os.environ:\n",
    "    raise Exception(\"AWS_ACCESS_KEY_ID or AWS_SECRET_ACCESS_KEY not found in environment variables. Please set them in .env file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pp\n",
    "from pathlib import Path\n",
    "from typing import Optional, Iterable\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch \n",
    "from torch import nn\n",
    "\n",
    "import devinterp\n",
    "import devinfra\n",
    "\n",
    "from icl.analysis.utils import get_unique_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "SWEEP_ID = \"6g954fkg\"\n",
    "SWEEP_FILENAME = \"small-sweep-2.yaml\"\n",
    "FIGURES=Path(\"../figures\")\n",
    "ANALYSIS = Path(\"../analysis\")\n",
    "\n",
    "DEVICE = devinfra.utils.device.get_default_device()\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 21 runs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/Projects/devinfra/devinfra/utils/iterables.py:29: UserWarning: Number of steps in int_logspace is not 100, got 91.\n",
      "  warnings.warn(\n",
      "/home/paperspace/Projects/devinfra/devinfra/utils/iterables.py:29: UserWarning: Number of steps in int_logspace is not 50, got 47.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from icl.analysis.utils import get_sweep_configs\n",
    "\n",
    "filters = {\"task_config\": {\"num_layers\": 2, \"num_heads\": 4}, \"optimizer_config\": {\"lr\": 0.01}}  # TODO: Where are the H=2 runs?\n",
    "configs = list(get_sweep_configs(f\"../sweeps/{SWEEP_FILENAME}\", **filters))\n",
    "\n",
    "print(f\"Found {len(configs)} runs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading checkpoints: 100%|██████████| 21/21 [00:13<00:00,  1.57it/s]\n",
      "Loading checkpoints: 100%|██████████| 21/21 [00:00<00:00, 6327.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 96 checkpoints for CompositeStorageProvider([S3StorageProvider(s3://devinterp/checkpoints/icl/ntasks-1-task-c19845-opt-aa689f-sched-1ee2ae)])\n",
      "Found 96 checkpoints for CompositeStorageProvider([S3StorageProvider(s3://devinterp/checkpoints/icl/ntasks-2-task-7ed30b-opt-aa689f-sched-1ee2ae)])\n",
      "Found 96 checkpoints for CompositeStorageProvider([S3StorageProvider(s3://devinterp/checkpoints/icl/ntasks-4-task-871f4f-opt-aa689f-sched-1ee2ae)])\n",
      "Found 96 checkpoints for CompositeStorageProvider([S3StorageProvider(s3://devinterp/checkpoints/icl/ntasks-8-task-6d414c-opt-aa689f-sched-1ee2ae)])\n",
      "Found 96 checkpoints for CompositeStorageProvider([S3StorageProvider(s3://devinterp/checkpoints/icl/ntasks-16-task-fef7aa-opt-aa689f-sched-1ee2ae)])\n",
      "Found 96 checkpoints for CompositeStorageProvider([S3StorageProvider(s3://devinterp/checkpoints/icl/ntasks-32-task-b02901-opt-aa689f-sched-1ee2ae)])\n",
      "Found 96 checkpoints for CompositeStorageProvider([S3StorageProvider(s3://devinterp/checkpoints/icl/ntasks-64-task-48d75c-opt-aa689f-sched-1ee2ae)])\n",
      "Found 96 checkpoints for CompositeStorageProvider([S3StorageProvider(s3://devinterp/checkpoints/icl/ntasks-128-task-6cc650-opt-aa689f-sched-1ee2ae)])\n",
      "Found 96 checkpoints for CompositeStorageProvider([S3StorageProvider(s3://devinterp/checkpoints/icl/ntasks-256-task-69174b-opt-aa689f-sched-1ee2ae)])\n",
      "Found 96 checkpoints for CompositeStorageProvider([S3StorageProvider(s3://devinterp/checkpoints/icl/ntasks-512-task-78b782-opt-aa689f-sched-1ee2ae)])\n",
      "Found 96 checkpoints for CompositeStorageProvider([S3StorageProvider(s3://devinterp/checkpoints/icl/ntasks-1024-task-0fcb82-opt-aa689f-sched-1ee2ae)])\n",
      "Found 96 checkpoints for CompositeStorageProvider([S3StorageProvider(s3://devinterp/checkpoints/icl/ntasks-2048-task-3c92ba-opt-aa689f-sched-1ee2ae)])\n",
      "Found 96 checkpoints for CompositeStorageProvider([S3StorageProvider(s3://devinterp/checkpoints/icl/ntasks-4096-task-f9810d-opt-aa689f-sched-1ee2ae)])\n",
      "Found 96 checkpoints for CompositeStorageProvider([S3StorageProvider(s3://devinterp/checkpoints/icl/ntasks-8192-task-77033f-opt-aa689f-sched-1ee2ae)])\n",
      "Found 96 checkpoints for CompositeStorageProvider([S3StorageProvider(s3://devinterp/checkpoints/icl/ntasks-16384-task-e30fe5-opt-aa689f-sched-1ee2ae)])\n",
      "Found 96 checkpoints for CompositeStorageProvider([S3StorageProvider(s3://devinterp/checkpoints/icl/ntasks-32768-task-13c862-opt-aa689f-sched-1ee2ae)])\n",
      "Found 96 checkpoints for CompositeStorageProvider([S3StorageProvider(s3://devinterp/checkpoints/icl/ntasks-65536-task-2dee6f-opt-aa689f-sched-1ee2ae)])\n",
      "Found 96 checkpoints for CompositeStorageProvider([S3StorageProvider(s3://devinterp/checkpoints/icl/ntasks-131072-task-40304c-opt-aa689f-sched-1ee2ae)])\n",
      "Found 96 checkpoints for CompositeStorageProvider([S3StorageProvider(s3://devinterp/checkpoints/icl/ntasks-262144-task-3abb88-opt-aa689f-sched-1ee2ae)])\n",
      "Found 96 checkpoints for CompositeStorageProvider([S3StorageProvider(s3://devinterp/checkpoints/icl/ntasks-524288-task-ec350d-opt-aa689f-sched-1ee2ae)])\n",
      "Found 96 checkpoints for CompositeStorageProvider([S3StorageProvider(s3://devinterp/checkpoints/icl/ntasks-1048576-task-faf506-opt-aa689f-sched-1ee2ae)])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Figure out which checkpoints are available\n",
    "\n",
    "checkpointers = [config.checkpointer_config.factory() for config in tqdm(configs, desc=\"Reading checkpoints\")]\n",
    "\n",
    "for checkpointer in tqdm(checkpointers, desc=\"Loading checkpoints\"):\n",
    "    print(f\"Found {len(checkpointer.file_ids)} checkpoints for {checkpointer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replication "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 21 runs.\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "from devinfra.utils.iterables import filter_objs\n",
    "\n",
    "api= wandb.Api()\n",
    "sweep = api.sweep(f\"devinterp/icl/{SWEEP_ID}\")\n",
    "runs = list(filter_objs([r for r in sweep.runs], config=filters))\n",
    "\n",
    "print(f\"Found {len(runs)} runs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/Projects/devinfra/devinfra/utils/iterables.py:29: UserWarning: Number of steps in int_logspace is not 100, got 91.\n",
      "  warnings.warn(\n",
      "/home/paperspace/Projects/devinfra/devinfra/utils/iterables.py:29: UserWarning: Number of steps in int_logspace is not 50, got 47.\n",
      "  warnings.warn(\n",
      "/home/paperspace/Projects/icl/.venv/lib/python3.9/site-packages/pydantic/main.py:301: UserWarning: Pydantic serializer warnings:\n",
      "  Expected `str` but got `device` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "/home/paperspace/Projects/devinfra/devinfra/utils/iterables.py:29: UserWarning: Number of steps in int_logspace is not 100, got 91.\n",
      "  warnings.warn(\n",
      "/home/paperspace/Projects/devinfra/devinfra/utils/iterables.py:29: UserWarning: Number of steps in int_logspace is not 50, got 47.\n",
      "  warnings.warn(\n",
      "/home/paperspace/Projects/icl/.venv/lib/python3.9/site-packages/pydantic/main.py:301: UserWarning: Pydantic serializer warnings:\n",
      "  Expected `str` but got `device` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "/home/paperspace/Projects/devinfra/devinfra/utils/iterables.py:29: UserWarning: Number of steps in int_logspace is not 100, got 91.\n",
      "  warnings.warn(\n",
      "/home/paperspace/Projects/devinfra/devinfra/utils/iterables.py:29: UserWarning: Number of steps in int_logspace is not 50, got 47.\n",
      "  warnings.warn(\n",
      "/home/paperspace/Projects/icl/.venv/lib/python3.9/site-packages/pydantic/main.py:301: UserWarning: Pydantic serializer warnings:\n",
      "  Expected `str` but got `device` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "/home/paperspace/Projects/devinfra/devinfra/utils/iterables.py:29: UserWarning: Number of steps in int_logspace is not 100, got 91.\n",
      "  warnings.warn(\n",
      "/home/paperspace/Projects/devinfra/devinfra/utils/iterables.py:29: UserWarning: Number of steps in int_logspace is not 50, got 47.\n",
      "  warnings.warn(\n",
      "/home/paperspace/Projects/icl/.venv/lib/python3.9/site-packages/pydantic/main.py:301: UserWarning: Pydantic serializer warnings:\n",
      "  Expected `str` but got `device` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "/home/paperspace/Projects/devinfra/devinfra/utils/iterables.py:29: UserWarning: Number of steps in int_logspace is not 100, got 91.\n",
      "  warnings.warn(\n",
      "/home/paperspace/Projects/devinfra/devinfra/utils/iterables.py:29: UserWarning: Number of steps in int_logspace is not 50, got 47.\n",
      "  warnings.warn(\n",
      "/home/paperspace/Projects/icl/.venv/lib/python3.9/site-packages/pydantic/main.py:301: UserWarning: Pydantic serializer warnings:\n",
      "  Expected `str` but got `device` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "/home/paperspace/Projects/devinfra/devinfra/utils/iterables.py:29: UserWarning: Number of steps in int_logspace is not 100, got 91.\n",
      "  warnings.warn(\n",
      "/home/paperspace/Projects/devinfra/devinfra/utils/iterables.py:29: UserWarning: Number of steps in int_logspace is not 50, got 47.\n",
      "  warnings.warn(\n",
      "/home/paperspace/Projects/icl/.venv/lib/python3.9/site-packages/pydantic/main.py:301: UserWarning: Pydantic serializer warnings:\n",
      "  Expected `str` but got `device` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "/home/paperspace/Projects/devinfra/devinfra/utils/iterables.py:29: UserWarning: Number of steps in int_logspace is not 100, got 91.\n",
      "  warnings.warn(\n",
      "/home/paperspace/Projects/devinfra/devinfra/utils/iterables.py:29: UserWarning: Number of steps in int_logspace is not 50, got 47.\n",
      "  warnings.warn(\n",
      "/home/paperspace/Projects/icl/.venv/lib/python3.9/site-packages/pydantic/main.py:301: UserWarning: Pydantic serializer warnings:\n",
      "  Expected `str` but got `device` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "/home/paperspace/Projects/devinfra/devinfra/utils/iterables.py:29: UserWarning: Number of steps in int_logspace is not 100, got 91.\n",
      "  warnings.warn(\n",
      "/home/paperspace/Projects/devinfra/devinfra/utils/iterables.py:29: UserWarning: Number of steps in int_logspace is not 50, got 47.\n",
      "  warnings.warn(\n",
      "/home/paperspace/Projects/icl/.venv/lib/python3.9/site-packages/pydantic/main.py:301: UserWarning: Pydantic serializer warnings:\n",
      "  Expected `str` but got `device` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "/home/paperspace/Projects/devinfra/devinfra/utils/iterables.py:29: UserWarning: Number of steps in int_logspace is not 100, got 91.\n",
      "  warnings.warn(\n",
      "/home/paperspace/Projects/devinfra/devinfra/utils/iterables.py:29: UserWarning: Number of steps in int_logspace is not 50, got 47.\n",
      "  warnings.warn(\n",
      "/home/paperspace/Projects/icl/.venv/lib/python3.9/site-packages/pydantic/main.py:301: UserWarning: Pydantic serializer warnings:\n",
      "  Expected `str` but got `device` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "/home/paperspace/Projects/devinfra/devinfra/utils/iterables.py:29: UserWarning: Number of steps in int_logspace is not 100, got 91.\n",
      "  warnings.warn(\n",
      "/home/paperspace/Projects/devinfra/devinfra/utils/iterables.py:29: UserWarning: Number of steps in int_logspace is not 50, got 47.\n",
      "  warnings.warn(\n",
      "/home/paperspace/Projects/icl/.venv/lib/python3.9/site-packages/pydantic/main.py:301: UserWarning: Pydantic serializer warnings:\n",
      "  Expected `str` but got `device` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "/home/paperspace/Projects/devinfra/devinfra/utils/iterables.py:29: UserWarning: Number of steps in int_logspace is not 100, got 91.\n",
      "  warnings.warn(\n",
      "/home/paperspace/Projects/devinfra/devinfra/utils/iterables.py:29: UserWarning: Number of steps in int_logspace is not 50, got 47.\n",
      "  warnings.warn(\n",
      "/home/paperspace/Projects/icl/.venv/lib/python3.9/site-packages/pydantic/main.py:301: UserWarning: Pydantic serializer warnings:\n",
      "  Expected `str` but got `device` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "/home/paperspace/Projects/devinfra/devinfra/utils/iterables.py:29: UserWarning: Number of steps in int_logspace is not 100, got 91.\n",
      "  warnings.warn(\n",
      "/home/paperspace/Projects/devinfra/devinfra/utils/iterables.py:29: UserWarning: Number of steps in int_logspace is not 50, got 47.\n",
      "  warnings.warn(\n",
      "/home/paperspace/Projects/icl/.venv/lib/python3.9/site-packages/pydantic/main.py:301: UserWarning: Pydantic serializer warnings:\n",
      "  Expected `str` but got `device` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "/home/paperspace/Projects/devinfra/devinfra/utils/iterables.py:29: UserWarning: Number of steps in int_logspace is not 100, got 91.\n",
      "  warnings.warn(\n",
      "/home/paperspace/Projects/devinfra/devinfra/utils/iterables.py:29: UserWarning: Number of steps in int_logspace is not 50, got 47.\n",
      "  warnings.warn(\n",
      "/home/paperspace/Projects/icl/.venv/lib/python3.9/site-packages/pydantic/main.py:301: UserWarning: Pydantic serializer warnings:\n",
      "  Expected `str` but got `device` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "/home/paperspace/Projects/devinfra/devinfra/utils/iterables.py:29: UserWarning: Number of steps in int_logspace is not 100, got 91.\n",
      "  warnings.warn(\n",
      "/home/paperspace/Projects/devinfra/devinfra/utils/iterables.py:29: UserWarning: Number of steps in int_logspace is not 50, got 47.\n",
      "  warnings.warn(\n",
      "/home/paperspace/Projects/icl/.venv/lib/python3.9/site-packages/pydantic/main.py:301: UserWarning: Pydantic serializer warnings:\n",
      "  Expected `str` but got `device` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "/home/paperspace/Projects/devinfra/devinfra/utils/iterables.py:29: UserWarning: Number of steps in int_logspace is not 100, got 91.\n",
      "  warnings.warn(\n",
      "/home/paperspace/Projects/devinfra/devinfra/utils/iterables.py:29: UserWarning: Number of steps in int_logspace is not 50, got 47.\n",
      "  warnings.warn(\n",
      "/home/paperspace/Projects/icl/.venv/lib/python3.9/site-packages/pydantic/main.py:301: UserWarning: Pydantic serializer warnings:\n",
      "  Expected `str` but got `device` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "/home/paperspace/Projects/devinfra/devinfra/utils/iterables.py:29: UserWarning: Number of steps in int_logspace is not 100, got 91.\n",
      "  warnings.warn(\n",
      "/home/paperspace/Projects/devinfra/devinfra/utils/iterables.py:29: UserWarning: Number of steps in int_logspace is not 50, got 47.\n",
      "  warnings.warn(\n",
      "/home/paperspace/Projects/icl/.venv/lib/python3.9/site-packages/pydantic/main.py:301: UserWarning: Pydantic serializer warnings:\n",
      "  Expected `str` but got `device` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "/home/paperspace/Projects/devinfra/devinfra/utils/iterables.py:29: UserWarning: Number of steps in int_logspace is not 100, got 91.\n",
      "  warnings.warn(\n",
      "/home/paperspace/Projects/devinfra/devinfra/utils/iterables.py:29: UserWarning: Number of steps in int_logspace is not 50, got 47.\n",
      "  warnings.warn(\n",
      "/home/paperspace/Projects/icl/.venv/lib/python3.9/site-packages/pydantic/main.py:301: UserWarning: Pydantic serializer warnings:\n",
      "  Expected `str` but got `device` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "/home/paperspace/Projects/devinfra/devinfra/utils/iterables.py:29: UserWarning: Number of steps in int_logspace is not 100, got 91.\n",
      "  warnings.warn(\n",
      "/home/paperspace/Projects/devinfra/devinfra/utils/iterables.py:29: UserWarning: Number of steps in int_logspace is not 50, got 47.\n",
      "  warnings.warn(\n",
      "/home/paperspace/Projects/icl/.venv/lib/python3.9/site-packages/pydantic/main.py:301: UserWarning: Pydantic serializer warnings:\n",
      "  Expected `str` but got `device` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "/home/paperspace/Projects/devinfra/devinfra/utils/iterables.py:29: UserWarning: Number of steps in int_logspace is not 100, got 91.\n",
      "  warnings.warn(\n",
      "/home/paperspace/Projects/devinfra/devinfra/utils/iterables.py:29: UserWarning: Number of steps in int_logspace is not 50, got 47.\n",
      "  warnings.warn(\n",
      "/home/paperspace/Projects/icl/.venv/lib/python3.9/site-packages/pydantic/main.py:301: UserWarning: Pydantic serializer warnings:\n",
      "  Expected `str` but got `device` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "/home/paperspace/Projects/devinfra/devinfra/utils/iterables.py:29: UserWarning: Number of steps in int_logspace is not 100, got 91.\n",
      "  warnings.warn(\n",
      "/home/paperspace/Projects/devinfra/devinfra/utils/iterables.py:29: UserWarning: Number of steps in int_logspace is not 50, got 47.\n",
      "  warnings.warn(\n",
      "/home/paperspace/Projects/icl/.venv/lib/python3.9/site-packages/pydantic/main.py:301: UserWarning: Pydantic serializer warnings:\n",
      "  Expected `str` but got `device` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "/home/paperspace/Projects/devinfra/devinfra/utils/iterables.py:29: UserWarning: Number of steps in int_logspace is not 100, got 91.\n",
      "  warnings.warn(\n",
      "/home/paperspace/Projects/devinfra/devinfra/utils/iterables.py:29: UserWarning: Number of steps in int_logspace is not 50, got 47.\n",
      "  warnings.warn(\n",
      "/home/paperspace/Projects/icl/.venv/lib/python3.9/site-packages/pydantic/main.py:301: UserWarning: Pydantic serializer warnings:\n",
      "  Expected `str` but got `device` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "Converting runs to dfs: 100%|██████████| 21/21 [00:09<00:00,  2.15it/s]\n"
     ]
    }
   ],
   "source": [
    "from devinfra.utils.iterables import flatten_dict\n",
    "from icl.analysis.utils import wandb_runs_to_df\n",
    "\n",
    "df = wandb_runs_to_df(runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pretrain/token/7',\n",
      " 'pretrain/delta_ridge',\n",
      " '_timestamp',\n",
      " 'true/token/7',\n",
      " '_runtime',\n",
      " 'pretrain/token/0',\n",
      " 'pretrain/token/6',\n",
      " 'pretrain/token/5',\n",
      " 'true/token/3',\n",
      " 'true/mse',\n",
      " 'pretrain/token/4',\n",
      " 'true/token/2',\n",
      " 'true/token/5',\n",
      " 'true/delta_ridge',\n",
      " 'pretrain/token/2',\n",
      " 'batch/loss',\n",
      " 'true/token/1',\n",
      " 'pretrain/token/3',\n",
      " 'true/token/6',\n",
      " '_step',\n",
      " 'true/token/0',\n",
      " 'pretrain/token/1',\n",
      " 'true/delta_dmmse',\n",
      " 'pretrain/mse',\n",
      " 'true/token/4',\n",
      " 'pretrain/delta_dmmse',\n",
      " 'num_training_samples',\n",
      " 'batch_size',\n",
      " 'run_name',\n",
      " 'num_steps',\n",
      " 'optimizer_config/optimizer_type',\n",
      " 'optimizer_config/lr',\n",
      " 'optimizer_config/weight_decay',\n",
      " 'optimizer_config/momentum',\n",
      " 'optimizer_config/betas',\n",
      " 'optimizer_config/noise_level',\n",
      " 'optimizer_config/elasticity',\n",
      " 'optimizer_config/temperature',\n",
      " 'optimizer_config/num_samples',\n",
      " 'scheduler_config/scheduler_type',\n",
      " 'scheduler_config/step_size',\n",
      " 'scheduler_config/gamma',\n",
      " 'scheduler_config/T_max',\n",
      " 'scheduler_config/eta_min',\n",
      " 'scheduler_config/last_epoch',\n",
      " 'scheduler_config/milestones',\n",
      " 'scheduler_config/lr_lambda',\n",
      " 'scheduler_config/max_lr',\n",
      " 'scheduler_config/total_steps',\n",
      " 'scheduler_config/anneal_strategy',\n",
      " 'scheduler_config/div_factor',\n",
      " 'scheduler_config/final_div_factor',\n",
      " 'scheduler_config/pct_start',\n",
      " 'scheduler_config/cycle_momentum',\n",
      " 'device',\n",
      " 'criterion',\n",
      " 'eval_batch_size',\n",
      " 'task_config/task_size',\n",
      " 'task_config/max_examples',\n",
      " 'task_config/num_tasks',\n",
      " 'task_config/noise_variance',\n",
      " 'task_config/embed_size',\n",
      " 'task_config/mlp_size',\n",
      " 'task_config/num_heads',\n",
      " 'task_config/num_layers',\n",
      " 'task_config/model_seed',\n",
      " 'task_config/pretrain_seed',\n",
      " 'task_config/true_seed',\n",
      " 'task_config/sampling_seed']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pretrain/token/7</th>\n",
       "      <th>pretrain/delta_ridge</th>\n",
       "      <th>_timestamp</th>\n",
       "      <th>true/token/7</th>\n",
       "      <th>_runtime</th>\n",
       "      <th>pretrain/token/0</th>\n",
       "      <th>pretrain/token/6</th>\n",
       "      <th>pretrain/token/5</th>\n",
       "      <th>true/token/3</th>\n",
       "      <th>true/mse</th>\n",
       "      <th>...</th>\n",
       "      <th>task_config/num_tasks</th>\n",
       "      <th>task_config/noise_variance</th>\n",
       "      <th>task_config/embed_size</th>\n",
       "      <th>task_config/mlp_size</th>\n",
       "      <th>task_config/num_heads</th>\n",
       "      <th>task_config/num_layers</th>\n",
       "      <th>task_config/model_seed</th>\n",
       "      <th>task_config/pretrain_seed</th>\n",
       "      <th>task_config/true_seed</th>\n",
       "      <th>task_config/sampling_seed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.887876</td>\n",
       "      <td>2.962052</td>\n",
       "      <td>1.694888e+09</td>\n",
       "      <td>4.464043</td>\n",
       "      <td>194.516827</td>\n",
       "      <td>4.799209</td>\n",
       "      <td>4.641932</td>\n",
       "      <td>4.923923</td>\n",
       "      <td>4.647494</td>\n",
       "      <td>4.307594</td>\n",
       "      <td>...</td>\n",
       "      <td>1048576</td>\n",
       "      <td>0.125</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.836228</td>\n",
       "      <td>2.910503</td>\n",
       "      <td>1.694888e+09</td>\n",
       "      <td>4.404435</td>\n",
       "      <td>197.258324</td>\n",
       "      <td>4.729499</td>\n",
       "      <td>4.591867</td>\n",
       "      <td>4.864076</td>\n",
       "      <td>4.619861</td>\n",
       "      <td>4.258442</td>\n",
       "      <td>...</td>\n",
       "      <td>1048576</td>\n",
       "      <td>0.125</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.694888e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>236.672661</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1048576</td>\n",
       "      <td>0.125</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.679016</td>\n",
       "      <td>1.891562</td>\n",
       "      <td>1.694888e+09</td>\n",
       "      <td>3.277371</td>\n",
       "      <td>243.851240</td>\n",
       "      <td>4.242196</td>\n",
       "      <td>3.437490</td>\n",
       "      <td>3.602231</td>\n",
       "      <td>3.513309</td>\n",
       "      <td>3.364686</td>\n",
       "      <td>...</td>\n",
       "      <td>1048576</td>\n",
       "      <td>0.125</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.694888e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>245.008824</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1048576</td>\n",
       "      <td>0.125</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.694884e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6008.206496</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.125</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.694884e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6064.002723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.125</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.694884e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6070.992826</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.125</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.694884e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6073.299681</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.125</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.694884e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6086.285128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.125</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10500 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pretrain/token/7  pretrain/delta_ridge    _timestamp  true/token/7  \\\n",
       "0            4.887876              2.962052  1.694888e+09      4.464043   \n",
       "1            4.836228              2.910503  1.694888e+09      4.404435   \n",
       "2                 NaN                   NaN  1.694888e+09           NaN   \n",
       "3            3.679016              1.891562  1.694888e+09      3.277371   \n",
       "4                 NaN                   NaN  1.694888e+09           NaN   \n",
       "..                ...                   ...           ...           ...   \n",
       "495               NaN                   NaN  1.694884e+09           NaN   \n",
       "496               NaN                   NaN  1.694884e+09           NaN   \n",
       "497               NaN                   NaN  1.694884e+09           NaN   \n",
       "498               NaN                   NaN  1.694884e+09           NaN   \n",
       "499               NaN                   NaN  1.694884e+09           NaN   \n",
       "\n",
       "        _runtime  pretrain/token/0  pretrain/token/6  pretrain/token/5  \\\n",
       "0     194.516827          4.799209          4.641932          4.923923   \n",
       "1     197.258324          4.729499          4.591867          4.864076   \n",
       "2     236.672661               NaN               NaN               NaN   \n",
       "3     243.851240          4.242196          3.437490          3.602231   \n",
       "4     245.008824               NaN               NaN               NaN   \n",
       "..           ...               ...               ...               ...   \n",
       "495  6008.206496               NaN               NaN               NaN   \n",
       "496  6064.002723               NaN               NaN               NaN   \n",
       "497  6070.992826               NaN               NaN               NaN   \n",
       "498  6073.299681               NaN               NaN               NaN   \n",
       "499  6086.285128               NaN               NaN               NaN   \n",
       "\n",
       "     true/token/3  true/mse  ...  task_config/num_tasks  \\\n",
       "0        4.647494  4.307594  ...                1048576   \n",
       "1        4.619861  4.258442  ...                1048576   \n",
       "2             NaN       NaN  ...                1048576   \n",
       "3        3.513309  3.364686  ...                1048576   \n",
       "4             NaN       NaN  ...                1048576   \n",
       "..            ...       ...  ...                    ...   \n",
       "495           NaN       NaN  ...                      1   \n",
       "496           NaN       NaN  ...                      1   \n",
       "497           NaN       NaN  ...                      1   \n",
       "498           NaN       NaN  ...                      1   \n",
       "499           NaN       NaN  ...                      1   \n",
       "\n",
       "     task_config/noise_variance  task_config/embed_size  task_config/mlp_size  \\\n",
       "0                         0.125                      64                    64   \n",
       "1                         0.125                      64                    64   \n",
       "2                         0.125                      64                    64   \n",
       "3                         0.125                      64                    64   \n",
       "4                         0.125                      64                    64   \n",
       "..                          ...                     ...                   ...   \n",
       "495                       0.125                      64                    64   \n",
       "496                       0.125                      64                    64   \n",
       "497                       0.125                      64                    64   \n",
       "498                       0.125                      64                    64   \n",
       "499                       0.125                      64                    64   \n",
       "\n",
       "     task_config/num_heads  task_config/num_layers  task_config/model_seed  \\\n",
       "0                        4                       2                       0   \n",
       "1                        4                       2                       0   \n",
       "2                        4                       2                       0   \n",
       "3                        4                       2                       0   \n",
       "4                        4                       2                       0   \n",
       "..                     ...                     ...                     ...   \n",
       "495                      4                       2                       0   \n",
       "496                      4                       2                       0   \n",
       "497                      4                       2                       0   \n",
       "498                      4                       2                       0   \n",
       "499                      4                       2                       0   \n",
       "\n",
       "     task_config/pretrain_seed  task_config/true_seed  \\\n",
       "0                            1                      2   \n",
       "1                            1                      2   \n",
       "2                            1                      2   \n",
       "3                            1                      2   \n",
       "4                            1                      2   \n",
       "..                         ...                    ...   \n",
       "495                          1                      2   \n",
       "496                          1                      2   \n",
       "497                          1                      2   \n",
       "498                          1                      2   \n",
       "499                          1                      2   \n",
       "\n",
       "     task_config/sampling_seed  \n",
       "0                            3  \n",
       "1                            3  \n",
       "2                            3  \n",
       "3                            3  \n",
       "4                            3  \n",
       "..                         ...  \n",
       "495                          3  \n",
       "496                          3  \n",
       "497                          3  \n",
       "498                          3  \n",
       "499                          3  \n",
       "\n",
       "[10500 rows x 69 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp(list(df.columns))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/Projects/icl/.venv/lib/python3.9/site-packages/seaborn/_base.py:1006: FutureWarning: reindexing with a non-unique Index is deprecated and will raise in a future version.\n",
      "  comp_data.insert(0, var, comp_col)\n",
      "Converting runs to dfs:  14%|█▍        | 3/21 [01:11<07:10, 23.93s/it]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reindex on an axis with duplicate labels",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bpaperspace/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=100'>101</a>\u001b[0m     plt\u001b[39m.\u001b[39mshow()\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bpaperspace/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=102'>103</a>\u001b[0m \u001b[39m# TODO: Add baselines (also make comparisons for other hyperparameters besides batch_size). \u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Bpaperspace/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=103'>104</a>\u001b[0m recreate_fig_2_over_time(df, title\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mOver training\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bpaperspace/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=104'>105</a>\u001b[0m recreate_fig_2(df, title\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAt the end\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb Cell 12\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpaperspace/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=65'>66</a>\u001b[0m cmap \u001b[39m=\u001b[39m sns\u001b[39m.\u001b[39mcolor_palette(\u001b[39m\"\u001b[39m\u001b[39mviridis\u001b[39m\u001b[39m\"\u001b[39m, as_cmap\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpaperspace/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=67'>68</a>\u001b[0m \u001b[39m# Top row\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bpaperspace/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=68'>69</a>\u001b[0m sns\u001b[39m.\u001b[39;49mscatterplot(x\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtask_config/num_tasks\u001b[39;49m\u001b[39m'\u001b[39;49m, y\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mpretrain/mse\u001b[39;49m\u001b[39m'\u001b[39;49m, data\u001b[39m=\u001b[39;49mdf, ax\u001b[39m=\u001b[39;49maxs[\u001b[39m0\u001b[39;49m, \u001b[39m0\u001b[39;49m], hue\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m_step\u001b[39;49m\u001b[39m'\u001b[39;49m, palette\u001b[39m=\u001b[39;49mcmap)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpaperspace/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=69'>70</a>\u001b[0m sns\u001b[39m.\u001b[39mscatterplot(x\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtask_config/num_tasks\u001b[39m\u001b[39m'\u001b[39m, y\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpretrain/delta_dmmse\u001b[39m\u001b[39m'\u001b[39m, data\u001b[39m=\u001b[39mdf, ax\u001b[39m=\u001b[39maxs[\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m], hue\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m_step\u001b[39m\u001b[39m'\u001b[39m, palette\u001b[39m=\u001b[39mcmap)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpaperspace/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=70'>71</a>\u001b[0m sns\u001b[39m.\u001b[39mscatterplot(x\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtask_config/num_tasks\u001b[39m\u001b[39m'\u001b[39m, y\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpretrain/delta_ridge\u001b[39m\u001b[39m'\u001b[39m, data\u001b[39m=\u001b[39mdf, ax\u001b[39m=\u001b[39maxs[\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m], hue\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m_step\u001b[39m\u001b[39m'\u001b[39m, palette\u001b[39m=\u001b[39mcmap)\n",
      "File \u001b[0;32m~/Projects/icl/.venv/lib/python3.9/site-packages/seaborn/relational.py:624\u001b[0m, in \u001b[0;36mscatterplot\u001b[0;34m(data, x, y, hue, size, style, palette, hue_order, hue_norm, sizes, size_order, size_norm, markers, style_order, legend, ax, **kwargs)\u001b[0m\n\u001b[1;32m    621\u001b[0m color \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mcolor\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    622\u001b[0m kwargs[\u001b[39m\"\u001b[39m\u001b[39mcolor\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m _default_color(ax\u001b[39m.\u001b[39mscatter, hue, color, kwargs)\n\u001b[0;32m--> 624\u001b[0m p\u001b[39m.\u001b[39;49mplot(ax, kwargs)\n\u001b[1;32m    626\u001b[0m \u001b[39mreturn\u001b[39;00m ax\n",
      "File \u001b[0;32m~/Projects/icl/.venv/lib/python3.9/site-packages/seaborn/relational.py:398\u001b[0m, in \u001b[0;36m_ScatterPlotter.plot\u001b[0;34m(self, ax, kws)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot\u001b[39m(\u001b[39mself\u001b[39m, ax, kws):\n\u001b[1;32m    395\u001b[0m \n\u001b[1;32m    396\u001b[0m     \u001b[39m# --- Determine the visual attributes of the plot\u001b[39;00m\n\u001b[0;32m--> 398\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcomp_data\u001b[39m.\u001b[39mdropna()\n\u001b[1;32m    399\u001b[0m     \u001b[39mif\u001b[39;00m data\u001b[39m.\u001b[39mempty:\n\u001b[1;32m    400\u001b[0m         \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/icl/.venv/lib/python3.9/site-packages/seaborn/_base.py:1006\u001b[0m, in \u001b[0;36mVectorPlotter.comp_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1004\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1005\u001b[0m             comp_col \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mSeries(dtype\u001b[39m=\u001b[39m\u001b[39mfloat\u001b[39m, name\u001b[39m=\u001b[39mvar)\n\u001b[0;32m-> 1006\u001b[0m         comp_data\u001b[39m.\u001b[39;49minsert(\u001b[39m0\u001b[39;49m, var, comp_col)\n\u001b[1;32m   1008\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_comp_data \u001b[39m=\u001b[39m comp_data\n\u001b[1;32m   1010\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_comp_data\n",
      "File \u001b[0;32m~/Projects/icl/.venv/lib/python3.9/site-packages/pandas/core/frame.py:4821\u001b[0m, in \u001b[0;36mDataFrame.insert\u001b[0;34m(self, loc, column, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   4818\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(loc, \u001b[39mint\u001b[39m):\n\u001b[1;32m   4819\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mloc must be int\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 4821\u001b[0m value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sanitize_column(value)\n\u001b[1;32m   4822\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mgr\u001b[39m.\u001b[39minsert(loc, column, value)\n",
      "File \u001b[0;32m~/Projects/icl/.venv/lib/python3.9/site-packages/pandas/core/frame.py:4912\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4910\u001b[0m     \u001b[39mreturn\u001b[39;00m _reindex_for_setitem(value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex)\n\u001b[1;32m   4911\u001b[0m \u001b[39melif\u001b[39;00m is_dict_like(value):\n\u001b[0;32m-> 4912\u001b[0m     \u001b[39mreturn\u001b[39;00m _reindex_for_setitem(Series(value), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex)\n\u001b[1;32m   4914\u001b[0m \u001b[39mif\u001b[39;00m is_list_like(value):\n\u001b[1;32m   4915\u001b[0m     com\u001b[39m.\u001b[39mrequire_length_match(value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/Projects/icl/.venv/lib/python3.9/site-packages/pandas/core/frame.py:12025\u001b[0m, in \u001b[0;36m_reindex_for_setitem\u001b[0;34m(value, index)\u001b[0m\n\u001b[1;32m  12021\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m  12022\u001b[0m     \u001b[39m# raised in MultiIndex.from_tuples, see test_insert_error_msmgs\u001b[39;00m\n\u001b[1;32m  12023\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m value\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mis_unique:\n\u001b[1;32m  12024\u001b[0m         \u001b[39m# duplicate axis\u001b[39;00m\n\u001b[0;32m> 12025\u001b[0m         \u001b[39mraise\u001b[39;00m err\n\u001b[1;32m  12027\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m  12028\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mincompatible index of inserted column with frame index\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m  12029\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m  12030\u001b[0m \u001b[39mreturn\u001b[39;00m reindexed_value\n",
      "File \u001b[0;32m~/Projects/icl/.venv/lib/python3.9/site-packages/pandas/core/frame.py:12020\u001b[0m, in \u001b[0;36m_reindex_for_setitem\u001b[0;34m(value, index)\u001b[0m\n\u001b[1;32m  12018\u001b[0m \u001b[39m# GH#4107\u001b[39;00m\n\u001b[1;32m  12019\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m> 12020\u001b[0m     reindexed_value \u001b[39m=\u001b[39m value\u001b[39m.\u001b[39;49mreindex(index)\u001b[39m.\u001b[39m_values\n\u001b[1;32m  12021\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m  12022\u001b[0m     \u001b[39m# raised in MultiIndex.from_tuples, see test_insert_error_msmgs\u001b[39;00m\n\u001b[1;32m  12023\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m value\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mis_unique:\n\u001b[1;32m  12024\u001b[0m         \u001b[39m# duplicate axis\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/icl/.venv/lib/python3.9/site-packages/pandas/core/series.py:5094\u001b[0m, in \u001b[0;36mSeries.reindex\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5090\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m   5091\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m'\u001b[39m\u001b[39m passed as both positional and keyword argument\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   5092\u001b[0m         )\n\u001b[1;32m   5093\u001b[0m     kwargs\u001b[39m.\u001b[39mupdate({\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m: index})\n\u001b[0;32m-> 5094\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mreindex(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Projects/icl/.venv/lib/python3.9/site-packages/pandas/core/generic.py:5289\u001b[0m, in \u001b[0;36mNDFrame.reindex\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5286\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_multi(axes, copy, fill_value)\n\u001b[1;32m   5288\u001b[0m \u001b[39m# perform the reindex on the axes\u001b[39;00m\n\u001b[0;32m-> 5289\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reindex_axes(\n\u001b[1;32m   5290\u001b[0m     axes, level, limit, tolerance, method, fill_value, copy\n\u001b[1;32m   5291\u001b[0m )\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mreindex\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Projects/icl/.venv/lib/python3.9/site-packages/pandas/core/generic.py:5309\u001b[0m, in \u001b[0;36mNDFrame._reindex_axes\u001b[0;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[1;32m   5304\u001b[0m new_index, indexer \u001b[39m=\u001b[39m ax\u001b[39m.\u001b[39mreindex(\n\u001b[1;32m   5305\u001b[0m     labels, level\u001b[39m=\u001b[39mlevel, limit\u001b[39m=\u001b[39mlimit, tolerance\u001b[39m=\u001b[39mtolerance, method\u001b[39m=\u001b[39mmethod\n\u001b[1;32m   5306\u001b[0m )\n\u001b[1;32m   5308\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_axis_number(a)\n\u001b[0;32m-> 5309\u001b[0m obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_reindex_with_indexers(\n\u001b[1;32m   5310\u001b[0m     {axis: [new_index, indexer]},\n\u001b[1;32m   5311\u001b[0m     fill_value\u001b[39m=\u001b[39;49mfill_value,\n\u001b[1;32m   5312\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m   5313\u001b[0m     allow_dups\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   5314\u001b[0m )\n\u001b[1;32m   5315\u001b[0m \u001b[39m# If we've made a copy once, no need to make another one\u001b[39;00m\n\u001b[1;32m   5316\u001b[0m copy \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/icl/.venv/lib/python3.9/site-packages/pandas/core/generic.py:5355\u001b[0m, in \u001b[0;36mNDFrame._reindex_with_indexers\u001b[0;34m(self, reindexers, fill_value, copy, allow_dups)\u001b[0m\n\u001b[1;32m   5352\u001b[0m     indexer \u001b[39m=\u001b[39m ensure_platform_int(indexer)\n\u001b[1;32m   5354\u001b[0m \u001b[39m# TODO: speed up on homogeneous DataFrame objects (see _reindex_multi)\u001b[39;00m\n\u001b[0;32m-> 5355\u001b[0m new_data \u001b[39m=\u001b[39m new_data\u001b[39m.\u001b[39;49mreindex_indexer(\n\u001b[1;32m   5356\u001b[0m     index,\n\u001b[1;32m   5357\u001b[0m     indexer,\n\u001b[1;32m   5358\u001b[0m     axis\u001b[39m=\u001b[39;49mbaxis,\n\u001b[1;32m   5359\u001b[0m     fill_value\u001b[39m=\u001b[39;49mfill_value,\n\u001b[1;32m   5360\u001b[0m     allow_dups\u001b[39m=\u001b[39;49mallow_dups,\n\u001b[1;32m   5361\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m   5362\u001b[0m )\n\u001b[1;32m   5363\u001b[0m \u001b[39m# If we've made a copy once, no need to make another one\u001b[39;00m\n\u001b[1;32m   5364\u001b[0m copy \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/icl/.venv/lib/python3.9/site-packages/pandas/core/internals/managers.py:737\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[39m# some axes don't allow reindexing with dups\u001b[39;00m\n\u001b[1;32m    736\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_dups:\n\u001b[0;32m--> 737\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maxes[axis]\u001b[39m.\u001b[39;49m_validate_can_reindex(indexer)\n\u001b[1;32m    739\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim:\n\u001b[1;32m    740\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mRequested axis not found in manager\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Projects/icl/.venv/lib/python3.9/site-packages/pandas/core/indexes/base.py:4316\u001b[0m, in \u001b[0;36mIndex._validate_can_reindex\u001b[0;34m(self, indexer)\u001b[0m\n\u001b[1;32m   4314\u001b[0m \u001b[39m# trying to reindex on an axis with duplicates\u001b[39;00m\n\u001b[1;32m   4315\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_as_unique \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(indexer):\n\u001b[0;32m-> 4316\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcannot reindex on an axis with duplicate labels\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reindex on an axis with duplicate labels"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x720 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def recreate_fig_2(df, title=\"\"):\n",
    "    # Create a 2x3 grid of subplots\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "    # Set title\n",
    "\n",
    "    # Set common labels\n",
    "    fig.text(0.08, 0.5, r'$\\mathcal{T}_\\mathrm{Pretrain}$', va='center', rotation='vertical', fontsize=14)\n",
    "    fig.text(0.08, 0.26, r'$\\mathcal{T}_\\mathrm{True}$', va='center', rotation='vertical', fontsize=14)\n",
    "\n",
    "    grouped_by_num_tasks = df.groupby('task_config/num_tasks')\n",
    "\n",
    "    # Within each group, find the row with the last step\n",
    "    last_rows = grouped_by_num_tasks.apply(lambda g: g[g._step == g._step.max() & g[\"pretrain/mse\"].notna()])\n",
    "\n",
    "    # Ungroup\n",
    "    last_rows = last_rows.reset_index(drop=True)\n",
    "    print(last_rows)\n",
    "\n",
    "    # Top row\n",
    "    sns.lineplot(x='task_config/num_tasks', y='pretrain/mse', data=last_rows, ax=axs[0, 0], hue='_step')\n",
    "    sns.lineplot(x='task_config/num_tasks', y='pretrain/delta_dmmse', data=last_rows, ax=axs[0, 1], hue='_step')\n",
    "    sns.lineplot(x='task_config/num_tasks', y='pretrain/delta_ridge', data=last_rows, ax=axs[0, 2], hue='_step')\n",
    "\n",
    "    # Bottom row\n",
    "    sns.lineplot(x='task_config/num_tasks', y='true/mse', data=last_rows, ax=axs[1, 0], hue='_step')\n",
    "    sns.lineplot(x='task_config/num_tasks', y='true/delta_dmmse', data=last_rows, ax=axs[1, 1], hue='_step')\n",
    "    sns.lineplot(x='task_config/num_tasks', y='true/delta_ridge', data=last_rows, ax=axs[1, 2], hue='_step')\n",
    "\n",
    "    # Y-labels for first column\n",
    "    axs[0, 0].set_ylabel('MSE')\n",
    "    axs[1, 0].set_ylabel('MSE')\n",
    "\n",
    "    # Y-labels for second column\n",
    "    axs[0, 1].set_ylabel(r'$\\Delta_\\mathrm{PT dMMSE}$')\n",
    "    axs[1, 1].set_ylabel(r'$\\Delta_\\mathrm{PT dMMSE}$')\n",
    "\n",
    "    # Y-labels for third column\n",
    "    axs[0, 2].set_ylabel(r'$\\Delta_\\mathrm{PT Ridge}$')\n",
    "    axs[1, 2].set_ylabel(r'$\\Delta_\\mathrm{PT Ridge}$')\n",
    "\n",
    "    for i in range(3):\n",
    "        axs[1, i].set_xlabel(\"# Pretraining Tasks\")\n",
    "\n",
    "    for ax in axs.flat:\n",
    "        ax.set_xscale(\"log\")\n",
    "\n",
    "    # Hide x-labels for the top row\n",
    "    for ax in axs[0, :]:\n",
    "        ax.set_xlabel('')\n",
    "\n",
    "    plt.tight_layout(rect=[0.1, 0.1, 1, 1])\n",
    "    plt.show()\n",
    "\n",
    "def recreate_fig_2_over_time(df, title=\"\"):\n",
    "    # Create a 2x3 grid of subplots\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "    # Set title\n",
    "    plt.suptitle(title)\n",
    "\n",
    "    # Set common labels\n",
    "    fig.text(0.08, 0.5, r'$\\mathcal{T}_\\mathrm{Pretrain}$', va='center', rotation='vertical', fontsize=14)\n",
    "    fig.text(0.08, 0.26, r'$\\mathcal{T}_\\mathrm{True}$', va='center', rotation='vertical', fontsize=14)\n",
    "\n",
    "    cmap = sns.color_palette(\"viridis\", as_cmap=True)\n",
    "\n",
    "    # Top row\n",
    "    sns.scatterplot(x='task_config/num_tasks', y='pretrain/mse', data=df, ax=axs[0, 0], hue='_step', palette=cmap)\n",
    "    sns.scatterplot(x='task_config/num_tasks', y='pretrain/delta_dmmse', data=df, ax=axs[0, 1], hue='_step', palette=cmap)\n",
    "    sns.scatterplot(x='task_config/num_tasks', y='pretrain/delta_ridge', data=df, ax=axs[0, 2], hue='_step', palette=cmap)\n",
    "\n",
    "    # Bottom row\n",
    "    sns.scatterplot(x='task_config/num_tasks', y='true/mse', data=df, ax=axs[1, 0], hue='_step', palette=cmap)\n",
    "    sns.scatterplot(x='task_config/num_tasks', y='true/delta_dmmse', data=df, ax=axs[1, 1], hue='_step', palette=cmap)\n",
    "    sns.scatterplot(x='task_config/num_tasks', y='true/delta_ridge', data=df, ax=axs[1, 2], hue='_step', palette=cmap)\n",
    "\n",
    "    # Y-labels for first column\n",
    "    axs[0, 0].set_ylabel('MSE')\n",
    "    axs[1, 0].set_ylabel('MSE')\n",
    "\n",
    "    # Y-labels for second column\n",
    "    axs[0, 1].set_ylabel(r'$\\Delta_\\mathrm{PT dMMSE}$')\n",
    "    axs[1, 1].set_ylabel(r'$\\Delta_\\mathrm{PT dMMSE}$')\n",
    "\n",
    "    # Y-labels for third column\n",
    "    axs[0, 2].set_ylabel(r'$\\Delta_\\mathrm{PT Ridge}$')\n",
    "    axs[1, 2].set_ylabel(r'$\\Delta_\\mathrm{PT Ridge}$')\n",
    "\n",
    "    for i in range(3):\n",
    "        axs[1, i].set_xlabel(\"# Pretraining Tasks\")\n",
    "\n",
    "    for ax in axs.flat:\n",
    "        ax.set_xscale(\"log\")\n",
    "\n",
    "    # Hide x-labels for the top row\n",
    "    for ax in axs[0, :]:\n",
    "        ax.set_xlabel('')\n",
    "\n",
    "    plt.tight_layout(rect=[0.1, 0.1, 1, 1])\n",
    "    plt.show()\n",
    "\n",
    "# TODO: Add baselines (also make comparisons for other hyperparameters besides batch_size). \n",
    "recreate_fig_2_over_time(df, title=\"Over training\")\n",
    "recreate_fig_2(df, title=\"At the end\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise NotImplementedError(\"TODO: Fit noise terms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_enumerated_models(model, checkpointer, verbose=False):\n",
    "    for file_id in tqdm(checkpointer.file_ids, desc=\"Iterating over checkpoints\", disable=not verbose):\n",
    "        model.load_state_dict(checkpointer.load_file(file_id)[\"model\"])\n",
    "        yield file_id, model\n",
    "\n",
    "def iter_models(model, checkpointer, verbose=False):\n",
    "    for file_id in tqdm(checkpointer.file_ids, desc=\"Iterating over checkpoints\", disable=not verbose):\n",
    "        model.load_state_dict(checkpointer.load_file(file_id)[\"model\"])\n",
    "        yield model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb Cell 17\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpaperspace/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Dict, Iterable, Tuple\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bpaperspace/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdecomposition\u001b[39;00m \u001b[39mimport\u001b[39;00m PCA\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpaperspace/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcollections\u001b[39;00m \u001b[39mimport\u001b[39;00m defaultdict\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpaperspace/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdevinterp\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmechinterp\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mhooks\u001b[39;00m \u001b[39mimport\u001b[39;00m hook\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from typing import Dict, Iterable, Tuple\n",
    "from sklearn.decomposition import PCA\n",
    "from collections import defaultdict\n",
    "from devinterp.mechinterp.hooks import hook\n",
    "import numpy as np\n",
    "from icl.analysis.utils import map_evals_over_checkpoints, get_unique_run\n",
    "from icl.train import Run\n",
    "from devinfra.utils.tensors import convert_tensor, ReturnTensor\n",
    "\n",
    "\n",
    "def extract_activations_over_checkpoints(models: Iterable[nn.Module], xs, ys, *paths, return_type: ReturnTensor=\"np\"):\n",
    "    def eval_activations(model):\n",
    "        hooked_model = hook(model, *paths)\n",
    "        return {k: convert_tensor(v, return_type) for k, v in hooked_model.run_with_cache(xs, ys)[1].items() if k in paths and v is not None}\n",
    "    \n",
    "    for model in models:\n",
    "        yield eval_activations(model)\n",
    "\n",
    "\n",
    "def get_vectorized_activations_trace(models: Iterable[nn.Module], xs, ys, *paths):\n",
    "    evals: Dict[str, list] = defaultdict(list)\n",
    "    \n",
    "    for activations in extract_activations_over_checkpoints(models, xs, ys, *paths):\n",
    "        for path, activation in activations.items():\n",
    "            evals[path].append(activation)\n",
    "\n",
    "    return {\n",
    "        k: np.array(v).reshape(len(v), -1) for k, v in evals.items()\n",
    "    }\n",
    "\n",
    "\n",
    "def get_pca_activations_trace(models: Iterable[nn.Module], xs, ys, *paths, num_components=3) -> Dict[str, Tuple[PCA, np.ndarray]]:\n",
    "    results = {}\n",
    "\n",
    "    for path, activations in get_vectorized_activations_trace(models, xs, ys, *paths).items():\n",
    "        pca = PCA(n_components=num_components)\n",
    "        activations_reduced = pca.fit_transform(activations)\n",
    "        results[path] = pca, activations_reduced\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo = Run(configs[2])\n",
    "# demo_models = iter_models(demo.model, demo.checkpointer, verbose=True)\n",
    "\n",
    "# demo_logits_pca_3, demo_logits_reduced_3  = get_pca_activations_trace(\n",
    "#     demo_models, \n",
    "#     demo.evaluator.pretrain_xs, \n",
    "#     demo.evaluator.pretrain_ys, \n",
    "#     \"token_sequence_transformer\",\n",
    "#     num_components=3\n",
    "# )['token_sequence_transformer']\n",
    "\n",
    "# steps = demo.checkpointer.file_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "def plot_sample_evolution(steps, samples, title=\"Sample Evolution in 2D Plane\", num_points_to_label=10, save: Optional[str] = None, ax: Optional = None, connect_dots=False):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(15, 8))\n",
    "    \n",
    "    # Main plot\n",
    "    sc = ax.scatter(samples[:, 0], samples[:, 1], c=steps, cmap='viridis', s=50, alpha=0.6)\n",
    "\n",
    "    if connect_dots:\n",
    "        ax.plot(samples[:, 0], samples[:, 1], c='black', alpha=0.2)\n",
    "\n",
    "    plt.colorbar(sc, ax=ax, label='Steps')\n",
    "    \n",
    "    # Label some points\n",
    "    total_samples = len(samples)\n",
    "    step = total_samples // num_points_to_label\n",
    "    for i in range(0, total_samples, step):\n",
    "        sample_step = steps[i]\n",
    "        ax.text(samples[i, 0], samples[i, 1], str(sample_step), fontsize=12, ha='right', va='bottom')\n",
    "        \n",
    "    ax.set_xlabel('Feature 1')\n",
    "    ax.set_ylabel('Feature 2')\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    # Inset for explained variance at the bottom right corner with slight transparency\n",
    "    if save:\n",
    "        parent_dir = os.path.dirname(save)\n",
    "\n",
    "        if not os.path.exists(parent_dir):\n",
    "            os.makedirs(parent_dir)\n",
    "\n",
    "        plt.savefig(save)\n",
    "\n",
    "\n",
    "def plot_explained_variance(pca, title=\"Explained Variance\", ax: Optional[plt.Axes] = None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "    ax.bar(range(len(pca.explained_variance_ratio_)), pca.explained_variance_ratio_)\n",
    "\n",
    "    for i, ratio in enumerate(pca.explained_variance_ratio_):\n",
    "        ax.text(i, ratio, f\"{ratio:.2f}\", fontsize=12, ha='center', va='bottom')\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Component')\n",
    "    ax.set_ylabel('Variance')\n",
    "\n",
    "\n",
    "def plot_sample_evolution_with_inset(steps, samples, pca, title=\"Sample Evolution in 2D Plane\", num_points_to_label=10, save: Optional[str] = None, ax: Optional = None, connect_dots=False):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(15, 8))\n",
    "    \n",
    "    plot_sample_evolution(steps, samples, title=title, num_points_to_label=num_points_to_label, ax=ax, connect_dots=connect_dots)\n",
    "\n",
    "    axins = ax.inset_axes([0.7, 0.05, 0.25, 0.25])  # x, y, width, height\n",
    "    axins.patch.set_alpha(0.5)\n",
    "    plot_explained_variance(pca, ax=axins)\n",
    "    \n",
    "    # Inset for explained variance at the bottom right corner with slight transparency\n",
    "    if save:\n",
    "        parent_dir = os.path.dirname(save)\n",
    "\n",
    "        if not os.path.exists(parent_dir):\n",
    "            os.makedirs(parent_dir)\n",
    "\n",
    "        plt.savefig(save)\n",
    "\n",
    "    \n",
    "def plot_multiple_slices(steps, samples, pca, title=\"Sample Evolution in 2D Plane\", num_points_to_label=10, save: Optional[str] = None, ax: Optional = None, connect_dots=False):\n",
    "    num_pca_components = samples.shape[-1]\n",
    "    num_rows = num_pca_components - 1\n",
    "    fig, ax = plt.subplots(num_rows, num_rows, figsize=(20, 20))\n",
    "\n",
    "    fig.suptitle(title)\n",
    "\n",
    "    for i in range(num_pca_components):\n",
    "        for j in range(i):\n",
    "            sc = ax[i-1, j].scatter(samples[:, i], samples[:, j], c=steps, cmap='viridis', s=50, alpha=0.6)\n",
    "            ax[i-1, j].set_xlabel(f'Feature {i}')\n",
    "            ax[i-1, j].set_ylabel(f'Feature {j}')\n",
    "            ax[i-1, j].set_title(f'Feature {i} vs Feature {j}')\n",
    "\n",
    "            if connect_dots:\n",
    "                ax[i-1, j].plot(samples[:, i], samples[:, j], c='black', alpha=0.2)\n",
    "\n",
    "            # Label some points\n",
    "            total_samples = len(samples)\n",
    "            step = total_samples // num_points_to_label\n",
    "            for k in range(0, total_samples, step):\n",
    "                sample_step = steps[k]\n",
    "                ax[i-1, j].text(samples[k, i], samples[k, j], str(sample_step), fontsize=12, ha='right', va='bottom')\n",
    "\n",
    "        for j in range(i + 1, num_rows):\n",
    "            ax[i, j].axis('off')\n",
    "\n",
    "\n",
    "    ax[0, -1].axis('on')\n",
    "    plot_explained_variance(pca, ax=ax[0, -1])\n",
    "\n",
    "    plt.colorbar(sc, ax=ax[0, -1], label='Steps')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save:\n",
    "        parent_dir = os.path.dirname(save)\n",
    "\n",
    "        if not os.path.exists(parent_dir):\n",
    "            os.makedirs(parent_dir)\n",
    "\n",
    "        plt.savefig(save)\n",
    "\n",
    "# plot_multiple_slices(steps, demo_logits_reduced_3, demo_logits_pca_3, title=demo.config.to_latex(), connect_dots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for config, checkpointer in zip(configs, checkpointers):\n",
    "    run = Run(config)\n",
    "    _steps = checkpointer.file_ids\n",
    "\n",
    "    _pca, _logits_reduced = get_pca_activations_trace(\n",
    "        iter_models(run.model, run.checkpointer, verbose=True), \n",
    "        run.evaluator.pretrain_xs, \n",
    "        run.evaluator.pretrain_ys, \n",
    "        \"token_sequence_transformer\",\n",
    "        num_components=3\n",
    "    )['token_sequence_transformer']\n",
    "    \n",
    "    plot_multiple_slices(\n",
    "        _steps, \n",
    "        _logits_reduced, \n",
    "        _pca, \n",
    "        connect_dots=True, \n",
    "        title=config.to_latex(), \n",
    "        save=FIGURES / (\"pca3-logits-\" + config.to_slug(delimiter=\"-\") + \".png\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention Entropies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Union\n",
    "from torchtyping import TensorType\n",
    "from devinfra.utils.iterables import map_nested\n",
    "\n",
    "def compute_attention_entropies(attn: TensorType[\"B\", \"H\", \"2K\", \"2K\"]):\n",
    "    \"\"\"\n",
    "    Computes the entropy of each token in each head, averaged across the batch, \n",
    "    then averages this over heads. \n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # Threshold attention weights to avoid log(0)\n",
    "    log_attention = torch.where(attn > 0, torch.log(attn), torch.tensor(0.0).to(attn.device))\n",
    "    entropy_per_token = - torch.sum(attn * log_attention, dim=-1).mean(dim=0).squeeze(-1) # TensorType[\"H\", \"2K\"]\n",
    "\n",
    "    num_heads, num_tokens = entropy_per_token.shape\n",
    "\n",
    "    entropy_per_head = entropy_per_token.mean(dim=-1) # TensorType[\"H\"]\n",
    "    entropy = entropy_per_head.mean() # TensorType[]    \n",
    "    \n",
    "    # Each token computes entropy over a variable context length, so we normalize by the maximum possible entropy\n",
    "    # for a token with a fixed context length.\n",
    "\n",
    "    max_entropy_per_token = torch.log2(torch.arange(1, num_tokens + 1).to(attn.device)) # TensorType[\"H\", \"2K\"]\n",
    "    max_entropy_per_token[0] = 1. # Special case for the first token to avoid dividing by 0\n",
    "\n",
    "    entropy_per_token_normalized = entropy_per_token / max_entropy_per_token\n",
    "    entropy_per_head_normalized = entropy_per_token_normalized.mean(dim=-1) # TensorType[\"H\"]\n",
    "    entropy_normalized = entropy_per_head_normalized.mean() # TensorType[]    \n",
    "\n",
    "    results: Dict[str, Union[torch.Tensor, Dict[str, torch.Tensor]]] = {\"mean\": entropy, \"mean_normalized\": entropy_normalized}\n",
    "\n",
    "    for i in range(num_heads):\n",
    "        head_results = {\"mean\": entropy_per_head[i], \"mean_normalized\": entropy_per_head_normalized[i]}\n",
    "\n",
    "        for j in range(num_tokens):\n",
    "            head_results[f\"token_{j}\"] = entropy_per_token[i, j]\n",
    "            head_results[f\"token_{j}_normalized\"] = entropy_per_token_normalized[i, j]\n",
    "\n",
    "        results[f\"head_{i}\"] = head_results\n",
    "\n",
    "    return map_nested(lambda x: convert_tensor(x, \"np\"), results)\n",
    "\n",
    "\n",
    "def get_attention_entropies_trace(\n",
    "    steps: List[int],\n",
    "    models: Iterable[nn.Module],\n",
    "    xs: torch.Tensor,\n",
    "    ys: torch.Tensor,\n",
    "    **paths,\n",
    "):\n",
    "    results = defaultdict(list)\n",
    "    reverse_paths = {v: k for k, v in paths.items()}\n",
    "\n",
    "    for activations in extract_activations_over_checkpoints(models, xs, ys, *paths.values(), return_type=\"pt\"):\n",
    "        for k, v in activations.items():\n",
    "            path = reverse_paths[k]\n",
    "            results[path].append(compute_attention_entropies(v))\n",
    "\n",
    "    values = []\n",
    "\n",
    "    for i in range(len(steps)):\n",
    "        value = {}\n",
    "\n",
    "        for block in results.keys():\n",
    "            value[block] = results[block][i]\n",
    "        \n",
    "        value[\"step\"] = steps[i]\n",
    "        values.append(flatten_dict(value, flatten_lists=True))\n",
    "\n",
    "    return pd.DataFrame(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention_patterns(df: pd.DataFrame, num_blocks: int, num_heads: int, num_tokens: int, title=\"\", save: Optional[str] = None, normalized=False, figsize=(20, 25), logx=False, logy=False):\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    plt.suptitle(title)\n",
    "\n",
    "    num_cols = num_blocks * 2\n",
    "    num_rows = 1 + 1 + num_heads\n",
    "\n",
    "    suffix = \"\" if not normalized else \"_normalized\"\n",
    "    suffix_title = \"\" if not normalized else \" (Normalized)\"\n",
    "\n",
    "    # Create subplot for mean entropy of first two blocks\n",
    "    ax0 = plt.subplot2grid((num_rows, num_cols), (0, 0), colspan=num_cols)\n",
    "    block_cmap = sns.color_palette(\"viridis\", num_blocks)\n",
    "\n",
    "    for b in range(num_blocks):\n",
    "        ax0.plot(df.step, df[f\"block_{b}/mean{suffix}\"], label=f\"block_{b}\", color=block_cmap[b])\n",
    "\n",
    "    ax0.set_title(\"Blocks\")\n",
    "    ax0.set_xlabel(\"Step\")\n",
    "    ax0.set_ylabel(f\"Entropy{suffix_title}\")\n",
    "    ax0.legend()\n",
    "\n",
    "    # Create subplots for each block, showing entropy in different heads\n",
    "    ax1 = [plt.subplot2grid((num_rows, num_cols), (1, i*2), colspan=2) for i in range(num_blocks)]\n",
    "    head_cmap = sns.color_palette(\"viridis\", num_heads)\n",
    "    \n",
    "    for b in range(num_blocks):\n",
    "        ax1[b].set_title(f\"Block {b}\")\n",
    "        ax1[b].set_xlabel(\"Step\")\n",
    "        ax1[b].set_ylabel(f\"Entropy{suffix_title}\")\n",
    "        for h in range(num_heads):\n",
    "            series = df[f\"block_{b}/head_{h}/mean{suffix}\"]\n",
    "            ax1[b].plot(df.step, series, label=f\"Head {h}\", color=head_cmap[h])\n",
    "\n",
    "    ax1[0].legend()\n",
    "\n",
    "    # Create subplots for each head in each block, detailing entropy for each token\n",
    "    ax2 = [plt.subplot2grid((num_rows, num_cols), (i//(num_cols) + 2, i%(num_cols))) for i in range(num_heads * num_blocks * 2)]\n",
    "    ax_idx = 0\n",
    "    token_cmap = sns.color_palette(\"viridis\", num_tokens)\n",
    "\n",
    "\n",
    "    for h in range(num_heads):\n",
    "        for b in range(num_blocks):\n",
    "            for x_or_y in (1, 0):\n",
    "                ax2[ax_idx].set_title(f\"Block {b} Head {h}\")\n",
    "                ax2[ax_idx].set_xlabel(\"Step\")\n",
    "                ax2[ax_idx].set_ylabel(f\"Entropy{suffix_title}\")\n",
    "\n",
    "                for t in range(1-int(x_or_y), num_tokens, 2):\n",
    "                    series = df[f\"block_{b}/head_{h}/token_{t}{suffix}\"]\n",
    "                    ax2[ax_idx].plot(df.step, series, label=f\"Token {t}\", color=token_cmap[t])\n",
    "                    \n",
    "                ax_idx += 1\n",
    "\n",
    "    ax2[0].legend()\n",
    "    ax2[1].legend()\n",
    "\n",
    "    for ax in [ax0, *ax1, *ax2]:\n",
    "        if logx:\n",
    "            ax.set_xscale(\"log\")\n",
    "        if logy:\n",
    "            ax.set_yscale(\"log\")\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "    if save:\n",
    "        parent_dir = os.path.dirname(save)\n",
    "        if not os.path.exists(parent_dir):\n",
    "            os.makedirs(parent_dir)\n",
    "        plt.savefig(save)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = Run(configs[2])\n",
    "\n",
    "num_blocks = demo.config.task_config.num_layers\n",
    "num_heads = demo.config.task_config.num_heads\n",
    "num_tokens = demo.config.task_config.max_examples\n",
    "\n",
    "df = get_attention_entropies_trace(\n",
    "    demo.checkpointer.file_ids,\n",
    "    iter_models(demo.model, demo.checkpointer, verbose=True), \n",
    "    demo.evaluator.pretrain_xs, \n",
    "    demo.evaluator.pretrain_ys, \n",
    "    **{f\"block_{b}\": f\"token_sequence_transformer.blocks.{b}.attention.attention_softmax\" for b in range(num_blocks)}\n",
    ")\n",
    "\n",
    "demo_attn_entropy_slug = \"attn-S-\" + demo.config.to_slug(delimiter=\"-\")\n",
    "\n",
    "for normalized in (True, False):\n",
    "    plot_attention_patterns(\n",
    "        df, \n",
    "        num_blocks=num_blocks, \n",
    "        num_heads=num_heads, \n",
    "        num_tokens=num_tokens, \n",
    "        title=demo.config.to_latex(), \n",
    "        save=FIGURES / (demo_attn_entropy_slug + \".png\"),\n",
    "        figsize=(25, 25),\n",
    "        normalized=normalized\n",
    "    )\n",
    "\n",
    "# df.to_csv(ANALYSIS / (demo_attn_entropy_slug + \".csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for config, checkpointer in zip(configs, checkpointers):\n",
    "    run = Run(config)\n",
    "    \n",
    "    num_blocks = run.config.task_config.num_layers\n",
    "    num_heads = run.config.task_config.num_heads\n",
    "    num_tokens = run.config.task_config.max_examples\n",
    "\n",
    "    df = get_attention_entropies_trace(\n",
    "        checkpointer.file_ids,\n",
    "        iter_models(run.model, checkpointer, verbose=True), \n",
    "        run.evaluator.pretrain_xs, \n",
    "        run.evaluator.pretrain_ys, \n",
    "        **{f\"block_{b}\": f\"token_sequence_transformer.blocks.{b}.attention.attention_softmax\" for b in range(num_blocks)}\n",
    "    )\n",
    "    \n",
    "    slug = \"attn-S-\" + run.config.to_slug(delimiter=\"-\")\n",
    "\n",
    "    plot_attention_patterns(\n",
    "        df, \n",
    "        num_blocks=num_blocks, \n",
    "        num_heads=num_heads, \n",
    "        num_tokens=num_tokens, \n",
    "        title=run.config.to_latex(), \n",
    "        save=FIGURES / (slug + \".png\"),\n",
    "        figsize=(25, 25),\n",
    "        normalized=True\n",
    "    )\n",
    "\n",
    "    df.to_csv(ANALYSIS / (slug + \".csv\"))\n",
    "\n",
    "os.system('say \"Your program has finished.\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RLCTs & Covariance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from icl.analysis.rlct import make_slt_evals\n",
    "\n",
    "def generate_slt_observables(\n",
    "    steps: List[int],\n",
    "    models: Iterable[nn.Module],\n",
    "    xs: torch.Tensor,\n",
    "    ys: torch.Tensor,\n",
    "    **kwargs\n",
    "):\n",
    "    xs, ys = run.evaluator.pretrain_xs, run.evaluator.pretrain_ys\n",
    "    trainset = torch.utils.data.TensorDataset(xs, ys)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=len(xs))\n",
    "    eval_rlcts = make_slt_evals(\n",
    "        dataset=trainset,\n",
    "        loader=trainloader,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "    for step, model in zip(steps, models):\n",
    "        yield step, eval_rlcts(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([192, 64])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from icl.train import Run\n",
    "demo = Run(configs[2])\n",
    "attn_weights = demo.model.token_sequence_transformer.blocks[0].attention.attention.weights\n",
    "attn_weights.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "L2H2\n",
      "Full: 603,979,776 (2.42 Gb)\n",
      "Within heads: 150,994,944 (0.60 Gb)\n",
      "Between heads: 150,994,944 (0.60 Gb)\n",
      "Reduction: -301,989,888 (-50.00%)\n",
      "\n",
      "L2H4\n",
      "Full: 603,979,776 (2.42 Gb)\n",
      "Within heads: 75,497,472 (0.30 Gb)\n",
      "Between heads: 150,994,944 (0.60 Gb)\n",
      "Reduction: -377,487,360 (-62.50%)\n",
      "\n",
      "L4H2\n",
      "Full: 2,415,919,104 (9.66 Gb)\n",
      "Within heads: 301,989,888 (1.21 Gb)\n",
      "Between heads: 452,984,832 (1.81 Gb)\n",
      "Reduction: -1,660,944,384 (-68.75%)\n",
      "\n",
      "L4H4\n",
      "Full: 2,415,919,104 (9.66 Gb)\n",
      "Within heads: 150,994,944 (0.60 Gb)\n",
      "Between heads: 452,984,832 (1.81 Gb)\n",
      "Reduction: -1,811,939,328 (-75.00%)\n",
      "\n",
      "L8H2\n",
      "Full: 9,663,676,416 (38.65 Gb)\n",
      "Within heads: 603,979,776 (2.42 Gb)\n",
      "Between heads: 1,056,964,608 (4.23 Gb)\n",
      "Reduction: -8,002,732,032 (-82.81%)\n",
      "\n",
      "L8H4\n",
      "Full: 9,663,676,416 (38.65 Gb)\n",
      "Within heads: 301,989,888 (1.21 Gb)\n",
      "Between heads: 1,056,964,608 (4.23 Gb)\n",
      "Reduction: -8,304,721,920 (-85.94%)\n"
     ]
    }
   ],
   "source": [
    "numel_per_layer = attn_weights.numel()\n",
    "\n",
    "def num_params_to_gb(num: int):\n",
    "    return f\"{num * (32 / 8) / (10 ** 9):.2f} Gb\"\n",
    "\n",
    "for num_blocks in [2, 4, 8]:\n",
    "    for num_heads in [2, 4]:\n",
    "        numel_per_head = numel_per_layer // num_heads\n",
    "\n",
    "        within_head_cov_size = (numel_per_head ** 2)  * num_heads * num_blocks\n",
    "        between_head_cov_size = (numel_per_head ** 2) * num_heads * num_heads * (num_blocks-1)\n",
    "\n",
    "        full_cov_size = (numel_per_layer * num_blocks) ** 2\n",
    "\n",
    "        reduction = full_cov_size - within_head_cov_size - between_head_cov_size\n",
    "\n",
    "        print(f\"\\nL{num_blocks}H{num_heads}\")\n",
    "        print(\"Full:\", f\"{full_cov_size:,} ({num_params_to_gb(full_cov_size)})\")\n",
    "        print(\"Within heads:\", f\"{within_head_cov_size:,} ({num_params_to_gb(within_head_cov_size)})\")\n",
    "        print(\"Between heads:\", f\"{between_head_cov_size:,} ({num_params_to_gb(between_head_cov_size)})\")\n",
    "        print(\"Reduction:\", f\"-{reduction:,} (-{reduction/full_cov_size * 100:.2f}%)\")\n",
    "\n",
    "# attn_weights.numel(), f\"{(32 // 8 * (attn_weights.numel() * 2 ) ** 2):,}\", attn_weights.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn0_weights = demo.model.token_sequence_transformer.blocks[0].attention.attention.weight\n",
    "attn1_weights = demo.model.token_sequence_transformer.blocks[1].attention.attention.weight\n",
    "\n",
    "# vectorize and stack\n",
    "attn_weights = torch.concatenate([attn0_weights.flatten().T, attn1_weights.flatten().T])\n",
    "\n",
    "cov = (attn_weights.unsqueeze(0) * attn_weights.unsqueeze(-1)).squeeze(0).detach().cpu().numpy()\n",
    "print(cov.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-9.3339605e-07,  9.3316061e-07,  1.2732251e+02], dtype=float32),\n",
       " array([[-1.3109646e-03, -9.3842647e-04,  4.0082061e-03],\n",
       "        [-2.3621570e-03, -1.1544566e-05,  2.8477809e-03],\n",
       "        [-2.3920022e-02, -8.0367047e-03, -9.5447274e-03],\n",
       "        ...,\n",
       "        [-9.4086705e-03,  8.2392953e-03,  8.5932221e-03],\n",
       "        [-9.2025725e-03, -1.7455228e-02,  1.0016643e-02],\n",
       "        [ 6.8640907e-04, -1.0135546e-04,  1.0584297e-03]], dtype=float32))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evals, evecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12288,) (12288,)\n",
      "(4096,) (4096,) (4096,)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb Cell 32\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpaperspace/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39mprint\u001b[39m(W_Q\u001b[39m.\u001b[39mshape, W_K\u001b[39m.\u001b[39mshape, W_V\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpaperspace/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m [\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpaperspace/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m         (W_Q[i \u001b[39m*\u001b[39m head_size : (i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m head_size, :], \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpaperspace/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m          W_K[i \u001b[39m*\u001b[39m head_size : (i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m head_size, :],\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpaperspace/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m          W_V[i \u001b[39m*\u001b[39m head_size : (i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m head_size, :]) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_heads)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpaperspace/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     ]\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bpaperspace/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m attn0_split \u001b[39m=\u001b[39m prettify_attn_weights_shape(attn0)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpaperspace/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m attn1_split \u001b[39m=\u001b[39m prettify_attn_weights_shape(attn1)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpaperspace/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m attn0_split, attn1_split\n",
      "\u001b[1;32m/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb Cell 32\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpaperspace/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m W_Q, W_K, W_V \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msplit(W, \u001b[39m3\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpaperspace/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(W_Q\u001b[39m.\u001b[39mshape, W_K\u001b[39m.\u001b[39mshape, W_V\u001b[39m.\u001b[39mshape)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bpaperspace/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mreturn\u001b[39;00m [\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpaperspace/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     (W_Q[i \u001b[39m*\u001b[39m head_size : (i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m head_size, :], \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpaperspace/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m      W_K[i \u001b[39m*\u001b[39m head_size : (i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m head_size, :],\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpaperspace/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m      W_V[i \u001b[39m*\u001b[39m head_size : (i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m head_size, :]) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_heads)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpaperspace/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m ]\n",
      "\u001b[1;32m/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb Cell 32\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpaperspace/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m W_Q, W_K, W_V \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msplit(W, \u001b[39m3\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpaperspace/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(W_Q\u001b[39m.\u001b[39mshape, W_K\u001b[39m.\u001b[39mshape, W_V\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpaperspace/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mreturn\u001b[39;00m [\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bpaperspace/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     (W_Q[i \u001b[39m*\u001b[39;49m head_size : (i \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m) \u001b[39m*\u001b[39;49m head_size, :], \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpaperspace/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m      W_K[i \u001b[39m*\u001b[39m head_size : (i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m head_size, :],\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpaperspace/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m      W_V[i \u001b[39m*\u001b[39m head_size : (i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m head_size, :]) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_heads)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpaperspace/home/paperspace/Projects/icl/notebooks/small-model-report.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m ]\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "attn0, attn1 = np.split(evecs[:, 0], [attn0_weights.numel()])\n",
    "\n",
    "print(attn0.shape, attn1.shape)\n",
    "\n",
    "def prettify_attn_weights_shape(W, num_heads=4, embed_dim=64):\n",
    "    head_size = embed_dim // num_heads\n",
    "\n",
    "    W_Q, W_K, W_V = np.split(W, 3, axis=0)\n",
    "    print(W_Q.shape, W_K.shape, W_V.shape)\n",
    "    return [\n",
    "        (W_Q[i * head_size : (i + 1) * head_size, :], \n",
    "         W_K[i * head_size : (i + 1) * head_size, :],\n",
    "         W_V[i * head_size : (i + 1) * head_size, :]) for i in range(num_heads)\n",
    "    ]\n",
    "\n",
    "attn0_split = prettify_attn_weights_shape(attn0)\n",
    "attn1_split = prettify_attn_weights_shape(attn1)\n",
    "\n",
    "attn0_split, attn1_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-19-a66d0cb2f1ca>, line 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[19], line 16\u001b[0;36m\u001b[0m\n\u001b[0;31m    num_chains=20,\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from scipy.sparse.linalg import eigsh\n",
    "\n",
    "\n",
    "# wandb.init(entity=\"devinterp\", project=\"icl\")\n",
    "\n",
    "for config, checkpointer in zip(configs, checkpointers):\n",
    "    run = Run(config)\n",
    "    observables_over_time = []\n",
    "    \n",
    "    for step, observables in generate_slt_observables(\n",
    "        checkpointer.file_ids,\n",
    "        iter_models(run.model, checkpointer, verbose=True), \n",
    "        run.evaluator.pretrain_xs, \n",
    "        run.evaluator.pretrain_ys, \n",
    "        cores=4,\n",
    "        lr=1e-5,\n",
    "        num_draws=100,\n",
    "        elasticity=1.,\n",
    "        num_chains=20,\n",
    "        device=\"cuda\",\n",
    "        covariance_paths=[\n",
    "            f\"token_sequence_transformer.blocks.{b}.attention.attention\"\n",
    "            for b in range(run.config.task_config.num_layers)\n",
    "        ]\n",
    "    ):\n",
    "        # wandb.log(observables, step=step)\n",
    "        observables[\"step\"] = step\n",
    "        covariances = observables.pop(\"covariances\")\n",
    "\n",
    "        # I only want the two largest eigenvalues in evals and evecs\n",
    "        covariances = np.linalg.eigvalsh(covariances)\n",
    "        evals, evecs = eigsh(covariances, k=3, which='LM')\n",
    "        \n",
    "        observables_over_time.append(observables)\n",
    "        print(yaml.dump({\n",
    "            **observables,\n",
    "            \"covariances\": covariances.shape\n",
    "        }))\n",
    "\n",
    "        raise NotImplementedError(\"TODO: Save covariances\")\n",
    "\n",
    "    df = pd.DataFrame(observables_over_time)\n",
    "    slug = \"slt-\" + run.config.to_slug(delimiter=\"-\")\n",
    "    df.to_csv(ANALYSIS / (slug + \".csv\"))\n",
    "\n",
    "# wandb.finish()\n",
    "os.system('say \"Your program has finished.\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "from icl.config import ICLConfig\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def gather_images_side_by_side(folder, save: Optional[str] = None, delete: bool = True):\n",
    "    \"\"\"\n",
    "    Assumes folder contains folders that contain pngs. \n",
    "    \"\"\"\n",
    "    folder = Path(folder)\n",
    "    folder_paths = folder.glob(\"*\")\n",
    "\n",
    "    # Create a dictionary to store images by filename\n",
    "    images_by_filename = {}\n",
    "\n",
    "    if save:\n",
    "        save = Path(save)\n",
    "\n",
    "        if not os.path.exists(save):\n",
    "            os.makedirs(save)\n",
    "\n",
    "    # Load images from each folder and organize them by filename\n",
    "    for folder_path in folder_paths:\n",
    "        filenames = [f for f in os.listdir(folder_path) if f.endswith('.png')] \n",
    "        for filename in filenames:\n",
    "            img = Image.open(os.path.join(folder_path, filename))\n",
    "            if filename in images_by_filename:\n",
    "                images_by_filename[filename].append(img)\n",
    "            else:\n",
    "                images_by_filename[filename] = [img]\n",
    "\n",
    "    # Create comparison images for each unique filename\n",
    "    for filename, image_list in images_by_filename.items():\n",
    "        # Calculate the width and height of the result image\n",
    "        width = sum(img.width for img in image_list)\n",
    "        height = max(img.height for img in image_list)\n",
    "\n",
    "        # Create a new image for the comparison\n",
    "        result_image = Image.new('RGB', (width, height))\n",
    "\n",
    "        # Paste images side by side\n",
    "        x_offset = 0\n",
    "        for img in image_list:\n",
    "            result_image.paste(img, (x_offset, 0))\n",
    "            x_offset += img.width\n",
    "\n",
    "        # Display or save the result image\n",
    "        if save: \n",
    "            result_image.save(save / filename)  # You can replace this with result_image.save() to save the comparison images\n",
    "\n",
    "    if delete:\n",
    "        # Delete the temporary folder\n",
    "        shutil.rmtree(folder)\n",
    "\n",
    "\n",
    "def plot_activations(config: ICLConfig, activations: Dict[str, torch.Tensor], save: Optional[str] = None):\n",
    "    B = 1\n",
    "    E = config.task_config.embed_size\n",
    "    T = 2 * config.task_config.max_examples\n",
    "    H = config.task_config.num_heads\n",
    "\n",
    "    def optionally_rotate(x, name):\n",
    "        if len(x.shape) != 2:\n",
    "            raise ValueError(\"Tensor should have two dimensions.\")\n",
    "\n",
    "        if x.shape[0] > x.shape[1]:\n",
    "            return x.T, f\"{name}.T\"\n",
    "        \n",
    "        return x, name \n",
    "\n",
    "    def separate_attention(qkv: TensorType[\"B\", \"T\", \"C\"], num_heads: int, batch_size: int, head_size: int, num_tokens: int):\n",
    "        return (qkv   \n",
    "            .view(batch_size, num_tokens, num_heads, 3*head_size)\n",
    "            .transpose(-2, -3)     \n",
    "            .split(head_size, dim=-1)\n",
    "        )\n",
    "\n",
    "    if save:\n",
    "        save = Path(save)\n",
    "\n",
    "        if not os.path.exists(save):\n",
    "            os.makedirs(save)\n",
    "\n",
    "    for location, v in activations.items():\n",
    "        activation_slice = v[0]\n",
    "\n",
    "        if location.endswith(\"attention.attention\"):\n",
    "            q, k, v = separate_attention(v, num_heads=H, batch_size=B, head_size=E//H, num_tokens=T)\n",
    "            qk = q @ k.transpose(-2, -1)\n",
    "            q, k, qk, v = q[0], k[0], v[0], qk[0]\n",
    "            \n",
    "            fig, axs = plt.subplots(H, 4, figsize=(15, 15))\n",
    "\n",
    "            for j, (name, x) in enumerate(zip([\"Q\", \"K\", \"QK\", \"V\"], [q, k, qk, v])):\n",
    "                for h in range(H):\n",
    "                    ax = axs[h, j]\n",
    "                    im = ax.matshow(x[h].detach().to(\"cpu\").numpy())\n",
    "                    ax.set_title(f\"{h}.{name}\")\n",
    "                    # fig.colorbar(im, ax=ax)\n",
    "\n",
    "            plt.suptitle(location)\n",
    "            plt.tight_layout()\n",
    "\n",
    "            if save:\n",
    "                plt.savefig(save / (location + \".png\"))\n",
    "                plt.close(fig)\n",
    "\n",
    "                del fig\n",
    "                del axs\n",
    "\n",
    "        elif len(activation_slice.shape) == 2:\n",
    "            fig = plt.figure()\n",
    "\n",
    "            x, location = optionally_rotate(activation_slice, location)\n",
    "            plt.matshow(x.detach().to(\"cpu\").numpy())\n",
    "            plt.title(f\"{location}\")\n",
    "            # fig.colorbar(im)\n",
    "\n",
    "            if save:\n",
    "                plt.savefig(save / (location + \".png\"))\n",
    "                plt.close(fig)\n",
    "\n",
    "                del fig\n",
    "\n",
    "\n",
    "        elif len(activation_slice.shape) == 3:  # [heads, xs, ys]\n",
    "            heads, xs, ys = activation_slice.shape\n",
    "            fig, axs = plt.subplots(1, heads, figsize=(15, 15))\n",
    "\n",
    "            for j in range(heads):\n",
    "                ax = axs[j]\n",
    "                x, name = optionally_rotate(activation_slice[j], str(j))\n",
    "                im = ax.matshow(x.detach().to(\"cpu\").numpy())\n",
    "                ax.set_title(f\"{name}\")\n",
    "                # fig.colorbar(im, ax=ax)\n",
    "            \n",
    "            plt.suptitle(f\"{location}.#\")\n",
    "            plt.tight_layout()\n",
    "\n",
    "            if save:\n",
    "                plt.savefig(save / (location + \".png\"))\n",
    "                plt.close(fig)\n",
    "\n",
    "            del fig\n",
    "            del axs\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported number of dimensions.\")\n",
    "\n",
    "\n",
    "def compare_activations(config: ICLConfig, model, x: TensorType[\"B\", \"D\"], y: TensorType[\"B\", 1], save: Optional[str] = None, names: Optional[List[str]] = None):\n",
    "    B = len(x)\n",
    "    hooked_model = hook(model)\n",
    "\n",
    "    activations = {}\n",
    "    output, activations_ = hooked_model.run_with_cache(x, y)\n",
    "    activations[\"x\"] = x\n",
    "    activations[\"y\"] = y\n",
    "    activations[\"output\"] = output\n",
    "    activations.update(activations_)\n",
    "\n",
    "    def activations_per_sample(activations, index, keep_batch_dim=False):\n",
    "        if keep_batch_dim:\n",
    "            print({k: type(v) for k, v in activations.items()})\n",
    "            return {k: v[index].unsqueeze(0) for k, v in activations.items() if v is not None}\n",
    "        \n",
    "        return {k: v[index] for k, v in activations.items() if v is not None}\n",
    "\n",
    "    tmp_folder = Path(\"tmp\")\n",
    "\n",
    "    names = names or list(map(str, range(B)))\n",
    "\n",
    "    for (name, b) in zip(names, range(B)):\n",
    "        activations_b = activations_per_sample(activations, b, keep_batch_dim=True)\n",
    "        plot_activations(config, activations_b, save=tmp_folder / str(name))\n",
    "\n",
    "    gather_images_side_by_side(tmp_folder, save=save, delete=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = Run.create_and_restore(configs[2])\n",
    "compare_activations(demo.config, demo.model, demo.evaluator.pretrain_xs[:3], demo.evaluator.pretrain_ys[:3], save=FIGURES / \"demo\", names=[\"$x_0$\", \"$x_1$\", \"$x_2$\"])\n",
    "# gather_images_side_by_side(\"tmp\", save=FIGURES/\"demo\", delete=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a few samples for each model at the end of training\n",
    "from icl.train import Run\n",
    "\n",
    "NUM_SAMPLES = 4\n",
    "\n",
    "for config, checkpointer in zip(configs, checkpointers):\n",
    "    run = Run.create_and_restore(config)\n",
    "    \n",
    "    sample_names = [f\"$x_{i}$\" for i in range(NUM_SAMPLES)]\n",
    "    slug = \"activations-\" + run.config.to_slug(delimiter=\"-\")\n",
    "\n",
    "    compare_activations(\n",
    "        run.config, \n",
    "        run.model, \n",
    "        run.evaluator.pretrain_xs[:NUM_SAMPLES], \n",
    "        run.evaluator.pretrain_ys[:NUM_SAMPLES], \n",
    "        save=FIGURES / slug, \n",
    "        names=sample_names\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(checkpointer.file_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a few samples for a subset of models over training\n",
    "\n",
    "MS = [1, 4, 64, 2**10, 2**20]\n",
    "STEPS = [0, 1_805, 3_084, 15_381, 26_279, 100_262, 153_061, 193_877, 255_102, 306_122, 408_163]\n",
    "\n",
    "for m in MS:\n",
    "    log2_m = int(np.log2(m))\n",
    "    config, checkpointer = configs[log2_m], checkpointers[log2_m]\n",
    "    run = Run(config)\n",
    "\n",
    "    for step in STEPS:\n",
    "        run.model.load_state_dict(checkpointer.load_file(step)[\"model\"])\n",
    "\n",
    "        sample_names = [f\"$x_{i}$\" for i in range(NUM_SAMPLES)]\n",
    "        slug = \"activations-\" + run.config.to_slug(delimiter=\"-\") + f\"@t={step}\"\n",
    "\n",
    "        # TODO: Need to rename the new files otherwise you can't tell easily tell what step they come from.\n",
    "        compare_activations(\n",
    "            run.config, \n",
    "            run.model, \n",
    "            run.evaluator.pretrain_xs[:NUM_SAMPLES], \n",
    "            run.evaluator.pretrain_ys[:NUM_SAMPLES], \n",
    "            save=FIGURES / slug, \n",
    "            names=sample_names\n",
    "        )\n",
    "        \n",
    "        os.system('say \"Your program has finished.\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get it all on Wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
