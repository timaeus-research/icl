{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M=1 Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots \n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from devinterp.mechinterp.hooks import hook\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.patches import FancyArrowPatch\n",
    "from mpl_toolkits.mplot3d import proj3d\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# import sys\n",
    "# del sys.modules['icl.figures.colors']\n",
    "# del sys.modules['icl.figures.notation']\n",
    "\n",
    "from icl.analysis.utils import get_unique_run\n",
    "from icl.constants import ANALYSIS, FIGURES, SWEEPS\n",
    "from icl.figures.notation import str_d_dlogt, str_d_dt, str_dlog_dlogt\n",
    "from icl.figures.colors import plot_transitions, gen_transition_colors, get_transition_type, PRIMARY, SECONDARY, TERTIARY, BRED, BBLUE, BRED, BGREEN\n",
    "\n",
    "DEVICE = 'mps'\n",
    "MODEL_ID = \"L2H4M1\"\n",
    "LLC_RUN_ID = \"5e0cq1db\"\n",
    "\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TASKS = 1\n",
    "NUM_LAYERS = 2\n",
    "MAX_LR = 0.01\n",
    "\n",
    "# shorthands\n",
    "BATCH_SIZE = 8192\n",
    "K = 8\n",
    "D = 4\n",
    "\n",
    "run = get_unique_run(\n",
    "    str(SWEEPS / \"training-runs/small-L-2.yaml\"), \n",
    "    task_config={\"num_tasks\": NUM_TASKS, \"num_layers\": NUM_LAYERS},\n",
    "    optimizer_config={\"lr\": MAX_LR}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy \n",
    "# Let's generate these same plots and also look at their evolution. \n",
    "models = []\n",
    "optimizer_state_dicts = []\n",
    "\n",
    "steps = run.checkpointer.file_ids\n",
    "\n",
    "for checkpoint in run.checkpointer:\n",
    "    m = deepcopy(run.model)\n",
    "    m.load_state_dict(checkpoint[\"model\"])\n",
    "    models.append(m)\n",
    "    optimizer_state_dicts.append(checkpoint[\"optimizer\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at how the curvature of the llc changes over time. \n",
    "\n",
    "import wandb\n",
    "\n",
    "api = wandb.Api()\n",
    "llc_run = api.run(f\"devinterp/icl/{LLC_RUN_ID}\")\n",
    "history_df = llc_run.history()\n",
    "\n",
    "llc_steps = history_df[\"_step\"]\n",
    "llcs = history_df[\"llc/mean\"]\n",
    "llcs_std = history_df[\"llc/std\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from icl.figures.derivatives import d_dt, d_dlogt, dlog_dlogt\n",
    "\n",
    "weight_norms = [(sum(torch.norm(p) ** 2 for p in model.parameters()) ** 0.5).item() for model in models]\n",
    "\n",
    "d_llc_dt = d_dt(steps, llcs)\n",
    "d_llc_dlogt = d_dlogt(steps, llcs)\n",
    "\n",
    "d_weight_norm_dt = d_dt(run.checkpointer.file_ids, weight_norms)\n",
    "d_weight_norm_dlogt = d_dlogt(run.checkpointer.file_ids, weight_norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from icl.analysis.evals import ICLEvaluator\n",
    "\n",
    "FORCE_REEVAL = True\n",
    "\n",
    "evaluator = ICLEvaluator(\n",
    "    pretrain_dist=run.pretrain_dist,\n",
    "    true_dist=run.true_dist,\n",
    "    max_examples=run.config.task_config.max_examples,\n",
    "    eval_batch_size=BATCH_SIZE,\n",
    "    seed=run.config.task_config.true_seed,   \n",
    ")\n",
    "\n",
    "if os.path.exists(ANALYSIS / f\"{MODEL_ID}_evals_over_time.csv\") and not FORCE_REEVAL:\n",
    "    evals_over_time_df = pd.read_csv(ANALYSIS / f\"{MODEL_ID}_evals_over_time.csv\")\n",
    "    evals_over_time = evals_over_time_df.to_dict(\"records\")\n",
    "else:\n",
    "    evals_over_time = [evaluator(model) for model in models]\n",
    "    evals_over_time_df = pd.DataFrame(evals_over_time)\n",
    "    evals_over_time_df.to_csv(ANALYSIS / f\"{MODEL_ID}_evals_over_time.csv\")\n",
    "\n",
    "evals_over_time_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evals_over_time_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import colorsys\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "\n",
    "TRANSITIONS = [\n",
    "    (30, 600, 'A1'),\n",
    "    (600, 12500, 'A2'),\n",
    "    (12500, 60000, 'B1'),\n",
    "    (60000, 110000, 'B2'),\n",
    "    (110000, 180000, 'B3'),\n",
    "    (180000, 280000, \"B4\"),\n",
    "    (280000, 320000, \"B5\"),\n",
    "    (320000, 500000, \"B6\")\n",
    "]\n",
    "\n",
    "\n",
    "# def gen_transition_colors(types):\n",
    "#     \"\"\"Generates a palette for transition colors. Orange-flavored for Type A. Blue-flavored for Type B.\"\"\"\n",
    "#     num_type_a = sum([t == \"A\" for t in types])\n",
    "#     num_type_b = sum([t == \"B\" for t in types])\n",
    "#     num_other = sum([t == \"Other\" for t in types])\n",
    "\n",
    "#     type_a_palette = sns.color_palette(\"Oranges_r\", num_type_a)\n",
    "#     type_b_palette = sns.color_palette(\"Blues_r\", num_type_b)\n",
    "#     other_palette = sns.color_palette(\"Greys_r\", num_other)\n",
    "\n",
    "#     palette = []\n",
    "\n",
    "#     for t in types:\n",
    "#         if t == \"A\":\n",
    "#             palette.append(type_a_palette.pop())\n",
    "#         elif t == \"B\":\n",
    "#             palette.append(type_b_palette.pop())\n",
    "#         else:\n",
    "#             palette.append(other_palette.pop())\n",
    "\n",
    "#     return palette\n",
    "\n",
    "\n",
    "def increase_saturation(rgb, saturation_factor):\n",
    "    # Convert RGB to HSV\n",
    "    hsv = colorsys.rgb_to_hsv(*rgb)\n",
    "    \n",
    "    # Increase saturation by the given factor, making sure it stays in [0, 1]\n",
    "    new_s = min(max(hsv[1] * saturation_factor, 0), 1)\n",
    "    \n",
    "    # Convert back to RGB\n",
    "    new_rgb = colorsys.hsv_to_rgb(hsv[0], new_s, hsv[2])\n",
    "    return new_rgb\n",
    "\n",
    "\n",
    "def increase_contrast(rgb, contrast_factor):\n",
    "    # Midpoint\n",
    "    midpoint = 128.0 / 255\n",
    "    \n",
    "    # Increase contrast\n",
    "    new_rgb = [(0.5 + contrast_factor * (component - 0.5)) for component in rgb]\n",
    "    \n",
    "    # Clip to the range [0, 1]\n",
    "    new_rgb = [min(max(component, 0), 1) for component in new_rgb]\n",
    "    return new_rgb\n",
    "\n",
    "\n",
    "\n",
    "transition_types = [get_transition_type(t) for t in TRANSITIONS]\n",
    "transition_colors = gen_transition_colors(transition_types)\n",
    "\n",
    "transition_colors = [increase_saturation(rgb, 2) for rgb in transition_colors]\n",
    "transition_colors = [increase_contrast(rgb, 2) for rgb in transition_colors]\n",
    "\n",
    "transitions_cmap = LinearSegmentedColormap.from_list(\"transitions\", transition_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_to_plot = [\n",
    "    (r\"L_{\\mathcal{T}}(t)\", evals_over_time_df[\"pretrain/mse_subsequence\"], {\"logy\": True}, ),\n",
    "    # (r\"L_\\mathcal{G}(t)\", evals_over_time_df[\"true/mse\"], {\"logy\": False}),\n",
    "    (r\"\\hat \\lambda(t)\", llcs, {}),\n",
    "    (r\"|\\theta(t)|\", weight_norms, {\"derivative\": \"dlog_dlogt\", \"logy\": True}),\n",
    "] \n",
    "\n",
    "fig, axes = plt.subplots(2, len(metrics_to_plot), figsize=(18, 6))\n",
    "\n",
    "for i, (metric_name, metric_values, kwargs) in enumerate(metrics_to_plot):\n",
    "    axes[0, i].plot(run.checkpointer.file_ids, metric_values, label=metric_name, marker='.')\n",
    "    axes[0, i].set_title(f\"${metric_name}$\")\n",
    "    axes[0, i].set_xlabel('Step, $t$')\n",
    "    axes[0, i].set_ylabel(metric_name)\n",
    "\n",
    "    if kwargs.get(\"logy\", False):\n",
    "        axes[0, i].set_yscale('log')\n",
    "\n",
    "    slope_type = kwargs.get(\"derivative\", \"d_dlogt\")\n",
    "\n",
    "    if slope_type == \"d_dlogt\":\n",
    "        slope = d_dlogt(run.checkpointer.file_ids, metric_values)\n",
    "        slope_name = str_d_dlogt(metric_name)\n",
    "    elif slope_type == \"d_dt\":\n",
    "        slope = d_dt(run.checkpointer.file_ids, metric_values)\n",
    "        slope_name = str_d_dt(metric_name)\n",
    "    elif slope_type == \"dlog_dlogt\":\n",
    "        slope = dlog_dlogt(run.checkpointer.file_ids, metric_values)\n",
    "        slope_name = str_dlog_dlogt(metric_name)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown slope type {slope_type}\")\n",
    "\n",
    "    axes[1, i].plot(run.checkpointer.file_ids, slope, label=metric_name + \" Slope\", marker='.')\n",
    "    axes[1, i].set_title(slope_name)\n",
    "    axes[1, i].set_xlabel('Step, $t$')\n",
    "    axes[1, i].set_ylabel(slope_name)\n",
    "\n",
    "for ax in axes.flatten():\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xlim(30, 500_000)\n",
    "\n",
    "# axes[0, 1].set_ylim(0, 100)\n",
    "# axes[1, 1].set_ylim(0, 200)\n",
    "# axes[1,1].set_ylim(-2, 2)\n",
    "\n",
    "patch_list = plot_transitions(axes, TRANSITIONS)\n",
    "\n",
    "milestone_labels = [label for _, _, label in TRANSITIONS]\n",
    "fig.legend(patch_list, milestone_labels, loc='upper center', bbox_to_anchor=(0.5, -0.025), ncol=len(TRANSITIONS))\n",
    "\n",
    "fig.set_facecolor(\"white\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Behavioral Indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss, Prediction Norm, OOD Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait if my layer norm theory is right. Then we should see a sudden improvement in the ability of the model to make predictions for out-of-distribution xs/ys (not ws). \n",
    "from devinfra.utils.seed import set_seed\n",
    "from icl.tasks import apply_transformations\n",
    "from devinfra.utils.iterables import flatten_dict\n",
    "\n",
    "pretrain_dist_noiseless = run.config.task_config.pretrain_dist_factory().to(\n",
    "    DEVICE\n",
    ")\n",
    "pretrain_dist_noiseless.std = 0.\n",
    "\n",
    "set_seed(run.config.task_config.pretrain_seed)\n",
    "\n",
    "\n",
    "# sample a batch of random tasks\n",
    "ws = pretrain_dist_noiseless.task_distribution.sample_tasks(BATCH_SIZE) # -> B D\n",
    "\n",
    "# sample i.i.d. inputs and outputs for each task according to the\n",
    "# regression model\n",
    "xs = torch.normal(\n",
    "    mean=0.,\n",
    "    std=1.,\n",
    "    size=(BATCH_SIZE, K, D,),\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "OOD_MULTIPLIER = 5\n",
    "\n",
    "ood_xs = 100 * xs\n",
    "ys = apply_transformations(ws, xs, 0.125, DEVICE)\n",
    "ood_ys = apply_transformations(ws, ood_xs, 0.125, DEVICE)\n",
    "\n",
    "def eval_loss(yhats, ys):\n",
    "    losses = ((yhats - ys) ** 2).mean(dim=0)[:, 0]\n",
    "    return [loss.item() for loss in losses] + [losses.mean().item()]\n",
    "\n",
    "losses_over_time = []\n",
    "\n",
    "for step, model in zip(run.checkpointer.file_ids, models):\n",
    "    losses = eval_loss(model(xs, ys), ys)\n",
    "    ood_losses = eval_loss(model(ood_xs, ood_ys), ood_ys)\n",
    "    losses_0s = eval_loss(model(xs, ys), torch.zeros_like(ys))\n",
    "\n",
    "    for i in range(9):\n",
    "        losses_over_time.append({\n",
    "            \"step\": step,\n",
    "            \"loss\": losses[i],\n",
    "            \"ood_loss\": ood_losses[i],\n",
    "            \"loss_0\": losses_0s[i],\n",
    "            # \"token\": f\"$\\hat y_{i+1}$\" if i < 8 else \"$\\overline{\\hat y}$\"\n",
    "            \"token\": i + 1 if i < 8 else \"$\\overline{\\hat y}$\"\n",
    "        })\n",
    "\n",
    "losses_over_time = pd.DataFrame(losses_over_time)\n",
    "losses_over_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In-context learning score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import colors as mcolors\n",
    "\n",
    "LINE_PALETTE=\"viridis\"\n",
    "ALPHA=1\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "\n",
    "sns.lineplot(data=losses_over_time, x=\"step\", y=\"loss\", hue=\"token\", palette=LINE_PALETTE, alpha=ALPHA, ax=ax)\n",
    "\n",
    "ax.set_yscale('log')\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_xlabel(\"Step, $t$\")\n",
    "ax.set_ylabel(\"$L_\\mathrm{val}$\")\n",
    "ax.legend().remove()\n",
    "\n",
    "plot_transitions(ax, TRANSITIONS, limit=True) #, alpha=0.25)\n",
    "\n",
    "cbar_ax = fig.add_axes([0.93, 0.15, 0.02, 0.7])  # Adjust as necessary for position and size\n",
    "\n",
    "# custom_cmap = mcolors.LinearSegmentedColormap.from_list(\"custom_cmap\", LINE_PALETTE)\n",
    "\n",
    "sm = plt.cm.ScalarMappable(cmap='viridis', norm=plt.Normalize(vmin=1, vmax=8), )\n",
    "sm._A = []  # Dummy array for the ScalarMappable. \n",
    "cbar = fig.colorbar(sm, cax=cbar_ax)\n",
    "\n",
    "tick_positions = range(1, len(LINE_PALETTE)+1)  # Positions for each color\n",
    "tick_labels = [f\"${i}$\" for i in range(1, len(LINE_PALETTE) + 1)] # Replace with your labels\n",
    "cbar.set_ticks(tick_positions)\n",
    "cbar.set_ticklabels(tick_labels)\n",
    "cbar.set_label(\"$k$\")\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 0.91, 1])  # Adjust layout to make room for colorbar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import colors as mcolors\n",
    "\n",
    "LINE_PALETTE=\"viridis\"\n",
    "ALPHA=1\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "\n",
    "icl_score = losses_over_time.loc[losses_over_time.token == 8, \"loss\"].values - losses_over_time.loc[losses_over_time.token == 1, \"loss\"].values\n",
    "sns.lineplot(x=steps, y=icl_score, alpha=ALPHA, ax=ax)\n",
    "    \n",
    "# ax.set_yscale('log')\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_xlabel(\"Step, $t$\")\n",
    "ax.set_ylabel(\"$L_\\mathrm{val}$\")\n",
    "ax.legend().remove()\n",
    "\n",
    "plot_transitions(ax, TRANSITIONS, limit=True) #, alpha=0.25)\n",
    "\n",
    "cbar_ax = fig.add_axes([0.93, 0.15, 0.02, 0.7])  # Adjust as necessary for position and size\n",
    "\n",
    "# custom_cmap = mcolors.LinearSegmentedColormap.from_list(\"custom_cmap\", LINE_PALETTE)\n",
    "\n",
    "sm = plt.cm.ScalarMappable(cmap='viridis', norm=plt.Normalize(vmin=1, vmax=8), )\n",
    "sm._A = []  # Dummy array for the ScalarMappable. \n",
    "cbar = fig.colorbar(sm, cax=cbar_ax)\n",
    "\n",
    "tick_positions = range(1, len(LINE_PALETTE)+1)  # Positions for each color\n",
    "tick_labels = [f\"${i}$\" for i in range(1, len(LINE_PALETTE) + 1)] # Replace with your labels\n",
    "cbar.set_ticks(tick_positions)\n",
    "cbar.set_ticklabels(tick_labels)\n",
    "cbar.set_label(\"$k$\")\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 0.91, 1])  # Adjust layout to make room for colorbar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Behavioral Essential Dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the PCAs again. \n",
    "from typing import Dict, Iterable, Tuple\n",
    "from sklearn.decomposition import PCA\n",
    "from collections import defaultdict\n",
    "from devinterp.mechinterp.hooks import hook\n",
    "import numpy as np\n",
    "from icl.analysis.utils import map_evals_over_checkpoints, get_unique_run\n",
    "from icl.train import Run\n",
    "from devinfra.utils.tensors import convert_tensor, ReturnTensor\n",
    "from matplotlib import colors as mcolors\n",
    "\n",
    "\n",
    "def extract_activations_over_checkpoints(models: Iterable[nn.Module], xs, ys, *paths, return_type: ReturnTensor=\"np\"):\n",
    "    def eval_activations(model):\n",
    "        model.to(DEVICE)\n",
    "        xs.to(model.device)\n",
    "        ys.to(model.device)\n",
    "        hooked_model = hook(model, *paths)\n",
    "        outputs, activations = hooked_model.run_with_cache(xs, ys)\n",
    "        activations[\"\"] = outputs\n",
    "        return {k: convert_tensor(v, return_type) for k, v in activations.items() if (k in paths or k == \"\") and v is not None}\n",
    "    \n",
    "    for model in models:\n",
    "        yield eval_activations(model)\n",
    "\n",
    "\n",
    "def get_vectorized_activations_trace(models: Iterable[nn.Module], xs, ys, *paths, normalize=False):\n",
    "    evals: Dict[str, list] = defaultdict(list)\n",
    "    \n",
    "    for activations in extract_activations_over_checkpoints(models, xs, ys, *paths):\n",
    "        for path, activation in activations.items():\n",
    "            if normalize:\n",
    "                activation = activation / np.linalg.norm(activation)\n",
    "\n",
    "            evals[path].append(activation)\n",
    "\n",
    "    return {\n",
    "        k: np.array(v).reshape(len(v), -1) for k, v in evals.items()\n",
    "    }\n",
    "\n",
    "\n",
    "def get_pca_activations_trace(models: Iterable[nn.Module], xs, ys, *paths, num_components=3, normalize=False) -> Dict[str, Tuple[PCA, np.ndarray]]:\n",
    "    results = {}\n",
    "\n",
    "    for path, activations in get_vectorized_activations_trace(models, xs, ys, *paths, normalize=normalize).items():\n",
    "        pca = PCA(n_components=num_components)\n",
    "        activations_reduced = pca.fit_transform(activations)\n",
    "        results[path] = pca, activations_reduced\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "tab10 = plt.cm.get_cmap('tab10', 10)  # Get the tab10 colormap\n",
    "colors = tab10.colors[:len(TRANSITIONS)]  # Get the first 6 colors \n",
    "# Add an extra gray to this np array for extra colors\n",
    "colors = np.vstack((colors, np.array([0.8, 0.8, 0.8, 1.0])))\n",
    "\n",
    "# Create a new colormap from the extracted colors\n",
    "custom_cmap = mcolors.ListedColormap(colors)\n",
    "\n",
    "# plot_multiple_slices(steps, demo_logits_reduced_3, demo_logits_pca_3, title=demo.config.to_latex(), connect_dots=True)\n",
    "train_xs_1, train_ys_1 = pretrain_dist_noiseless.get_batch(8, 1024)\n",
    "\n",
    "traces = get_pca_activations_trace(\n",
    "    models,\n",
    "    train_xs_1, \n",
    "    train_ys_1, \n",
    "    \"token_sequence_transformer\",\n",
    "    # \"token_sequence_transformer.blocks.1\",\n",
    "    # \"token_sequence_transformer.token_embedding\",\n",
    "    num_components=3,\n",
    "    normalize=False\n",
    ") \n",
    "\n",
    "# traces_small = get_pca_activations_trace(\n",
    "#     models,\n",
    "#     train_xs_1[:1024], \n",
    "#     train_ys_1[:1024], \n",
    "#     \"\",\n",
    "#     \"token_sequence_transformer.blocks.1\",\n",
    "#     # \"token_sequence_transformer.token_embedding\",\n",
    "#     num_components=3,\n",
    "#     normalize=False\n",
    "# ) \n",
    "\n",
    "pca_outputs, logits_outputs = traces[\"\"]\n",
    "pca_logits, logits_reduced = traces[\"token_sequence_transformer\"]\n",
    "# pca_internal, activations_reduced = traces_small[\"token_sequence_transformer.blocks.1\"]\n",
    "\n",
    "traces_normalized = get_pca_activations_trace(\n",
    "    models,\n",
    "    train_xs_1, \n",
    "    train_ys_1, \n",
    "    \"token_sequence_transformer\",\n",
    "    # \"token_sequence_transformer.blocks.1\",\n",
    "    # \"token_sequence_transformer.token_embedding\",\n",
    "    num_components=3,\n",
    "    normalize=True\n",
    ") \n",
    "\n",
    "# traces_small_normalized = get_pca_activations_trace(\n",
    "#     models,\n",
    "#     train_xs_1[:1024], \n",
    "#     train_ys_1[:1024], \n",
    "#     # \"token_sequence_transformer\",\n",
    "#     \"token_sequence_transformer.blocks.1\",\n",
    "#     # \"token_sequence_transformer.token_embedding\",\n",
    "#     num_components=3,\n",
    "#     normalize=True\n",
    "# ) \n",
    "\n",
    "pca_outputs_normalized, activations_outputs_normalized = traces_normalized[\"\"]\n",
    "pca_internal_normalized, activations_reduced_normalized = traces_normalized[\"token_sequence_transformer\"]\n",
    "# pca_internal, activations_reduced = traces_small[\"token_sequence_transformer.blocks.1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from typing import Optional\n",
    "\n",
    "def get_transition_indices(steps, transitions):\n",
    "    transition_indices = []\n",
    "    for step in steps:\n",
    "        # Find the index of the transition that the current step falls into\n",
    "        index = next((i for i, transition in enumerate(transitions) if transition[0] <= step < transition[1]), None)\n",
    "        transition_indices.append(index if index is not None else -1)\n",
    "\n",
    "    return transition_indices\n",
    "\n",
    "def get_nearest_step(step):\n",
    "    idx = np.argmin(np.abs(np.array(steps) - step))\n",
    "    return steps[idx]\n",
    "\n",
    "def plot_explained_variance(pca, title=\"Explained Variance\", ax: Optional[plt.Axes] = None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "    ax.bar(range(len(pca.explained_variance_ratio_)), pca.explained_variance_ratio_)\n",
    "\n",
    "    for i, ratio in enumerate(pca.explained_variance_ratio_):\n",
    "        ax.text(i, ratio, f\"{ratio:.2f}\", fontsize=12, ha='center', va='bottom')\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('PC')\n",
    "    ax.set_ylabel('Explained Variance')\n",
    "\n",
    "    ax.set_xticks(range(len(pca.explained_variance_ratio_)), range(1, len(pca.explained_variance_ratio_) + 1))\n",
    "\n",
    "\n",
    "def plot_multiple_slices(steps, samples, pca, highlighted_steps, transition_idxs, ave: Optional[str] = None, connect_dots=False, cmap=custom_cmap, alpha=1, save=False, line_color=\"auto\"):\n",
    "    num_pca_components = samples.shape[-1]\n",
    "    \n",
    "    # Create a single row of subplots\n",
    "    num_pca_combos = (num_pca_components * (num_pca_components-1)) // 2\n",
    "    fig, axes = plt.subplots(1, num_pca_combos + 1, figsize=(20, 4))\n",
    "    # fig.suptitle(title)\n",
    "\n",
    "    # Ensure ax is iterable by converting to a list if there's only one subplot\n",
    "    if num_pca_components == 2:\n",
    "        axes = [axes]\n",
    "\n",
    "\n",
    "    I = 0\n",
    "    for i in range(1, num_pca_components):\n",
    "        for j in range(i):\n",
    "\n",
    "            if connect_dots:\n",
    "                axes[I].plot(samples[:, i], samples[:, j], c='black', alpha=0.2)\n",
    "\n",
    "            sc = axes[I].scatter(samples[:, i], samples[:, j], c=transition_idxs, cmap=cmap, s=50, alpha=alpha)\n",
    "            axes[I].set_xlabel(f'PC {i}')\n",
    "            axes[I].set_ylabel(f'PC {j}')\n",
    "            axes[I].set_title(f'PC {i} vs PC {j}')\n",
    "\n",
    "            # Label some points\n",
    "            total_samples = len(samples)\n",
    "            for step in highlighted_steps:\n",
    "                k = steps.index(step)  # Find the index of the highlighted step\n",
    "                axes[I].text(samples[k, i], samples[k, j], str(step), fontsize=8, ha='right', va='bottom', alpha=0.5)\n",
    "\n",
    "            I += 1\n",
    "\n",
    "    plot_explained_variance(pca, ax=axes[-1])\n",
    "    # for I in range( num_pca_combos):\n",
    "    #     axes[I].axis('off')\n",
    "            \n",
    "    # Colorbar for the last plot\n",
    "    # cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])  # Adjust as necessary\n",
    "        # plt.colorbar(sc, cax=cbar_ax, label='Milestones')\n",
    "\n",
    "    # Plot the legend on the first subplot on the left\n",
    "    legend_ax = axes[0]\n",
    "    scatter_proxy = [plt.Line2D([0], [0], linestyle='none', marker='o', alpha=alpha, color=cmap(i / len(TRANSITIONS))) for i in range(len(transition_idxs))]\n",
    "    legend_labels = [label for _, _, label in TRANSITIONS]\n",
    "    legend_ax.legend(scatter_proxy, legend_labels, loc='center', ncol=1, frameon=False, bbox_to_anchor=(-0.5, 0.5), title='Developmental Stages')\n",
    "    # legend_ax.set_title()\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 0.9, 1])  # Adjust the right side to make room for the colorbar\n",
    "\n",
    "    if save:\n",
    "        parent_dir = os.path.dirname(save)\n",
    "        if not os.path.exists(parent_dir):\n",
    "            os.makedirs(parent_dir)\n",
    "        plt.savefig(save)\n",
    "\n",
    "\n",
    "    fig.set_facecolor('white')\n",
    "    \n",
    "# Usage of the function\n",
    "# Call the function with your data and the list of highlighted steps\n",
    "# plot_multiple_slices(steps, samples, pca, highlighted_steps=[100, 1000, 10000], title=\"Your Title\", num_points_to_label=10, save=\"path/to/save.png\", connect_dots=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transitions_of_steps = get_transition_indices(steps, TRANSITIONS)\n",
    "highlight_steps = list(map(get_nearest_step, [t[0] for t in TRANSITIONS][1:]))\n",
    "\n",
    "plot_multiple_slices(\n",
    "    steps, \n",
    "    logits_outputs, \n",
    "    pca_outputs, \n",
    "    highlight_steps,\n",
    "    transitions_of_steps,\n",
    "    connect_dots=True, \n",
    "    save=None,\n",
    "    cmap=transitions_cmap\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plot_multiple_slices(\n",
    "    steps, \n",
    "    activations_outputs_normalized, \n",
    "    pca_outputs_normalized, \n",
    "    highlight_steps,\n",
    "    transitions_of_steps,\n",
    "    connect_dots=True, \n",
    "    save=None,\n",
    "    cmap=transitions_cmap\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plot_multiple_slices(\n",
    "    steps, \n",
    "    logits_reduced, \n",
    "    pca_logits, \n",
    "    highlight_steps,\n",
    "    transitions_of_steps,\n",
    "    connect_dots=True, \n",
    "    save=None,\n",
    "    cmap=transitions_cmap\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plot_multiple_slices(\n",
    "    steps, \n",
    "    activations_reduced_normalized, \n",
    "    pca_internal_normalized, \n",
    "    highlight_steps,\n",
    "    transitions_of_steps,\n",
    "    connect_dots=True, \n",
    "    save=None,\n",
    "    cmap=transitions_cmap\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "LAST_CHECKPOINT_IDXS = -50\n",
    "last_steps = steps[LAST_CHECKPOINT_IDXS:]\n",
    "last_highlight_steps = [step for step in highlight_steps if step in last_steps]\n",
    "\n",
    "plot_multiple_slices(\n",
    "    last_steps, \n",
    "    activations_reduced_normalized[LAST_CHECKPOINT_IDXS:], \n",
    "    pca_internal_normalized, \n",
    "    last_highlight_steps,\n",
    "    transitions_of_steps[LAST_CHECKPOINT_IDXS:],\n",
    "    connect_dots=True, \n",
    "    save=None,\n",
    "    cmap=transitions_cmap\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_multiple_slices(\n",
    "    steps, \n",
    "    activations_reduced, \n",
    "    pca_internal, \n",
    "    highlight_steps,\n",
    "    transitions_of_steps,\n",
    "    connect_dots=True, \n",
    "    save=None\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plot_multiple_slices(\n",
    "    steps, \n",
    "    activations_reduced_normalized, \n",
    "    pca_internal_normalized,\n",
    "    highlight_steps,\n",
    "    transitions_of_steps,\n",
    "    connect_dots=True, \n",
    "    save=None\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geometric Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.cm import ScalarMappable\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "token_losses_over_time = losses_over_time.loc[losses_over_time.token != \"$\\overline{\\hat y}$\"]\n",
    "mean_losses_over_time = losses_over_time.loc[losses_over_time.token == \"$\\overline{\\hat y}$\"]\n",
    "\n",
    "sns.lineplot(data=token_losses_over_time, x=\"step\", y=f\"loss\", hue=\"token\", palette=\"viridis\", ax=axes[0], alpha=0.5)\n",
    "sns.lineplot(data=token_losses_over_time, x=\"step\", y=f\"loss_0\", hue=\"token\", palette=\"viridis\", ax=axes[1], alpha=0.5)\n",
    "sns.lineplot(data=token_losses_over_time, x=\"step\", y=f\"ood_loss\", hue=\"token\", palette=\"viridis\", ax=axes[2], alpha=0.5)\n",
    "\n",
    "sns.lineplot(data=mean_losses_over_time, x=\"step\", y=\"loss\", label=\"Mean\", ax=axes[0], color=BRED)\n",
    "sns.lineplot(data=mean_losses_over_time, x=\"step\", y=f\"loss_0\", label=\"Mean\", ax=axes[1], color=BRED)\n",
    "sns.lineplot(data=mean_losses_over_time, x=\"step\", y=\"ood_loss\", label=\"Mean\", ax=axes[2], color=BRED)\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_xlabel(\"Step, $t$\")\n",
    "    ax.set_yscale('log')\n",
    "    legend = ax.legend()\n",
    "    legend.remove()\n",
    "    ax.set_xlim(100, 500_000)\n",
    "\n",
    "legend = axes[1].legend(loc='upper center', bbox_to_anchor=(0.5, -0.2), ncol=6)\n",
    "legend.set_title(\"Per-Token Losses\")\n",
    "\n",
    "# Move legend to be likee fig.legend(patch_list, milestone_labels, loc='upper center', bbox_to_anchor=(0.5, -0.025), ncol=len(TRANSITIONS))\n",
    "\n",
    "axes[0].set_title(\"MSE on in-distribution inputs over time\")\n",
    "axes[0].set_ylabel(\"MSE\")\n",
    "\n",
    "axes[1].set_title(\"Mean squared prediction over time\")\n",
    "axes[1].set_ylabel(\"$\\|\\hat y_k\\|^2$\")\n",
    "\n",
    "axes[2].set_title(\"MSE on out-of-distribution inputs over time\")\n",
    "axes[2].set_ylabel(\"MSE\")\n",
    "\n",
    "plot_transitions(axes, TRANSITIONS)\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "# Add color bar on the far right\n",
    "\n",
    "fig.set_facecolor('white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "gradient_stats = []\n",
    "\n",
    "xs, ys = run.evaluator.pretrain_xs, run.evaluator.pretrain_ys\n",
    "xs, ys = xs.to(DEVICE), ys.to(DEVICE)\n",
    "\n",
    "\n",
    "for step, model in zip(steps, models):\n",
    "    model.to(DEVICE)\n",
    "    model.zero_grad()\n",
    "\n",
    "    yhats = model(xs, ys)\n",
    "\n",
    "    loss = F.mse_loss(yhats, ys)\n",
    "    loss.backward()\n",
    "\n",
    "    for n, p in model.named_parameters():\n",
    "\n",
    "        if p.grad is None:\n",
    "            continue\n",
    "\n",
    "        grad_sq_mean = (p.grad ** 2).mean().item()\n",
    "        grad_sq_std = (p.grad ** 2).std().item()\n",
    "\n",
    "        gradient_stats.append({\n",
    "            \"step\": step,\n",
    "            \"layer\": n,\n",
    "            \"grad/norm\": grad_sq_mean ** 0.5,\n",
    "            \"grad_sq/mean\": grad_sq_mean,\n",
    "            \"grad_sq/std\": grad_sq_std,\n",
    "            \"numel\": p.numel(),\n",
    "            \"loss\": loss.item(),\n",
    "        })          \n",
    "\n",
    "        p.grad = None \n",
    "\n",
    "gradient_stats = pd.DataFrame(gradient_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(20, 5))\n",
    "\n",
    "avg_gradients = gradient_stats.groupby(['step']).mean()\n",
    "\n",
    "grad_norm_thresholded = gradient_stats['grad/norm'].values + 0.00001\n",
    "\n",
    "sns.lineplot(data=gradient_stats, x='step', y=grad_norm_thresholded, hue=\"layer\", ax=ax, legend=False, alpha=0.5)\n",
    "sns.lineplot(data=avg_gradients, x='step', y='grad/norm', ax=ax, legend=False, color=BRED)\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel(\"Step, $t$\")\n",
    "ax.set_ylabel(\"Gradient norm, $\\|w_t\\|$\")\n",
    "\n",
    "_ = plot_transitions(ax, TRANSITIONS, limit=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the optimizer state\n",
    "\n",
    "names = [n for n, _ in run.model.named_parameters()]\n",
    "\n",
    "optimizer_stats = []\n",
    "\n",
    "for step, optimizer_state_dict in zip(steps, optimizer_state_dicts):\n",
    "    for layer, g in optimizer_state_dict[\"state\"].items():\n",
    "        optimizer_stats.append({\n",
    "            \"step\": step,\n",
    "            \"layer\": layer,\n",
    "            \"layer_name\": list(model.state_dict().keys())[layer],\n",
    "            \"exp_avg_sq_norm\": g[\"exp_avg_sq\"].norm().item() + 0.0000001\n",
    "        })\n",
    "\n",
    "optimizer_stats = pd.DataFrame(optimizer_stats)\n",
    "avg_optimizer_stats = optimizer_stats.groupby('step').mean()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "sns.lineplot(data=optimizer_stats, x=\"step\", y=\"exp_avg_sq_norm\", hue=\"layer\", palette=\"viridis\", ax=ax, alpha=0.5)\n",
    "sns.lineplot(data=avg_optimizer_stats, x=\"step\", y=\"exp_avg_sq_norm\", palette=\"viridis\", ax=ax, color=BRED)\n",
    "ax.set_ylabel(\"Gradient Norm\")\n",
    "ax.set_xlabel(\"Step\")\n",
    "ax.set_title(\"Gradient Norms by Layer and Step\")\n",
    "ax.legend().remove()\n",
    "\n",
    "plot_transitions(ax, TRANSITIONS, limit=True)\n",
    "\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_xscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to see in what order the layers reach \"zero\"\n",
    "# 1. Figure out the earliest step for each layer where exp_avg_sq_norm < 1e-5\n",
    "# 2. Order by this earliest step\n",
    "# 3. List the names\n",
    "\n",
    "threshold = 3e-7\n",
    "\n",
    "# Find the earliest step where exp_avg_sq_norm < threshold for each layer\n",
    "earliest_zero_step = optimizer_stats[optimizer_stats['exp_avg_sq_norm'] < threshold] \\\n",
    "    .groupby('layer_name') \\\n",
    "    .agg(earliest_step=('step', 'min'))\n",
    "\n",
    "# Now, sort the layers by the earliest step where their norm goes below the threshold\n",
    "sorted_layers_by_earliest_zero_step = earliest_zero_step.sort_values(by='earliest_step')\n",
    "sorted_layers_by_earliest_zero_step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient essential dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "try:\n",
    "    del gradients_over_time\n",
    "    del gradients_reduced\n",
    "    del gradients_reduced_normalized\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "PERPLEXITY = 15\n",
    "\n",
    "for layer_name in [\n",
    "    \"token_sequence_transformer.token_embedding\",\n",
    "    \"token_sequence_transformer.unembedding.0\",\n",
    "    \"token_sequence_transformer.blocks.0.compute.0\",\n",
    "    \"token_sequence_transformer.blocks.0.compute.2\",\n",
    "    \"token_sequence_transformer.blocks.1.compute.0\",\n",
    "    \"token_sequence_transformer.blocks.1.compute.2\"\n",
    "]:\n",
    "    layer_path = layer_name.split(\".\")\n",
    "    last_state_dict = models[-1].state_dict()\n",
    "    num_params = 0\n",
    "    \n",
    "    for subset in (\"weight\", \"bias\"):\n",
    "        subset_full_name = layer_name + \".\" + subset\n",
    "        if subset_full_name in last_state_dict:\n",
    "            num_params += models[-1].state_dict()[subset_full_name].numel()\n",
    "            \n",
    "    gradients_over_time = np.zeros((len(steps), num_params))\n",
    "\n",
    "    def get_params(model, layer_path):\n",
    "        m = model\n",
    "        for part in layer_path:\n",
    "            m = getattr(m, part)\n",
    "        \n",
    "        return m\n",
    "\n",
    "    for i, model in enumerate(models):\n",
    "        # model.train()\n",
    "        model.to(DEVICE)\n",
    "        model.zero_grad()\n",
    "\n",
    "        yhats = model(xs, ys)\n",
    "\n",
    "        loss = F.mse_loss(yhats, ys)\n",
    "        loss.backward()\n",
    "\n",
    "        layer = get_params(model, layer_path)\n",
    "\n",
    "        n = 0\n",
    "        for subset in (\"weight\", \"bias\"):\n",
    "            if layer and hasattr(layer, subset):\n",
    "                param = getattr(layer, subset)\n",
    "                if param is None:\n",
    "                    continue\n",
    "\n",
    "                numel = param.numel()\n",
    "                gradients_over_time[i, n:n+numel] = param.grad.flatten().cpu().numpy()\n",
    "                n += numel\n",
    "\n",
    "    pca = PCA(n_components=50)\n",
    "    gradients_reduced = pca.fit_transform(gradients_over_time)\n",
    "\n",
    "    norms = np.linalg.norm(gradients_over_time, axis=1, keepdims=True)\n",
    "    norms[norms == 0] = 1\n",
    "\n",
    "    gradients_reduced_normalized = pca.fit_transform(gradients_over_time / norms)\n",
    "\n",
    "    plot_multiple_slices(\n",
    "        steps, \n",
    "        gradients_reduced[:, :3], \n",
    "        pca, \n",
    "        highlight_steps,\n",
    "        transitions_of_steps,\n",
    "        connect_dots=True, \n",
    "        save=None,\n",
    "    )\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    tsne = TSNE(n_components=2, perplexity=PERPLEXITY, n_iter=1000, random_state=0)\n",
    "    gradients_tsne = tsne.fit_transform(gradients_reduced)\n",
    "\n",
    "    plt.scatter(gradients_tsne[:, 0], gradients_tsne[:, 1], c=transitions_of_steps, cmap=custom_cmap, s=50, alpha=0.6)\n",
    "    plt.show()\n",
    "\n",
    "    tsne_normalized = TSNE(n_components=2, perplexity=PERPLEXITY, n_iter=1000, random_state=0)\n",
    "    gradients_tsne_normalized = tsne.fit_transform(gradients_reduced_normalized)\n",
    "\n",
    "    plt.scatter(gradients_tsne_normalized[:, 0], gradients_tsne_normalized[:, 1], c=transitions_of_steps, cmap=custom_cmap, s=50, alpha=0.6)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "try:\n",
    "    del gradients_over_time\n",
    "    del gradients_reduced\n",
    "    del gradients_reduced_normalized\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "PERPLEXITY = 10\n",
    "\n",
    "def get_all_params_as_array(model):\n",
    "    return np.concatenate([p.cpu().numpy().flatten() for p in model.parameters()])\n",
    "\n",
    "\n",
    "def get_all_gradients_as_array(model):\n",
    "    return np.concatenate([p.grad.cpu().numpy().flatten() for p in model.parameters() if p.grad is not None])\n",
    "\n",
    "gradients_over_time = []\n",
    "gradients_normalized_over_time = []\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    # model.train()\n",
    "    model.to(DEVICE)\n",
    "    model.zero_grad()\n",
    "\n",
    "    yhats = model(xs, ys)\n",
    "\n",
    "    loss = F.mse_loss(yhats, ys)\n",
    "    loss.backward()\n",
    "\n",
    "    layer = get_params(model, layer_path)\n",
    "\n",
    "    gradients = get_all_gradients_as_array(model)\n",
    "    gradients_over_time.append(gradients)\n",
    "    gradients_normalized_over_time.append(gradients / np.linalg.norm(gradients))\n",
    "\n",
    "gradients_over_time = np.array(gradients_over_time)\n",
    "gradients_normalized_over_time = np.array(gradients_normalized_over_time)\n",
    "\n",
    "pca_1 = PCA(n_components=50)\n",
    "gradients_reduced = pca_1.fit_transform(gradients_over_time)\n",
    "\n",
    "pca_2 = PCA(n_components=50)\n",
    "gradients_reduced_normalized = pca_2.fit_transform(gradients_normalized_over_time)\n",
    "\n",
    "plot_multiple_slices(\n",
    "    steps, \n",
    "    gradients_reduced[:, :3], \n",
    "    pca_1, \n",
    "    highlight_steps,\n",
    "    transitions_of_steps,\n",
    "    connect_dots=True, \n",
    "    save=None,\n",
    ")\n",
    "\n",
    "plot_multiple_slices(\n",
    "    steps, \n",
    "    gradients_reduced_normalized[:, :3], \n",
    "    pca_2, \n",
    "    highlight_steps,\n",
    "    transitions_of_steps,\n",
    "    connect_dots=True, \n",
    "    save=None,\n",
    ")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"Full gradients\")\n",
    "print(\"Unnormalized\")\n",
    "\n",
    "tsne = TSNE(n_components=2, perplexity=PERPLEXITY, n_iter=1000, random_state=0)\n",
    "gradients_tsne = tsne.fit_transform(gradients_reduced)\n",
    "\n",
    "plt.scatter(gradients_tsne[:, 0], gradients_tsne[:, 1], c=transitions_of_steps, cmap=custom_cmap, s=50, alpha=0.6)\n",
    "plt.show()\n",
    "\n",
    "print(\"Normalized\")\n",
    "\n",
    "tsne_normalized = TSNE(n_components=2, perplexity=PERPLEXITY, n_iter=1000, random_state=0)\n",
    "gradients_tsne_normalized = tsne.fit_transform(gradients_reduced_normalized)\n",
    "\n",
    "plt.scatter(gradients_tsne_normalized[:, 0], gradients_tsne_normalized[:, 1], c=transitions_of_steps, cmap=custom_cmap, s=50, alpha=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "try:\n",
    "    del exp_avg_grads_over_time\n",
    "    del exp_avg_grads_reduced\n",
    "    del exp_avg_grads_reduced_normalized\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "PERPLEXITY = 15\n",
    "\n",
    "exp_avg_grads_over_time = []\n",
    "exp_avg_grads_normalized_over_time = []\n",
    "\n",
    "def get_exp_avg_sq_grads(optimizer_state_dict):\n",
    "    return np.concatenate([g[\"exp_avg_sq\"].cpu().numpy().flatten() for g in optimizer_state_dict[\"state\"].values()])\n",
    "\n",
    "def get_exp_avg_grads(optimizer_state_dict):\n",
    "    return np.concatenate([g[\"exp_avg\"].cpu().numpy().flatten() for g in optimizer_state_dict[\"state\"].values()])\n",
    "\n",
    "\n",
    "for i, opt_state in enumerate(optimizer_state_dicts):\n",
    "    # model.train()\n",
    "    exp_avg_grads = get_exp_avg_grads(opt_state)\n",
    "    exp_avg_grads_over_time.append(exp_avg_grads)\n",
    "    exp_avg_grads_normalized_over_time.append(exp_avg_grads / np.linalg.norm(exp_avg_grads))\n",
    "\n",
    "exp_avg_grads_over_time = np.array(exp_avg_grads_over_time)\n",
    "exp_avg_grads_normalized_over_time = np.array(exp_avg_grads_normalized_over_time)\n",
    "\n",
    "\n",
    "pca_1 = PCA(n_components=50)\n",
    "exp_avg_grads_reduced = pca_1.fit_transform(exp_avg_grads_over_time)\n",
    "\n",
    "pca_2 = PCA(n_components=50)\n",
    "exp_avg_grads_reduced_normalized = pca_2.fit_transform(exp_avg_grads_normalized_over_time)\n",
    "\n",
    "plot_multiple_slices(\n",
    "    steps, \n",
    "    exp_avg_grads_reduced[:, :3], \n",
    "    pca_1, \n",
    "    highlight_steps,\n",
    "    transitions_of_steps,\n",
    "    connect_dots=True, \n",
    "    save=None,\n",
    ")\n",
    "\n",
    "plot_multiple_slices(\n",
    "    steps, \n",
    "    exp_avg_grads_reduced_normalized[:, :3], \n",
    "    pca_2, \n",
    "    highlight_steps,\n",
    "    transitions_of_steps,\n",
    "    connect_dots=True, \n",
    "    save=None,\n",
    ")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"Exponentially averaged gradients\")\n",
    "print(\"Unnormalized\")\n",
    "\n",
    "tsne = TSNE(n_components=2, perplexity=PERPLEXITY, n_iter=1000, random_state=0)\n",
    "exp_avg_grads_tsne = tsne.fit_transform(exp_avg_grads_reduced)\n",
    "\n",
    "plt.scatter(exp_avg_grads_tsne[:, 0], exp_avg_grads_tsne[:, 1], c=transitions_of_steps, cmap=custom_cmap, s=50, alpha=0.6)\n",
    "plt.show()\n",
    "\n",
    "print(\"Normalized\")\n",
    "\n",
    "tsne_normalized = TSNE(n_components=2, perplexity=PERPLEXITY, n_iter=1000, random_state=0)\n",
    "exp_avg_grads_tsne_normalized = tsne.fit_transform(exp_avg_grads_reduced_normalized)\n",
    "\n",
    "plt.scatter(exp_avg_grads_tsne_normalized[:, 0], exp_avg_grads_tsne_normalized[:, 1], c=transitions_of_steps, cmap=custom_cmap, s=50, alpha=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "try:\n",
    "    del exp_avg_grads_over_time\n",
    "    del exp_avg_grads_reduced\n",
    "    del exp_avg_grads_reduced_normalized\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "PERPLEXITY = 15\n",
    "\n",
    "exp_avg_grads_over_time = []\n",
    "exp_avg_grads_normalized_over_time = []\n",
    "\n",
    "def get_exp_avg_sq_grads(optimizer_state_dict):\n",
    "    return np.concatenate([g[\"exp_avg_sq\"].cpu().numpy().flatten() for g in optimizer_state_dict[\"state\"].values()])\n",
    "\n",
    "def get_exp_avg_grads(optimizer_state_dict):\n",
    "    return np.concatenate([g[\"exp_avg\"].cpu().numpy().flatten() for g in optimizer_state_dict[\"state\"].values()])\n",
    "\n",
    "\n",
    "for i, opt_state in enumerate(optimizer_state_dicts):\n",
    "    # model.train()\n",
    "    exp_avg_grads = get_exp_avg_sq_grads(opt_state)\n",
    "    exp_avg_grads_over_time.append(exp_avg_grads)\n",
    "    exp_avg_grads_normalized_over_time.append(exp_avg_grads / np.linalg.norm(exp_avg_grads))\n",
    "\n",
    "exp_avg_grads_over_time = np.array(exp_avg_grads_over_time)\n",
    "exp_avg_grads_normalized_over_time = np.array(exp_avg_grads_normalized_over_time)\n",
    "\n",
    "pca_1 = PCA(n_components=50)\n",
    "exp_avg_grads_reduced = pca_1.fit_transform(exp_avg_grads_over_time)\n",
    "\n",
    "pca_2 = PCA(n_components=50)\n",
    "exp_avg_grads_reduced_normalized = pca_2.fit_transform(exp_avg_grads_normalized_over_time)\n",
    "\n",
    "plot_multiple_slices(\n",
    "    steps, \n",
    "    exp_avg_grads_reduced[:, :3], \n",
    "    pca_1, \n",
    "    highlight_steps,\n",
    "    transitions_of_steps,\n",
    "    connect_dots=True, \n",
    "    save=None,\n",
    ")\n",
    "\n",
    "plot_multiple_slices(\n",
    "    steps, \n",
    "    exp_avg_grads_reduced_normalized[:, :3], \n",
    "    pca_2, \n",
    "    highlight_steps,\n",
    "    transitions_of_steps,\n",
    "    connect_dots=True, \n",
    "    save=None,\n",
    ")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"Exponentially averaged square gradients\")\n",
    "print(\"Unnormalized\")\n",
    "\n",
    "tsne = TSNE(n_components=2, perplexity=PERPLEXITY, n_iter=1000, random_state=0)\n",
    "exp_avg_grads_tsne = tsne.fit_transform(exp_avg_grads_reduced)\n",
    "\n",
    "plt.scatter(exp_avg_grads_tsne[:, 0], exp_avg_grads_tsne[:, 1], c=transitions_of_steps, cmap=custom_cmap, s=50, alpha=0.6)\n",
    "plt.show()\n",
    "\n",
    "print(\"Normalized\")\n",
    "tsne_normalized = TSNE(n_components=2, perplexity=PERPLEXITY, n_iter=1000, random_state=0)\n",
    "exp_avg_grads_tsne_normalized = tsne.fit_transform(exp_avg_grads_reduced_normalized)\n",
    "\n",
    "plt.scatter(exp_avg_grads_tsne_normalized[:, 0], exp_avg_grads_tsne_normalized[:, 1], c=transitions_of_steps, cmap=custom_cmap, s=50, alpha=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tsne = TSNE(n_components=2, perplexity=30, n_iter=1000, random_state=0)\n",
    "gradients_tsne = tsne.fit_transform(gradients_reduced)\n",
    "\n",
    "plt.scatter(gradients_tsne[:, 0], gradients_tsne[:, 1], c=transitions_of_steps, cmap=custom_cmap, s=50, alpha=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGLD PCAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pp\n",
    "import sys\n",
    "\n",
    "from icl.analysis.slt import ExpectedBatchLossEstimator\n",
    "from icl.analysis.weights import WeightsTrace \n",
    "del sys.modules['icl.analysis.sample']\n",
    "del sys.modules['icl.analysis.slt']\n",
    "del sys.modules['icl.analysis.estimators']\n",
    "\n",
    "import yaml\n",
    "from icl.analysis.sample import SamplerConfig\n",
    "\n",
    "os.environ.setdefault('PYTORCH_ENABLE_MPS_FALLBACK', '1')\n",
    "\n",
    "CORES = 1\n",
    "NUM_CHAINS = 25\n",
    "NUM_DRAWS = 1000\n",
    "NUM_SAMPLES = 1024\n",
    "DATASET_SIZE = 2 ** 14\n",
    "\n",
    "sampler_config: SamplerConfig = SamplerConfig(\n",
    "    num_chains=NUM_CHAINS,\n",
    "    num_draws=NUM_DRAWS,\n",
    "    sampling_method='sgld',\n",
    "    grad_batch_origin='eval-dataset',\n",
    "    grad_batch_size=NUM_SAMPLES,\n",
    "    noise_scale=5e-3,    \n",
    "    localization_scale=5e-2,\n",
    "    gradient_scale=1e-5 * 1024. / (2 * np.log(1024)), \n",
    "    # noise_scale=5e-4,    \n",
    "    # localization_scale=1e-1,\n",
    "    # gradient_scale=1e-6 * 1024. / (2 * np.log(1024)), \n",
    "    # eval_method='fixed-minibatch',\n",
    "    eval_method='grad-minibatch',\n",
    "    eval_metrics=['likelihood-derived', 'batch-loss', 'weights'],\n",
    "    # eval_batch_size=8192,\n",
    "    eval_dataset_size=DATASET_SIZE,\n",
    "    device='cpu',\n",
    "    cores=CORES,\n",
    "    eval_loss_fn='mse',\n",
    "    eval_online=True\n",
    ")\n",
    "\n",
    "print(yaml.dump(sampler_config.model_dump()))\n",
    "\n",
    "run.model = models[-1]\n",
    "run.model.to('cpu')\n",
    "# log_fn = lambda data, step=None: print(f\"Step: {step}\\n\", yaml.dump(data))\n",
    "sampler = sampler_config.to_sampler(run, log_fn=None)\n",
    "print(\"INIT LOSS\", sampler.init_loss)\n",
    "\n",
    "results = sampler.eval(run.model)\n",
    "\n",
    "pp(sampler.callbacks[0].estimate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llc_callback = sampler.callbacks[0]\n",
    "sgld_estimates_df = llc_callback.estimates()\n",
    "\n",
    "sgld_estimates_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "batch_losses = sampler.batch_loss.estimates()\n",
    "batch_losses['mean'] = [float(x) for x in batch_losses['mean']]\n",
    "\n",
    "#llc_callback.expected_loss_estimator.\n",
    "sns.lineplot(data=batch_losses, x=\"draw\", y=\"mean\", hue=\"chain\", palette=\"gray\", ax=ax, alpha=0.5)\n",
    "\n",
    "twin_ax = ax.twinx()\n",
    "sns.lineplot(data=sgld_estimates_df, x=\"draw\", y=\"llc/mean\", ax=twin_ax, alpha=0.5, color=PRIMARY)\n",
    "\n",
    "ax.set_ylabel(r\"Batch Loss. $L^{(\\tau)}_m$\")\n",
    "twin_ax.set_ylabel(r\"LLC, $\\hat\\lambda_\\tau$\", color=PRIMARY)\n",
    "for label in twin_ax.get_yticklabels():\n",
    "    label.set_color(PRIMARY)\n",
    "\n",
    "ax.set_xlabel(r\"Draw, $\\tau$\")\n",
    "ax.legend().remove()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_weights_np = np.concatenate([p.view(-1).detach().cpu().numpy() for p in run.model.parameters()])\n",
    "\n",
    "weights_np = sampler.callbacks[-1].weights.detach().cpu().numpy()[:, :, :]\n",
    "# del sampler.callbacks[-1].weights\n",
    "\n",
    "weights_flat = weights_np.reshape(-1, weights_np.shape[-1]) - init_weights_np\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=50)\n",
    "weights_reduced = pca.fit_transform(weights_flat)\n",
    "\n",
    "# from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=2, perplexity=30, n_iter=1000, random_state=0)\n",
    "weights_tsne = tsne.fit_transform(weights_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "plot_explained_variance(pca, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_weights_np = np.concatenate([p.view(-1).detach().cpu().numpy() for p in run.model.parameters()])\n",
    "\n",
    "weights_np = sampler.callbacks[-1].weights.detach().cpu().numpy()[:, :, :]\n",
    "# del sampler.callbacks[-1].weights\n",
    "\n",
    "weights_flat = weights_np.reshape(-1, weights_np.shape[-1]) - init_weights_np\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=50)\n",
    "weights_reduced = pca.fit_transform(weights_flat)\n",
    "\n",
    "# from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=2, perplexity=30, n_iter=1000, random_state=0)\n",
    "weights_tsne = tsne.fit_transform(weights_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chain in range(NUM_CHAINS):\n",
    "    _weights = weights_tsne[chain * NUM_DRAWS:(chain + 1) * NUM_DRAWS] \n",
    "    sns.scatterplot(x=_weights[:, 0], y=_weights[:, 1], s=50, alpha=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def plot_weights_trace_fn(model, deltas, xs, ys, device='cpu', num_components=3, num_points=10):\n",
    "    model.to(device)\n",
    "    xs.to(device)\n",
    "    ys.to(device)\n",
    "\n",
    "    num_chains = deltas.shape[0]\n",
    "    num_draws = deltas.shape[1]\n",
    "\n",
    "\n",
    "    pca = PCA(n_components=num_components)\n",
    "\n",
    "    weights_reduced = pca.fit_transform(deltas.reshape(num_chains * num_draws, -1))\n",
    "\n",
    "    def get_pc_landscape(pca, fn, pc1, pc2, pc1_lim: Tuple[int, int], pc2_lim: Tuple[int, int], num_points=100, ax=None):\n",
    "        xx, yy = np.meshgrid(np.linspace(*pc1_lim, num_points), np.linspace(*pc2_lim, num_points))\n",
    "\n",
    "        # Compute function values for the grid\n",
    "        Z = np.zeros(xx.shape)\n",
    "        for i in tqdm.tqdm(range(xx.shape[0]), \"Iterating over rows\"):\n",
    "            for j in range(xx.shape[1]):\n",
    "                u = xx[i, j] * pc1 + yy[i, j] * pc2\n",
    "                Z[i, j] = fn(u)\n",
    "\n",
    "        # Plot the density map\n",
    "        Z = (Z - Z.min()) / (Z.max() - Z.min()) # rescale\n",
    "        Z = np.log(1e-3 + Z)\n",
    "        \n",
    "        im = ax.imshow(Z, interpolation='bilinear', origin='lower',\n",
    "            extent=(*pc1_lim, *pc2_lim), cmap='Blues', alpha=1., aspect='auto')\n",
    "        \n",
    "        return Z\n",
    "\n",
    "    def weights_to_model(weights):\n",
    "        m = deepcopy(model)\n",
    "        m.to(device)\n",
    "\n",
    "        i = 0\n",
    "        for n, p in m.named_parameters():\n",
    "            p.data += torch.from_numpy(weights[i:i+p.numel()]).view(p.shape).to(device)\n",
    "            i += p.numel()\n",
    "        \n",
    "        return m\n",
    "\n",
    "\n",
    "    def weights_to_loss(weights):\n",
    "        m = weights_to_model(weights)\n",
    "        yhats = m(xs, ys)\n",
    "        return F.mse_loss(yhats, ys).item()\n",
    "\n",
    "    xs.to(device)\n",
    "    ys.to(device)\n",
    "\n",
    "    pc_combos = list(itertools.combinations(range(num_components), 2))\n",
    "\n",
    "    fig, axes = plt.subplots(1, len(pc_combos) + 1, figsize=(20, 5))\n",
    "\n",
    "    for ax,  (pc1_idx, pc2_idx) in zip(axes, pc_combos):\n",
    "        pc1 = pca.components_[pc1_idx]\n",
    "        pc2 = pca.components_[pc2_idx]\n",
    "\n",
    "        min_pc1, max_pc1 = weights_reduced[:, pc1_idx].min(), weights_reduced[:, pc1_idx].max()\n",
    "        min_pc2, max_pc2 = weights_reduced[:, pc2_idx].min(), weights_reduced[:, pc2_idx].max()\n",
    "\n",
    "        pc1_lims = (min_pc1 - 0.1 * (max_pc1 - min_pc1), max_pc1 + 0.1 * (max_pc1 - min_pc1))\n",
    "        pc2_lims = (min_pc2 - 0.1 * (max_pc2 - min_pc2), max_pc2 + 0.1 * (max_pc2 - min_pc2))\n",
    "\n",
    "        get_pc_landscape(pca, weights_to_loss, pc1, pc2, pc1_lims, pc2_lims, num_points=num_points, ax=ax)\n",
    "\n",
    "        for chain in range(num_chains):\n",
    "            # _weights = pca.transform(deltas[chain])\n",
    "            _weights = weights_reduced[chain * num_draws:(chain + 1) * num_draws] \n",
    "            sns.scatterplot(x=_weights[:, pc1_idx], y=_weights[:, pc2_idx], ax=ax, s=2, alpha=0.2)\n",
    "\n",
    "        ax.set_xlim(*pc1_lims)\n",
    "        ax.set_ylim(*pc2_lims)\n",
    "\n",
    "        ax.set_title(f\"PC {pc1_idx + 1} vs PC {pc2_idx + 1}\")\n",
    "        ax.set_xlabel(f\"PC {pc1_idx + 1}\")\n",
    "        ax.set_ylabel(f\"PC {pc2_idx + 1}\")\n",
    "\n",
    "    # Plot explained variance\n",
    "    plot_explained_variance(pca, title=\"Explained Variance\", ax=axes[-1])        \n",
    "\n",
    "\n",
    "plot_weights_trace_fn(run.model, sampler.weights.deltas(), xs=xs, ys=ys, device=DEVICE, num_components=4, num_points=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mps.current_allocated_memory() / 1e9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per-token LLCs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per-token Essential Dynamics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structural indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametric Essential Dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try this for restricted subsets of weights as well\n",
    "\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "def extract_weights_over_checkpoints(models: Iterable[nn.Module], extract_weights: Callable = lambda m: [p.flatten() for p in m.parameters()], normalize=False):\n",
    "    for model in models:\n",
    "        weights = torch.cat(extract_weights(model)).detach().cpu().numpy()\n",
    "\n",
    "        if normalize:\n",
    "            weights /= np.linalg.norm(weights)\n",
    "\n",
    "        yield weights\n",
    "\n",
    "\n",
    "\n",
    "def get_pca_weights_trace(models: Iterable[nn.Module], extract_weights: Callable = lambda m: [p.flatten() for p in m.parameters()], num_components=3, normalize=False) -> Dict[str, Tuple[PCA, np.ndarray]]:\n",
    "    weights = np.array([w for w in extract_weights_over_checkpoints(models, extract_weights, normalize=normalize)])\n",
    "\n",
    "    pca = PCA(n_components=num_components)\n",
    "    weights_reduced = pca.fit_transform(weights)\n",
    "\n",
    "    return weights_reduced, pca\n",
    "\n",
    "all_weights, weights_pca = get_pca_weights_trace(models, num_components=3, normalize=False)\n",
    "\n",
    "plot_multiple_slices(\n",
    "    steps, \n",
    "    all_weights, \n",
    "    weights_pca, \n",
    "    highlight_steps,\n",
    "    transitions_of_steps,\n",
    "    connect_dots=True, \n",
    "    title=run.config.to_latex(), \n",
    "    save=None,\n",
    ")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_embedding_weights = lambda m: [p.flatten() for p in m.token_sequence_transformer.token_embedding.parameters()]\n",
    "extract_unembedding_weights = lambda m: [p.flatten() for p in m.token_sequence_transformer.unembedding[1].parameters()]\n",
    "extract_embedding_unembedding_weights = lambda m: [p.flatten() for p in m.token_sequence_transformer.token_embedding.parameters()] + [p.flatten() for p in m.token_sequence_transformer.unembedding[1].parameters()]\n",
    "extract_block_0_weights = lambda m: [p.flatten() for p in m.token_sequence_transformer.blocks[0].parameters()]\n",
    "extract_block_1_weights = lambda m: [p.flatten() for p in m.token_sequence_transformer.blocks[1].parameters()]\n",
    "extract_lns = lambda m: [m.state_dict()[f\"{ln}.{part}\"] for ln in layer_norms for part in [\"weight\", \"bias\"]]\n",
    "extract_mlp_0 = lambda m: [p.flatten() for p in m.token_sequence_transformer.blocks[0].compute[0].parameters()] + [p.flatten() for p in m.token_sequence_transformer.blocks[0].compute[2].parameters()]\n",
    "extract_mlp_1 = lambda m: [p.flatten() for p in m.token_sequence_transformer.blocks[1].compute[0].parameters()] + [p.flatten() for p in m.token_sequence_transformer.blocks[1].compute[2].parameters()]\n",
    "extract_attn_0 = lambda m: [p.flatten() for p in m.token_sequence_transformer.blocks[0].attention.attention.parameters()]\n",
    "extract_attn_1 = lambda m: [p.flatten() for p in m.token_sequence_transformer.blocks[1].attention.attention.parameters()]\n",
    "\n",
    "extract_weights_fns = {\n",
    "    \"Embedding & Unembedding\": extract_embedding_unembedding_weights, \n",
    "    \"Unembedding\": extract_unembedding_weights, \n",
    "    \"Embedding\": extract_embedding_weights, \n",
    "    \"Block 0\": extract_block_0_weights, \n",
    "    \"Block 1\": extract_block_1_weights, \n",
    "    \"Layer norms\": extract_lns,\n",
    "    \"MLP 0\": extract_mlp_0,\n",
    "    \"MLP 1\": extract_mlp_1,\n",
    "    \"Attention 0\": extract_attn_0,\n",
    "    \"Attention 1\": extract_attn_1,\n",
    "}\n",
    "\n",
    "for label, extract_weights in extract_weights_fns.items():\n",
    "    print(label)\n",
    "\n",
    "    for normalize in [False, True]:\n",
    "        print(f\"Normalize: {normalize}\")\n",
    "        subset_weights, weights_pca = get_pca_weights_trace(models, num_components=3, extract_weights=extract_weights, normalize=normalize)\n",
    "\n",
    "        plot_multiple_slices(\n",
    "            steps, \n",
    "            subset_weights, \n",
    "            weights_pca, \n",
    "            highlight_steps,\n",
    "            transitions_of_steps,\n",
    "            connect_dots=True, \n",
    "            title=run.config.to_latex(), \n",
    "            save=None,\n",
    "        )\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = run.checkpointer.file_ids\n",
    "embedding_matrices = []  # Shape: (64, 5): 64 vectors x (1 y dim + 4 x dims)\n",
    "\n",
    "for model in models:\n",
    "    embedding_matrices.append(model.state_dict()['token_sequence_transformer.token_embedding.weight'])\n",
    "\n",
    "\n",
    "embedding_vec_x_norms = [vec.norm(dim=1) for vec in embedding_matrices]  # (64,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA explained Variance over time\n",
    "pcas = []\n",
    "\n",
    "for model in models:\n",
    "    embed = model.token_sequence_transformer.token_embedding.weight.detach().cpu().numpy()\n",
    "    pca = PCA(n_components=embed.shape[1])\n",
    "    proj = pca.fit_transform(embed)[:,:3]\n",
    "    pcas.append((proj, pca))\n",
    "\n",
    "explained_variances = [{\"value\": value, \"index\": idx, \"step\": step} for step, (_, pca) in zip(steps, pcas) for idx, value in enumerate(pca.explained_variance_ratio_)]\n",
    "explained_variances = pd.DataFrame(explained_variances)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.lineplot(data=explained_variances, x=\"step\", y=\"value\", hue=\"index\", palette=\"viridis\", ax=ax)\n",
    "ax.legend(title=\"Component\", loc='upper left')\n",
    "ax.set_xscale('log')\n",
    "ax.set_title(\"Explained Variance of Embedding Vector PCA over Time\")\n",
    "ax.set_ylabel(\"Explained Variance\")\n",
    "ax.set_xlabel(\"Step, $t$\")\n",
    "\n",
    "plot_transitions(ax, TRANSITIONS, limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the final PCA\n",
    "\n",
    "def compute_explained_variance(pca, embed):\n",
    "    proj = pca.transform(embed)\n",
    "\n",
    "    # Step 4 and 5: Compute variance of projected data and total variance\n",
    "    variance_projected = np.var(proj, axis=0)\n",
    "    total_variance = np.sum(variance_projected)\n",
    "\n",
    "    # Step 6: Calculate explained variance ratio\n",
    "    explained_variance_ratio = variance_projected / total_variance\n",
    "\n",
    "    return explained_variance_ratio\n",
    "\n",
    "explained_variances_rel_last_pca = [{\"value\": value, \"index\": idx, \"step\": step} for step, embed in zip(steps, embedding_matrices) for idx, value in enumerate(compute_explained_variance(pcas[-1][-1], embed.detach().cpu().numpy()))]\n",
    "explained_variances_rel_last_pca = pd.DataFrame(explained_variances_rel_last_pca)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.lineplot(data=explained_variances_rel_last_pca, x=\"step\", y=\"value\", hue=\"index\", palette=\"viridis\", ax=ax)\n",
    "ax.legend(title=\"Component\", loc='upper left')\n",
    "\n",
    "ax.set_xscale('log')\n",
    "ax.set_title(\"Explained Variance of Embedding Vector PCA over Time\")\n",
    "ax.set_ylabel(\"Explained Variance\")\n",
    "ax.set_xlabel(\"Step, $t$\")\n",
    "\n",
    "plot_transitions(ax, TRANSITIONS, limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's project embedding vectors onto these pca components and track their evolution\n",
    "last_pca = pcas[-1][-1]\n",
    "transformed = [last_pca.transform(embed.detach().cpu().numpy()) for embed in embedding_matrices]\n",
    "transition_middles = [get_nearest_step((t[0] + t[1]) * 0.5) for t in TRANSITIONS]\n",
    "\n",
    "fig, axes = plt.subplots(1, len(transition_middles), figsize=(20, 5))\n",
    "\n",
    "min_x, max_x = 0, 0\n",
    "min_y, max_y = 0, 0\n",
    "\n",
    "for ax, middle in zip(axes, transition_middles):\n",
    "    middle_idx = steps.index(middle)\n",
    "    middle_embeddings = transformed[middle_idx]\n",
    "    sns.scatterplot(data=pd.DataFrame(middle_embeddings), x=0, y=1, ax=ax)\n",
    "    ax.set_title(f\"Step {middle}\")\n",
    "\n",
    "    min_x = min(min_x, middle_embeddings[:, 0].min())\n",
    "    max_x = max(max_x, middle_embeddings[:, 0].max())\n",
    "    min_y = min(min_y, middle_embeddings[:, 1].min())\n",
    "    max_y = max(max_y, middle_embeddings[:, 1].max())\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xlim(min_x * 1.25, max_x * 1.25)\n",
    "    ax.set_ylim(min_y * 1.25, max_y * 1.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "# Assuming 'pcas', 'embedding_matrices', 'TRANSITIONS', and 'steps' are defined as in your context.\n",
    "\n",
    "last_pca = pcas[-1][-1]\n",
    "transformed = [last_pca.transform(embed.detach().cpu().numpy()) for embed in embedding_matrices]\n",
    "transition_middles = [get_nearest_step((t[0] + t[1]) * 0.5) for t in TRANSITIONS]\n",
    "\n",
    "min_x, max_x = min([t[:, 0].min() for t in transformed]), max([t[:, 0].max() for t in transformed])\n",
    "min_y, max_y = min([t[:, 1].min() for t in transformed]), max([t[:, 1].max() for t in transformed])\n",
    "\n",
    "# Set up the figure.\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "plt.xlim(min_x * 1.25, max_x * 1.25)\n",
    "plt.ylim(min_y * 1.25, max_y * 1.25)\n",
    "scat = ax.scatter([], [])\n",
    "\n",
    "# Update function for the animation.\n",
    "def update(frame):\n",
    "    middle_embeddings = transformed[frame]\n",
    "    ax.clear()\n",
    "    ax.set_xlim(min_x * 1.25, max_x * 1.25)\n",
    "    ax.set_ylim(min_y * 1.25, max_y * 1.25)\n",
    "    ax.set_title(f\"Step {steps[frame]}\")\n",
    "    sns.scatterplot(data=pd.DataFrame(middle_embeddings), x=0, y=1, ax=ax)\n",
    "\n",
    "# Create the animation.\n",
    "ani = FuncAnimation(fig, update, frames=range(len(steps)), repeat=False)\n",
    "\n",
    "# To save the animation, you can use the following line:\n",
    "ani.save(FIGURES / 'M1-embed.mp4', writer='ffmpeg', fps=1)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero ablations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# W_U, W_E gives us a 5x5 matrix\n",
    "# The rows act, respectively, on y, and the x components. \n",
    "# So we can see what the cossim of these vectors is with the task vector. \n",
    "\n",
    "task = run.pretrain_dist.task_distribution.tasks[0]\n",
    "task_np = task.detach().cpu().numpy()\n",
    "task_embed = np.zeros(5)\n",
    "task_embed[1:] = task_np\n",
    "print(task_np)\n",
    "\n",
    "embed_unembed = [\n",
    "    model.token_sequence_transformer.unembedding[1].weight.detach().cpu().numpy() @ model.token_sequence_transformer.token_embedding.weight.detach().cpu().numpy()\n",
    "    for model in models\n",
    "]\n",
    "\n",
    "cossims = [\n",
    "    (v @ task_embed) / (np.linalg.norm(v) * np.linalg.norm(task_embed)) for v in embed_unembed\n",
    "]\n",
    "\n",
    "norm_ratio = [\n",
    "    np.linalg.norm(v, axis=0) / np.linalg.norm(task_embed) for v in embed_unembed\n",
    "]\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 5))\n",
    "\n",
    "ax = axes[0]\n",
    "ax.plot(run.checkpointer.file_ids, cossims, label=[\"$y$\", \"$x_1$\", \"$x_2$\", \"$x_3$\", \"$x_4$\"])\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_xlabel(\"Step, $t$\")\n",
    "ax.set_ylabel(r\"Cosine similarity between $(W_U W_E)_i$ and $\\mathbf{t}$\")\n",
    "ax.set_title(\"$W_U W_E$ over time\")\n",
    "\n",
    "ax.legend(loc='lower left')\n",
    "ax.legend()\n",
    "\n",
    "ax = axes[1]\n",
    "ax.plot(run.checkpointer.file_ids, norm_ratio)\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_xlabel(\"Step, $t$\")\n",
    "ax.set_ylabel(r\"$\\|(W_U W_E)_i\\| / \\|\\mathbf{t}\\|$\")\n",
    "\n",
    "plot_transitions(axes, TRANSITIONS, limit=True)\n",
    "\n",
    "fig.set_facecolor('white')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bias_stats = []\n",
    "\n",
    "for step, model in zip(steps, models):\n",
    "    state_dict = model.state_dict()\n",
    "\n",
    "    bias_stats.append({\n",
    "        \"step\": step,\n",
    "        \"postn_embedding_norm\": state_dict[\"token_sequence_transformer.postn_embedding.weight\"].norm().item(),\n",
    "        \"unembedding_ln_bias_norm\": state_dict[\"token_sequence_transformer.unembedding.0.bias\"].norm().item(),    \n",
    "    })\n",
    "\n",
    "bias_stats = pd.DataFrame(bias_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postn_embeddings = []\n",
    "unembedding_biases = []\n",
    "\n",
    "for step, model in zip(steps, models):\n",
    "    state_dict = model.state_dict()\n",
    "\n",
    "    _postn_embedding = state_dict[\"token_sequence_transformer.postn_embedding.weight\"]\n",
    "\n",
    "    for i, p in enumerate(_postn_embedding):\n",
    "        postn_embeddings.append({\n",
    "            \"step\": step,\n",
    "            \"postn_embedding_0\": p[0].item(),\n",
    "            \"idx\": i,\n",
    "            \"postn_embedding_x_std\": p[::2].std().item(),\n",
    "            \"postn_embedding_x_mean\": p[::2].mean().item(),\n",
    "            \"postn_embedding_y_std\": p[1::2].std().item(),\n",
    "            \"postn_embedding_y_mean\": p[1::2].mean().item(),\n",
    "        })\n",
    "\n",
    "    _unembedding_bias = state_dict[\"token_sequence_transformer.unembedding.0.bias\"]\n",
    "    for i, p in enumerate(_unembedding_bias):\n",
    "        unembedding_biases.append({\n",
    "            \"step\": step,\n",
    "            \"unembedding_bias\": p.item(),\n",
    "            \"idx\": i\n",
    "        })\n",
    "\n",
    "postn_embeddings = pd.DataFrame(postn_embeddings)\n",
    "unembedding_biases = pd.DataFrame(unembedding_biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(20, 2))\n",
    "\n",
    "axes[0].matshow(models[-1].token_sequence_transformer.postn_embedding.weight[:, ::2].T.detach().cpu().numpy(), aspect=\"auto\")\n",
    "axes[1].matshow(models[-1].token_sequence_transformer.postn_embedding.weight[:, 1::2].T.detach().cpu().numpy(), aspect=\"auto\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "ax.matshow(models[-1].token_sequence_transformer.unembedding[0].bias.reshape((1, 64)).detach().cpu().numpy(), aspect=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(20, 5))\n",
    "\n",
    "ax = axes[0]\n",
    "# sns.lineplot(data=bias_stats, x=\"step\", y=\"postn_embedding_norm\", ax=ax)\n",
    "sns.lineplot(data=postn_embeddings, x=\"step\", y=\"postn_embedding_0\", hue=\"idx\", palette=\"gray\", ax=ax, alpha=0.5)\n",
    "\n",
    "ax.set_xscale(\"log\")\n",
    "\n",
    "ax = axes[1]\n",
    "# sns.lineplot(data=bias_stats, x=\"step\", y=\"unembedding_ln_bias_norm\", ax=ax)\n",
    "sns.lineplot(data=unembedding_biases, x=\"step\", y=\"unembedding_bias\", hue=\"idx\", palette=\"gray\", ax=ax, alpha=0.5)\n",
    "ax.set_xscale(\"log\")\n",
    "\n",
    "plot_transitions(axes, TRANSITIONS, limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import patches\n",
    "from icl.model import to_token_sequence, from_predicted_token_sequence\n",
    "\n",
    "class EmbedUnembedOnlyV2(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.to_token_sequence = to_token_sequence\n",
    "        self.token_embedding = model.token_sequence_transformer.token_embedding\n",
    "        self.positional_embedding = model.token_sequence_transformer.postn_embedding\n",
    "        self.unembedding = model.token_sequence_transformer.unembedding\n",
    "        self.from_predicted_token_sequence = from_predicted_token_sequence\n",
    "\n",
    "    def forward(self, xs, ys):\n",
    "        tokens = self.to_token_sequence(xs, ys)\n",
    "\n",
    "        T = tokens.shape[1]\n",
    "        x = self.token_embedding(tokens) # + self.positional_embedding.weight.T[:T, :]\n",
    "        # Set everything to zero except for dimensions 46 and 51\n",
    "        # embedded[:, :, :46] = 0\n",
    "        # embedded[:, :, 47:51] = 0\n",
    "        # embedded[:, :, 52:] = 0\n",
    "\n",
    "        x = self.unembedding[0](x)\n",
    "        unembedded = self.unembedding[1](x)\n",
    "\n",
    "        # raise ValueError(\"Done\")\n",
    "    \n",
    "        return self.from_predicted_token_sequence(unembedded)\n",
    "\n",
    "\n",
    "# embed_unembed_only_model = EmbedUnembedOnly(run.model)\n",
    "\n",
    "def get_embed_unembed_with_bias(model, multiplier=1.):\n",
    "    eu_model = EmbedUnembedOnlyV2(model).to('cpu')\n",
    "\n",
    "    w = np.zeros(4)\n",
    "    basis = torch.eye(4, device=\"cpu\") * multiplier\n",
    "    ys = torch.zeros(1, 1, 1, device=\"cpu\") \n",
    "\n",
    "    for i in range(4):\n",
    "        w[i] = eu_model(basis[i].unsqueeze(0).unsqueeze(0), ys)[0].item()\n",
    "\n",
    "    return w\n",
    "\n",
    "\n",
    "embed_unembed_with_bias = [\n",
    "    get_embed_unembed_with_bias(model, 10)\n",
    "    for model in models\n",
    "]\n",
    "\n",
    "print(embed_unembed_with_bias[0].shape, task_embed.shape)\n",
    "\n",
    "cossims = [\n",
    "    (v @ task_np) / (np.linalg.norm(v) * np.linalg.norm(task_np)) for v in embed_unembed_with_bias\n",
    "]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "ax.plot(run.checkpointer.file_ids, cossims)\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_xlabel(\"step\")\n",
    "ax.set_ylabel(r\"Cosine similarity with $w_1$\")\n",
    "ax.set_title(\"Effective weight using only embedding (token only), unembedding (linear only), with biases\")\n",
    "\n",
    "# plt.legend(loc='lower left')\n",
    "plot_transitions(ax, TRANSITIONS)\n",
    "fig.set_facecolor('white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from icl.analysis.slt import prepend_keys\n",
    "\n",
    "layer_norms = [\n",
    "    \"token_sequence_transformer.unembedding.0\",\n",
    "    \"token_sequence_transformer.blocks.0.layer_norms.0\",\n",
    "    \"token_sequence_transformer.blocks.0.layer_norms.1\",\n",
    "    \"token_sequence_transformer.blocks.1.layer_norms.0\",\n",
    "    \"token_sequence_transformer.blocks.1.layer_norms.1\",\n",
    "]\n",
    "\n",
    "list(model.state_dict().keys())\n",
    "\n",
    "def get_ln(model, key):\n",
    "    return (model.state_dict()[f'{key}.weight'], model.state_dict()[f'{key}.bias'])\n",
    "\n",
    "unembed_lns = [get_ln(model, 'token_sequence_transformer.unembedding.0') for model in models]\n",
    "block_1_attn_lns =  [get_ln(model, 'token_sequence_transformer.blocks.0.layer_norms.0') for model in models]\n",
    "block_1_mlp_lns =  [get_ln(model, 'token_sequence_transformer.blocks.0.layer_norms.1') for model in models]\n",
    "block_2_attn_lns =  [get_ln(model, 'token_sequence_transformer.blocks.1.layer_norms.0') for model in models]\n",
    "block_2_mlp_lns =  [get_ln(model, 'token_sequence_transformer.blocks.1.layer_norms.1') for model in models]\n",
    "\n",
    "def ln_norm(weight, bias):\n",
    "    return torch.norm(weight).detach().cpu().numpy()\n",
    "\n",
    "def ln_norm_std(weight, bias):\n",
    "    return torch.std(weight.abs()).detach().cpu().numpy()\n",
    "\n",
    "unembed_ln_norms = [ln_norm(weight, bias) for weight, bias in unembed_lns]\n",
    "block_1_attn_ln_norms = [ln_norm(weight, bias) for weight, bias in block_1_attn_lns]\n",
    "block_1_mlp_ln_norms = [ln_norm(weight, bias) for weight, bias in block_1_mlp_lns]\n",
    "block_2_attn_ln_norms = [ln_norm(weight, bias) for weight, bias in block_2_attn_lns]\n",
    "block_2_mlp_ln_norms = [ln_norm(weight, bias) for weight, bias in block_2_mlp_lns]\n",
    "\n",
    "unembed_ln_norms_std = np.array([ln_norm_std(weight, bias) for weight, bias in unembed_lns])\n",
    "block_1_attn_ln_norms_std = np.array([ln_norm_std(weight, bias) for weight, bias in block_1_attn_lns])\n",
    "block_1_mlp_ln_norms_std = np.array([ln_norm_std(weight, bias) for weight, bias in block_1_mlp_lns])\n",
    "block_2_attn_ln_norms_std = np.array([ln_norm_std(weight, bias) for weight, bias in block_2_attn_lns])\n",
    "block_2_mlp_ln_norms_std = np.array([ln_norm_std(weight, bias) for weight, bias in block_2_mlp_lns])\n",
    "\n",
    "def frac_nonzero(weight, eps=1e-1):\n",
    "    return (weight.abs() > eps).float().mean().detach().cpu().numpy()\n",
    "\n",
    "unembed_ln_norm_nonzero = [frac_nonzero(weight) for weight, bias in unembed_lns]\n",
    "block_1_attn_ln_norm_nonzero = [frac_nonzero(weight) for weight, bias in block_1_attn_lns]\n",
    "block_1_mlp_ln_norm_nonzero = [frac_nonzero(weight) for weight, bias in block_1_mlp_lns]\n",
    "block_2_attn_ln_norm_nonzero = [frac_nonzero(weight) for weight, bias in block_2_attn_lns]\n",
    "block_2_mlp_ln_norm_nonzero = [frac_nonzero(weight) for weight, bias in block_2_mlp_lns]\n",
    "\n",
    "ln_stats = []\n",
    "\n",
    "def get_stats(weight):\n",
    "    return {\n",
    "        \"norm\": weight.norm().item(),\n",
    "        \"norm_std\": weight.abs().std().item(),\n",
    "        \"std\": weight.std().item(),\n",
    "        \"mean\": weight.mean().item(),\n",
    "        \"max\": weight.max().item(),\n",
    "        \"min\": weight.min().item(),\n",
    "    }\n",
    "    \n",
    "\n",
    "for step, model in zip(steps, models):\n",
    "    for layer in [\"unembed\", \"block_1_attn\", \"block_1_mlp\", \"block_2_attn\", \"block_2_mlp\"]:\n",
    "        weight, bias = get_ln(model, f\"token_sequence_transformer.{layer}.0\")\n",
    "\n",
    "        ln_stats.append({\n",
    "            \"step\": step,\n",
    "            \"layer\": layer,\n",
    "            \"layer_pretty\": layer.replace(\"_\", \" \").title(),\n",
    "            **prepend_keys(get_stats(weight), \"weight/\"),\n",
    "            **prepend_keys(get_stats(bias), \"bias/\"),\n",
    "        })\n",
    "\n",
    "ln_stats = pd.DataFrame(ln_stats)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.lineplot(data=ln_stats, x=\"step\", y=\"norm\", hue=\"layer\", palette=\"deep\", ax=ax)\n",
    "\n",
    "# Fill between using the std\n",
    "for layer in [\"unembed\", \"block_1_attn\", \"block_1_mlp\", \"block_2_attn\", \"block_2_mlp\"]:\n",
    "    ax.fill_between(steps, eval(f\"{layer}_ln_norms\") - eval(f\"{layer}_ln_norms_std\"), eval(f\"{layer}_ln_norms\") + eval(f\"{layer}_ln_norms_std\"), alpha=0.2)\n",
    "\n",
    "ax.legend(title=\"Layer\", loc='lower left')\n",
    "plot_transitions(ax, TRANSITIONS)\n",
    "ax.set_title(\"Layer Norm Weight Norms over Time\")\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim(100, 500_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"Unembed\", \"Block 1 Attn\", \"Block 1 MLP\", \"Block 2 Attn\", \"Block 2 MLP\"]\n",
    "\n",
    "for i, lns in enumerate([unembed_lns, block_1_attn_lns, block_1_mlp_lns, block_2_attn_lns, block_2_mlp_lns]):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(20, 5))\n",
    "\n",
    "    label = labels[i]\n",
    "    lns_df = pd.DataFrame([{\"step\": step, \"idx\": i, \"weight\": weight.item(), \"bias\": bias.item()} for step, (weights, biases) in zip(steps, lns) for i, (weight, bias) in enumerate(zip(weights, biases))])\n",
    "\n",
    "    ax = axes[0]\n",
    "    # inset_ax_1 = ax.inset_axes([0.1, 0.1, 0.4, 0.4])\n",
    "\n",
    "    sns.lineplot(data=lns_df, x=\"step\", y=\"weight\", color=PRIMARY, ax=ax)\n",
    "    # sns.lineplot(data=lns_df, x=\"step\", y=\"weight\", hue=\"idx\", palette=\"gray\", ax=inset_ax_1, alpha=0.1)\n",
    "    ax.set_title(f\"{label} Layer Norm Weights over Time\")\n",
    "    ax.set_ylabel(\"$u_i$\")\n",
    "    ax.set_xlim(100, 500_000)\n",
    "    \n",
    "    ax = axes[1]\n",
    "    # inset_ax_2 = ax.inset_axes([0.1, 0.1, 0.4, 0.4])\n",
    "\n",
    "    sns.lineplot(data=lns_df, x=\"step\", y=\"bias\", color=PRIMARY, ax=ax)\n",
    "    # sns.lineplot(data=lns_df, x=\"step\", y=\"bias\", hue=\"idx\", palette=\"gray\", ax=inset_ax_2, alpha=0.1)\n",
    "    ax.set_title(f\"{label} Layer Norm Biases over Time\")\n",
    "    ax.set_ylabel(\"$\\mathrm{unembed bias}_i$\")\n",
    "    ax.set_xlim(100, 500_000)\n",
    "    \n",
    "    plot_transitions(axes, TRANSITIONS, limit=True)\n",
    "    plot_transitions(np.array([inset_ax_1, inset_ax_2]), TRANSITIONS, limit=True)\n",
    "\n",
    "    for ax in axes:\n",
    "        ax.set_xlabel(\"Step, $t$\")\n",
    "        ax.set_xscale('log')\n",
    "        \n",
    "    # for ax in [inset_ax_1, inset_ax_2]:\n",
    "    #     ax.legend().remove()\n",
    "\n",
    "    # for ax in [*axes, inset_ax_1, inset_ax_2]:\n",
    "    #     ax.set_xscale('log')\n",
    "\n",
    "\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# act_stats_over_time = act_stats_over_time[act_stats_over_time[\"step\"] > 0]\n",
    "\n",
    "resid_stream_layers = [\n",
    "    \"token_sequence_transformer.token_embedding\",\n",
    "    \"token_sequence_transformer.blocks.0.resid_after_attn\",\n",
    "    \"token_sequence_transformer.blocks.0\",\n",
    "    \"token_sequence_transformer.blocks.1.resid_after_attn\",\n",
    "    \"token_sequence_transformer.blocks.1\"\n",
    "]\n",
    "\n",
    "try: \n",
    "    del act_stats_over_time\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "act_stats_over_time = []\n",
    "\n",
    "for step, model in zip(steps, models):\n",
    "    hooked_model = hook(model)\n",
    "    output, act = hooked_model.run_with_cache(xs, ys)\n",
    "\n",
    "    for layer in resid_stream_layers:\n",
    "        #print(act[layer].shape)\n",
    "        act_stats_over_time.append({\n",
    "            'mean': act[layer].mean().item(),  # mean over batch, over tokens, over activations\n",
    "            'abs_mean': act[layer].mean(dim=-1).abs().mean().item(),  # mean over batch and tokens of abs mean over activations\n",
    "            'var': act[layer].var().item(),  # var over batch, over tokens, over activations\n",
    "            'batch_var_of_mean': act[layer].var(dim=-1).mean().item(),  # mean over batch and tokens of var over activations\n",
    "            'batch_var_of_var': act[layer].var(dim=-1).var().item(),  # var over batch and tokens of var over activations\n",
    "            'max': act[layer].max().item(),\n",
    "            'min': act[layer].min().item(),\n",
    "            \"step\": step, \n",
    "            \"layer\": layer,\n",
    "            \"layer_idx\": resid_stream_layers.index(layer),\n",
    "            \"dim46\": act[layer][:, :, 46].abs().mean().item(),\n",
    "            \"dim51\": act[layer][:, :, 51].abs().mean().item(),\n",
    "        })\n",
    "\n",
    "act_stats_over_time = pd.DataFrame(act_stats_over_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_metrics_to_plot = [\n",
    "    (\"$\\overline{|\\mathrm{mean}[z^{(l)}_t]|}$\", \"abs_mean\", {}),\n",
    "#    (\"Mean over batch, token index, and activation index of residual stream activations\", \"std\", {}),\n",
    "    (\"$\\overline{\\mathrm{var}[z^{(l)}_t]}$\", \"batch_var_of_mean\", {}),\n",
    "#    (\"Std over batch and token index of std within residual stream activations\", \"batch_std_of_std\", {}),\n",
    "#    (\"Dim 46\", \"dim46\", {}),\n",
    "#    (\"Dim 51\", \"dim51\", {}),\n",
    "]\n",
    "\n",
    "layers = act_stats_over_time[\"layer\"].unique()\n",
    "slopes = np.zeros((len(layers), len(run.checkpointer.file_ids[1:])))\n",
    "\n",
    "slopes_list = []\n",
    "\n",
    "for (_, key, _) in more_metrics_to_plot:\n",
    "    for j, layer in enumerate(layers):\n",
    "        values = act_stats_over_time.loc[act_stats_over_time[\"layer\"] == layer][key].values\n",
    "        slopes[j, :] = dlog_dlogt(run.checkpointer.file_ids[1:], values)\n",
    "\n",
    "    slopes_list.extend([{\"layer\": layer, \"step\": step, key: slopes[j, step_idx]} for j, layer in enumerate(layers) for step_idx, step in enumerate(run.checkpointer.file_ids[1:]) for slope in slopes])\n",
    "\n",
    "slopes_df = pd.DataFrame(slopes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, len(more_metrics_to_plot), figsize=(20, 6))\n",
    "\n",
    "# act_stats_over_time = act_stats_over_time[act_stats_over_time[\"step\"] > 0]\n",
    "\n",
    "for i, (ax, (metric_name, key, kwargs)) in enumerate(zip(axes, more_metrics_to_plot)):\n",
    "    sns.lineplot(ax=ax, data=act_stats_over_time, x=\"step\", y=key, hue='layer', palette='viridis')\n",
    "\n",
    "    ax.set_title(metric_name + \" over Time\")\n",
    "    ax.set_xlabel('Time Steps')\n",
    "    ax.set_ylabel(metric_name)\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "    ax.legend().remove()\n",
    "\n",
    "    # sns.lineplot(ax=axes[1, i], data=slopes_df, x=\"step\", y=key, hue='layer', palette='viridis')\n",
    "    # axes[1, i].set_title(metric_name + \" Slope over Time\")\n",
    "    # axes[1, i].set_xlabel('Time Steps')\n",
    "    # axes[1, i].set_ylabel(metric_name + \" Slope\")\n",
    "\n",
    "plot_transitions(axes, TRANSITIONS, limit=True)\n",
    "\n",
    "for ax in axes[:2].flatten():\n",
    "    pass\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.set_facecolor(\"white\")\n",
    "\n",
    "# axes[1, 0].set_ylim(-10, 10)\n",
    "# axes[1, 1].set_ylim(-5, 5)\n",
    "\n",
    "# Show the plots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention Entropies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from typing import List, Union, Iterable, Optional\n",
    "from torchtyping import TensorType\n",
    "from devinfra.utils.iterables import map_nested\n",
    "\n",
    "from icl.experiments.utils import iter_models\n",
    "from devinfra.utils.iterables import flatten_dict\n",
    "\n",
    "from icl.train import Run\n",
    "\n",
    "def compute_attention_entropies(attn: TensorType[\"B\", \"H\", \"2K\", \"2K\"]):\n",
    "    \"\"\"\n",
    "    Computes the entropy of each token in each head, averaged across the batch, \n",
    "    then averages this over heads. \n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # Threshold attention weights to avoid log(0)\n",
    "    log_attention = torch.where(attn > 0, torch.log(attn), torch.tensor(0.0).to(attn.device))\n",
    "    entropy_per_token = - torch.sum(attn * log_attention, dim=-1).mean(dim=0).squeeze(-1) # TensorType[\"H\", \"2K\"]\n",
    "\n",
    "    num_heads, num_tokens = entropy_per_token.shape\n",
    "\n",
    "    entropy_per_head = entropy_per_token.mean(dim=-1) # TensorType[\"H\"]\n",
    "    entropy = entropy_per_head.mean() # TensorType[]    \n",
    "    \n",
    "    # Each token computes entropy over a variable context length, so we normalize by the maximum possible entropy\n",
    "    # for a token with a fixed context length.\n",
    "\n",
    "    max_entropy_per_token = torch.log2(torch.arange(1, num_tokens + 1).to(attn.device)) # TensorType[\"H\", \"2K\"]\n",
    "    max_entropy_per_token[0] = 1. # Special case for the first token to avoid dividing by 0\n",
    "\n",
    "    entropy_per_token_normalized = entropy_per_token / max_entropy_per_token\n",
    "    entropy_per_head_normalized = entropy_per_token_normalized.mean(dim=-1) # TensorType[\"H\"]\n",
    "    entropy_normalized = entropy_per_head_normalized.mean() # TensorType[]    \n",
    "\n",
    "    results: Dict[str, Union[torch.Tensor, Dict[str, torch.Tensor]]] = {\"mean\": entropy, \"mean_normalized\": entropy_normalized}\n",
    "\n",
    "    for i in range(num_heads):\n",
    "        head_results = {\"mean\": entropy_per_head[i], \"mean_normalized\": entropy_per_head_normalized[i]}\n",
    "\n",
    "        for j in range(num_tokens):\n",
    "            head_results[f\"token_{j}\"] = entropy_per_token[i, j]\n",
    "            head_results[f\"token_{j}_normalized\"] = entropy_per_token_normalized[i, j]\n",
    "\n",
    "        results[f\"head_{i}\"] = head_results\n",
    "\n",
    "    return map_nested(lambda x: convert_tensor(x, \"np\"), results)\n",
    "\n",
    "\n",
    "def get_attention_entropies_trace(\n",
    "    steps: List[int],\n",
    "    models: Iterable[nn.Module],\n",
    "    xs: torch.Tensor,\n",
    "    ys: torch.Tensor,\n",
    "    **paths,\n",
    "):\n",
    "    results = defaultdict(list)\n",
    "    reverse_paths = {v: k for k, v in paths.items()}\n",
    "\n",
    "    for activations in extract_activations_over_checkpoints(models, xs, ys, *paths.values(), return_type=\"pt\"):\n",
    "        for k, v in activations.items():\n",
    "            path = reverse_paths[k]\n",
    "            results[path].append(compute_attention_entropies(v))\n",
    "\n",
    "    values = []\n",
    "\n",
    "    for i in range(len(steps)):\n",
    "        value = {}\n",
    "\n",
    "        for block in results.keys():\n",
    "            value[block] = results[block][i]\n",
    "        \n",
    "        value[\"step\"] = steps[i]\n",
    "        values.append(flatten_dict(value, flatten_lists=True))\n",
    "\n",
    "    return pd.DataFrame(values)\n",
    "\n",
    "\n",
    "num_blocks = run.config.task_config.num_layers\n",
    "num_heads = run.config.task_config.num_heads\n",
    "num_tokens = run.config.task_config.max_examples * 2\n",
    "\n",
    "\n",
    "attn_entropies = get_attention_entropies_trace(\n",
    "    run.checkpointer.file_ids,\n",
    "    models, \n",
    "    xs, \n",
    "    ys, \n",
    "    **{f\"block_{b}\": f\"token_sequence_transformer.blocks.{b}.attention.attention_softmax\" for b in range(num_blocks)}\n",
    ")\n",
    "\n",
    "# run_attn_entropy_slug = \"attn-S-\" + run.config.to_slug(delimiter=\"-\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention_patterns(df: pd.DataFrame, num_blocks: int, num_heads: int, num_tokens: int, title=\"\", save: Optional[str] = None, normalized=False, figsize=(20, 25), logx=False, logy=False):\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    plt.suptitle(title)\n",
    "\n",
    "    num_cols = num_blocks * 2\n",
    "    num_rows = 1 + 1 + num_heads\n",
    "\n",
    "    suffix = \"\" if not normalized else \"_normalized\"\n",
    "    suffix_title = \"\" if not normalized else \" (Normalized)\"\n",
    "\n",
    "    fig.set_facecolor('white')\n",
    "\n",
    "    # Create subplot for mean entropy of first two blocks\n",
    "    ax0 = plt.subplot2grid((num_rows, num_cols), (0, 0), colspan=num_cols)\n",
    "    block_cmap = sns.color_palette(\"viridis\", num_blocks)\n",
    "\n",
    "    for b in range(num_blocks):\n",
    "        ax0.plot(df.step, df[f\"block_{b}/mean{suffix}\"], label=f\"block_{b}\", color=block_cmap[b])\n",
    "\n",
    "    ax0.set_title(\"Blocks\")\n",
    "    ax0.set_xlabel(\"Step\")\n",
    "    ax0.set_ylabel(f\"Entropy{suffix_title}\")\n",
    "    ax0.legend()\n",
    "\n",
    "    plot_transitions(ax0, TRANSITIONS, limit=True)\n",
    "\n",
    "    # Create subplots for each block, showing entropy in different heads\n",
    "    ax1 = [plt.subplot2grid((num_rows, num_cols), (1, i*2), colspan=2) for i in range(num_blocks)]\n",
    "    head_cmap = sns.color_palette(\"viridis\", num_heads)\n",
    "    \n",
    "    for b in range(num_blocks):\n",
    "        ax1[b].set_title(f\"Block {b}\")\n",
    "        ax1[b].set_xlabel(\"Step\")\n",
    "        ax1[b].set_ylabel(f\"Entropy{suffix_title}\")\n",
    "        for h in range(num_heads):\n",
    "            series = df[f\"block_{b}/head_{h}/mean{suffix}\"]\n",
    "            ax1[b].plot(df.step, series, label=f\"Head {h}\", color=head_cmap[h])\n",
    "\n",
    "    ax1[0].legend()\n",
    "\n",
    "    plot_transitions(ax1, TRANSITIONS, limit=True)\n",
    "\n",
    "    # Create subplots for each head in each block, detailing entropy for each token\n",
    "    ax2 = [plt.subplot2grid((num_rows, num_cols), (i//(num_cols) + 2, i%(num_cols))) for i in range(num_heads * num_blocks * 2)]\n",
    "    ax_idx = 0\n",
    "    token_cmap = sns.color_palette(\"viridis\", num_tokens)\n",
    "\n",
    "\n",
    "    for h in range(num_heads):\n",
    "        for b in range(num_blocks):\n",
    "            for x_or_y in (1, 0):\n",
    "                ax2[ax_idx].set_title(f\"Block {b} Head {h}\")\n",
    "                ax2[ax_idx].set_xlabel(\"Step\")\n",
    "                ax2[ax_idx].set_ylabel(f\"Entropy{suffix_title}\")\n",
    "\n",
    "                for t in range(1-int(x_or_y), num_tokens, 2):\n",
    "                    series = df[f\"block_{b}/head_{h}/token_{t}{suffix}\"]\n",
    "                    ax2[ax_idx].plot(df.step, series, label=f\"Token {t}\", color=token_cmap[t])\n",
    "                    \n",
    "                ax_idx += 1\n",
    "\n",
    "    ax2[0].legend()\n",
    "    ax2[1].legend()\n",
    "\n",
    "    plot_transitions(ax2, TRANSITIONS, limit=True)\n",
    "\n",
    "    for ax in [ax0, *ax1, *ax2]:\n",
    "        if logx:\n",
    "            ax.set_xscale(\"log\")\n",
    "        if logy:\n",
    "            ax.set_yscale(\"log\")\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "    if save:\n",
    "        parent_dir = os.path.dirname(save)\n",
    "        if not os.path.exists(parent_dir):\n",
    "            os.makedirs(parent_dir)\n",
    "        plt.savefig(save)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for normalized in (True, False):\n",
    "    plot_attention_patterns(\n",
    "        attn_entropies, \n",
    "        num_blocks=num_blocks, \n",
    "        num_heads=num_heads, \n",
    "        num_tokens=num_tokens, \n",
    "        title=run.config.to_latex(), \n",
    "        save=FIGURES / (f\"{MODEL_ID}-attn-entropy-normalized-{normalized}\" + \".png\"),\n",
    "        figsize=(25, 25),\n",
    "        normalized=normalized,\n",
    "        logx=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mechanistic Interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from torchtyping import TensorType\n",
    "\n",
    "\n",
    "def get_attention(model, xs, ys):\n",
    "    num_layers = len(model.token_sequence_transformer.blocks)\n",
    "    probes = []\n",
    "\n",
    "    for b in range(num_layers):\n",
    "        probe = ActivationProbe(model, f\"token_sequence_transformer.blocks.{b}.attention.attention_softmax\")\n",
    "        probe.register_hook()\n",
    "        probes.append(probe)\n",
    "\n",
    "    # Run the model\n",
    "    model(xs, ys)\n",
    "\n",
    "    for probe in probes:\n",
    "        probe.unregister_hook()\n",
    "\n",
    "    # Get the activations\n",
    "    return [probe.activation for probe in probes]\n",
    "\n",
    "def plot_activations(activations: List[TensorType[\"batch\", \"heads\", \"tokens\", \"tokens\"]]):       \n",
    "    num_layers = len(activations)\n",
    "    num_samples, num_heads, num_tokens, _ = activations[0].shape\n",
    "\n",
    "    for sample_idx in range(num_samples):\n",
    "        # Create a new figure\n",
    "        plt.figure(figsize=(15, 4 * num_layers))\n",
    "\n",
    "        # Loop through each head\n",
    "        for layer_idx, activation in enumerate(activations):\n",
    "            for head_idx in range(num_heads):\n",
    "                head_activation = activation[sample_idx, head_idx].detach().cpu().numpy()\n",
    "\n",
    "                # Create a subplot for each head\n",
    "                ax = plt.subplot(num_layers, num_heads, layer_idx * num_heads + head_idx + 1)\n",
    "\n",
    "                # Plot the activation\n",
    "                ax.imshow(head_activation, cmap='viridis', aspect='auto')\n",
    "\n",
    "                # Add title and labels\n",
    "                ax.set_title(f'Layer {layer_idx + 1}, Head {head_idx + 1}')\n",
    "                ax.set_xlabel('Keys')\n",
    "                ax.set_ylabel('Queries')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def compose2(f, g):\n",
    "    return lambda *a, **kw: f(g(*a, **kw))\n",
    "\n",
    "def compose(*fs):\n",
    "    from functools import reduce\n",
    "    return reduce(compose2, fs)\n",
    "\n",
    "get_and_plot_activations = compose(plot_activations, get_attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = run.pretrain_dist.task_distribution.tasks\n",
    "print(ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from icl.tasks import apply_transformations\n",
    "\n",
    "# x_trick = torch.zeros((4, 8, 4))\n",
    "# x_trick[:, :, 0] = torch.arange(0, 8)\n",
    "# # y_trick = torch.zeros((1, 8, 1))\n",
    "# x_trick = x_trick.to(\"mps\")\n",
    "# y_trick = apply_transformations(ws, x_trick, run.pretrain_dist.std, device=\"mps\")\n",
    "\n",
    "x_trick = torch.zeros((4, 8, 4))\n",
    "for i in range(4):\n",
    "    x_trick[i, :, i] = torch.arange(0, 8)\n",
    "\n",
    "# y_trick = torch.zeros((1, 8, 1))\n",
    "x_trick = x_trick.to(\"mps\")\n",
    "y_trick = apply_transformations(ws[0].repeat(4), x_trick, run.pretrain_dist.std, device=\"mps\")\n",
    "\n",
    "for i in range(4):\n",
    "    plt.matshow(x_trick[i].T.detach().cpu().numpy())\n",
    "\n",
    "plt.matshow(y_trick.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xs, ys = run.pretrain_dist.get_batch(8, 1)\n",
    "# get_and_plot_activations(run.model, xs=xs, ys=ys)\n",
    "get_and_plot_activations(run.model, xs=x_trick, ys=y_trick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_2 = get_unique_run(\n",
    "    \"../sweeps/small-sweep.yaml\", \n",
    "    task_config={\"num_tasks\": 65536, \"num_layers\": 2},\n",
    "    optimizer_config={\"lr\": 0.001}\n",
    ")\n",
    "\n",
    "xs_2, ys_2 = run_2.pretrain_dist.get_batch(8, 1)\n",
    "get_and_plot_activations(run_2.model, xs=xs_2, ys=ys_2)\n",
    "get_and_plot_activations(run_2.model, xs=x_trick, ys=y_trick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_3 = get_unique_run(\n",
    "    \"../sweeps/small-sweep.yaml\", \n",
    "    task_config={\"num_tasks\": 64, \"num_layers\": 2},\n",
    "    optimizer_config={\"lr\": 0.001}\n",
    ")\n",
    "\n",
    "xs_3, ys_3 = run_3.pretrain_dist.get_batch(8, 1)\n",
    "get_and_plot_activations(run_3.model, xs=xs_3, ys=ys_3)\n",
    "get_and_plot_activations(run_3.model, xs=x_trick, ys=y_trick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from icl.model import from_predicted_token_sequence, to_token_sequence\n",
    "\n",
    "activations = []\n",
    "\n",
    "class EmbedUnembedOnly(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.to_token_sequence = to_token_sequence\n",
    "        self.token_embedding = model.token_sequence_transformer.token_embedding\n",
    "        self.positional_embedding = model.token_sequence_transformer.postn_embedding\n",
    "        self.unembedding = model.token_sequence_transformer.unembedding\n",
    "        self.from_predicted_token_sequence = from_predicted_token_sequence\n",
    "\n",
    "    def forward(self, xs, ys):\n",
    "        tokens = self.to_token_sequence(xs, ys)\n",
    "\n",
    "        T = tokens.shape[1]\n",
    "        x = self.token_embedding(tokens) + self.positional_embedding.weight.T[:T, :]\n",
    "        # Set everything to zero except for dimensions 46 and 51\n",
    "        # embedded[:, :, :46] = 0\n",
    "        # embedded[:, :, 47:51] = 0\n",
    "        # embedded[:, :, 52:] = 0\n",
    "\n",
    "        # unembedded = self.unembedding[0](x)\n",
    "        unembedded = self.unembedding[1](x / 25)\n",
    "\n",
    "        # raise ValueError(\"Done\")\n",
    "    \n",
    "        return self.from_predicted_token_sequence(unembedded)\n",
    "\n",
    "\n",
    "embed_unembed_only_model = EmbedUnembedOnly(run.model)\n",
    "run.evaluator(embed_unembed_only_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hooked_model = hook(run.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = hooked_model.run_with_cache(run.evaluator.pretrain_xs, run.evaluator.pretrain_ys)[1]\n",
    "activations.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 1, figsize=(15, 10))\n",
    "plt.suptitle(\"Residual Stream Activations\")\n",
    "\n",
    "for ax, activation, label in zip(axes, activations, [\"Embedding\", \"Block 1\", \"Block 2\"]):\n",
    "    cax = ax.matshow(activation)\n",
    "    ax.set_title(f\"After {label}\")\n",
    "    ax.set_xlabel(\"Dimension\")\n",
    "    ax.set_ylabel(\"Token\")\n",
    "    fig.colorbar(cax, ax=ax)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def separate_attention(qkv, num_heads, batch_size, head_size, num_tokens):\n",
    "    return (qkv.view(batch_size, num_tokens, num_heads, 3*head_size)\n",
    "            .transpose(-2, -3)\n",
    "            .split(head_size, dim=-1))\n",
    "\n",
    "def plot_matrix(ax, data, title: Optional[str] = None):\n",
    "    ax.matshow(data.detach().to(\"cpu\").numpy())\n",
    "    ax.grid(None)\n",
    "\n",
    "    if title is not None:\n",
    "        ax.set_title(title)\n",
    "\n",
    "def plot_attention(axs, data, titles, num_heads):\n",
    "    q, k, softmax, v  = data\n",
    "    qk = (q.unsqueeze(0) @ k.unsqueeze(0).transpose(-2, -1))[0]\n",
    "\n",
    "    # Rows for each head\n",
    "    # Columns for Q, K, QK, V\n",
    "    for j, (name, x) in enumerate(zip(titles, [q, k, qk, softmax, v])):\n",
    "        axs[0, j].set_title(name)\n",
    "\n",
    "        for h in range(num_heads):\n",
    "            plot_matrix(axs[h, j], x[h])\n",
    "\n",
    "    for h in range(num_heads):\n",
    "        axs[h, 0].set_ylabel(f\"Head {h}\")\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(4, 5, figsize=(15, 15))\n",
    "softmax = activations[\"token_sequence_transformer.blocks.0.attention.attention_softmax\"]\n",
    "q, k, v = separate_attention(activations[\"token_sequence_transformer.blocks.0.attention.attention\"], 4, len(run.evaluator.pretrain_xs), 16, 16)\n",
    "attn = [q[0], k[0], softmax[0], v[0]]\n",
    "plot_attention(axes, attn, [\"Q\", \"K\", \"QK\", \"softmax\", \"V\"], num_heads=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 4, figsize=(15, 15))\n",
    "\n",
    "softmax0 = activations[\"token_sequence_transformer.blocks.0.attention.attention_softmax\"][0]\n",
    "v0 = separate_attention(activations[\"token_sequence_transformer.blocks.0.attention.attention\"], 4, len(run.evaluator.pretrain_xs), 16, 16)[-1][0]\n",
    "\n",
    "softmax1 = activations[\"token_sequence_transformer.blocks.1.attention.attention_softmax\"][0]\n",
    "v1 = separate_attention(activations[\"token_sequence_transformer.blocks.1.attention.attention\"], 4, len(run.evaluator.pretrain_xs), 16, 16)[-1][0]\n",
    "\n",
    "labels = [\"Block 1 Attention Patterns\", \"Block 1 Value Matrices\", \"Block 2 Attention Patterns\", \"Block 2 Value Matrices\"]\n",
    "\n",
    "for r, (layer, label) in enumerate(zip([softmax0, v0, softmax1, v1], labels)):\n",
    "    axes[r, 0].set_ylabel(label)\n",
    "    for c, x in enumerate(layer):\n",
    "        plot_matrix(axes[r, c], x, title=None)\n",
    "\n",
    "for c, label in enumerate(labels):\n",
    "    axes[0, c].set_title(f\"Head {c}\")\n",
    "\n",
    "plt.suptitle(\"Attention Patterns and Values Matrices\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../figures/m1-attn.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mat = run.model.token_sequence_transformer.blocks[0].attention.attention.weight.flatten() # .detach().to(\"cpu\").numpy().reshap\n",
    "\n",
    "def plot_attn_weights(W: torch.Tensor, num_heads: int, embed_dim: int, head_size: int, cols=(\"$W_Q^{(h)}$\", \"$W_K^{(h)}$\", \"$W_V^{(h)}$\"), title=\"\", save: Optional[str] = None, rows:Optional[List[str]] =None):\n",
    "    if len(W.shape) == 1:  # Num heads * Embedding dimension * Head size * 3\n",
    "        heads = list(split_attn_weights(W, num_heads, embed_dim, head_size))\n",
    "    elif len(W.shape) == 3:  # Num heads, Embedding dimension, Head size * 3\n",
    "        heads = [tuple(W[:, h, i*head_size:(i+1)*head_size].T for i in range(3)) for h in range(num_heads)]\n",
    "    else:\n",
    "        raise ValueError(f\"Expected W to have shape (num_heads, embed_dim, head_size * 3) or (num_heads * embed_dim * head_size * 3), got {W.shape}\")\n",
    "\n",
    "    fig, axs = plt.subplots(num_heads, 3, figsize=(25, 10))\n",
    "    plt.suptitle(title)\n",
    "\n",
    "    rows = rows or [f\"Head {h}\" for h in range(num_heads)]\n",
    "\n",
    "    min_, max_ = W.min(), W.max()\n",
    "\n",
    "    for h, head in enumerate(heads):\n",
    "        axs[h, 0].set_ylabel(f\"{rows[h]}\\nHead Size\")\n",
    "\n",
    "        for i, mat in enumerate(head):\n",
    "            axs[h, i].matshow(mat.detach().cpu().numpy().T, cmap='viridis', vmin=min_, vmax=max_) \n",
    "\n",
    "    for i, col in enumerate(cols):\n",
    "        axs[0, i].set_title(col)\n",
    "        axs[-1, i].set_xlabel(\"Embedding Dimension\")\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "    # Plot colorbar somewhere on right\n",
    "    fig.subplots_adjust(right=0.8)\n",
    "    cbar_ax = fig.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "    fig.colorbar(axs[0, 0].images[0], cax=cbar_ax)\n",
    "    \n",
    "\n",
    "    if save:\n",
    "        parent_dir = os.path.dirname(save)\n",
    "        if not os.path.exists(parent_dir):\n",
    "            os.makedirs(parent_dir)\n",
    "        plt.savefig(save)\n",
    "\n",
    "\n",
    "plot_attn_weights(mat, 4, 64, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_theme(\"paper\")\n",
    "\n",
    "plt.matshow(run.model.token_sequence_transformer.token_embedding.weight.detach().cpu().numpy().T)\n",
    "plt.title(\"Token embedding\")\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.matshow(run.model.token_sequence_transformer.postn_embedding.weight.detach().cpu().numpy().T)\n",
    "plt.title(\"Positional embedding\")\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.matshow(run.model.token_sequence_transformer.unembedding[0].weight.unsqueeze(0).detach().cpu().numpy())\n",
    "plt.title(\"Unembedding layer norm weight\")\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.matshow(run.model.token_sequence_transformer.unembedding[0].bias.unsqueeze(0).detach().cpu().numpy())\n",
    "plt.title(\"Unembedding layer norm bias\")\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.matshow(run.model.token_sequence_transformer.unembedding[1].weight.detach().cpu().numpy())\n",
    "plt.title(\"Unembedding linear\")\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# Please plot the layernorm weights and biases together as a histogram\n",
    "\n",
    "plt.bar(np.arange(64), run.model.token_sequence_transformer.unembedding[0].weight.detach().cpu().numpy().flatten(), label=\"weight\")\n",
    "plt.bar(np.arange(64), run.model.token_sequence_transformer.unembedding[0].bias.detach().cpu().numpy().flatten(), label=\"bias\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Dimension\")\n",
    "plt.title(\"Unembedding Layer Norm\")\n",
    "plt.show()\n",
    "\n",
    "plt.bar(np.arange(64), run.model.token_sequence_transformer.blocks[0].compute[2].bias.detach().cpu().numpy().flatten(), label=\"Block 0\")\n",
    "plt.bar(np.arange(64), run.model.token_sequence_transformer.blocks[1].compute[2].bias.detach().cpu().numpy().flatten(), label=\"Block 1\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Dimension\")\n",
    "plt.title(\"MLP Projection Bias\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.model.token_sequence_transformer.token_embedding.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a 1x2 grid of subplots\n",
    "fig, ax = plt.subplots(1, 1)  # Adjust figsize to desired size\n",
    "\n",
    "# Plot the weight on the first subplot (ax)\n",
    "ax.bar(np.arange(64), run.model.token_sequence_transformer.unembedding[1].weight[0, :].detach().cpu().numpy().flatten())\n",
    "ax.set_ylabel('Weight')\n",
    "ax.set_xlabel(\"Dimension\")\n",
    "ax.set_title(\"Scale\")\n",
    "\n",
    "# Set a main title for the entire figure\n",
    "plt.suptitle(\"$(W_U)\\,_{0,:}$\")\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a 1x2 grid of subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))  # Adjust figsize to desired size\n",
    "\n",
    "# Plot the weight on the first subplot (ax1)\n",
    "ax1.bar(np.arange(64), run.model.token_sequence_transformer.unembedding[0].weight.detach().cpu().numpy().flatten())\n",
    "ax1.set_ylabel('Scale')\n",
    "ax1.set_xlabel(\"Dimension\")\n",
    "ax1.set_title(\"Scale\")\n",
    "\n",
    "# Plot the bias on the second subplot (ax2)\n",
    "ax2.bar(np.arange(64), run.model.token_sequence_transformer.unembedding[0].bias.detach().cpu().numpy().flatten())\n",
    "ax2.set_ylabel('Bias')\n",
    "ax2.set_xlabel(\"Dimension\")\n",
    "ax2.set_title(\"Bias\")\n",
    "\n",
    "# Set a main title for the entire figure\n",
    "plt.suptitle(\"Unembedding Layer Norm\")\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed46 = run.model.token_sequence_transformer.token_embedding.weight[46]\n",
    "embed51 = run.model.token_sequence_transformer.token_embedding.weight[51]\n",
    "\n",
    "with torch.no_grad():\n",
    "    embed46[0] = 0\n",
    "    embed51[0] = 0\n",
    "\n",
    "\n",
    "print(\"Task weights (normalized):\", (run.pretrain_dist.task_distribution.tasks / run.pretrain_dist.task_distribution.tasks.sum()).tolist())\n",
    "print(\"Embedding weights (index 46):\", (embed46).tolist())\n",
    "print(\"Embedding weights (index 51):\", (embed51).tolist())\n",
    "print(\"Embedding weights (index 46, normalized):\", (embed46 / embed46.sum()).tolist())\n",
    "print(\"Embedding weights (index 51, normalized):\", (embed51 / embed51.sum()).tolist())\n",
    "print(\"Embedding weights (averaged across indices 46 and 51, normalized):\", ((embed46 / embed46.sum() + embed51 / embed51.sum()) / 2).tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(run.model.token_sequence_transformer.blocks[0].compute[2].bias.unsqueeze(0).cpu().detach().numpy())\n",
    "plt.title(\"BLock 0 MLP Linear bias\")\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.matshow(run.model.token_sequence_transformer.blocks[1].compute[2].bias.unsqueeze(0).cpu().detach().numpy())\n",
    "plt.title(\"BLock 1 MLP Linear bias\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(p.numel() for p in run.model.parameters()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the variance and mean of activations in the residual stream over time. I want to see this for different points of the model\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "embedding = run.model.token_sequence_transformer.token_embedding.weight.detach().cpu().numpy()\n",
    "\n",
    "pca = PCA(n_components=5)\n",
    "pca.fit(embedding)\n",
    "\n",
    "pca_internal = pca.transform(embedding)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "axes[0].scatter(pca_internal[:, 0], pca_internal[:, 1])\n",
    "axes[0].set_xlabel(\"PCA 1\")\n",
    "axes[0].set_ylabel(\"PCA 2\")\n",
    "\n",
    "axes[1].bar(np.arange(5), pca.explained_variance_ratio_)\n",
    "axes[1].set_xlabel(\"PCA Component\")\n",
    "\n",
    "\n",
    "task_embed_reduced = pca.transform(task_embed.reshape(1, -1)) * 3\n",
    "\n",
    "axes[0].arrow(0, 0, task_embed_reduced[0, 0], task_embed_reduced[0, 1], width=0.5)\n",
    "\n",
    "plt.suptitle(\"PCA of embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Create a subplot\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=('3D PCA', 'Explained Variance'),\n",
    "    column_widths=[0.7, 0.3],\n",
    "    specs=[[{'type': 'scatter3d'}, {'type': 'bar'}]]\n",
    ")\n",
    "\n",
    "# Create frames for each PCA projection and explained variance\n",
    "frames = [\n",
    "    go.Frame(\n",
    "        data=[\n",
    "            go.Scatter3d(\n",
    "            x=embed[:, 0], \n",
    "            y=embed[:, 1], \n",
    "            z=embed[:, 2],\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                    # symbol=symbols[:-2],\n",
    "                    symbol=\"circle\",\n",
    "                    size=5 #sizes[:-2], \n",
    "                    # opacity=opacities[:-2]\n",
    "                )\n",
    "        ),\n",
    "            # go.Bar(\n",
    "            #     x=list(range(1, len(pca_proj[1].explained_variance_ratio_) + 1)),\n",
    "            #     y=pca_proj[1].explained_variance_ratio_,\n",
    "            #     name=\"Explained Variance\",\n",
    "            # )\n",
    "            go.Scatter3d(\n",
    "                x=[0, task_embed_reduced[0, 0]], y=[0, task_embed_reduced[0, 1]], z=[0, task_embed_reduced[0, 2]],\n",
    "                mode='lines+markers',\n",
    "                line=dict(width=5.0, color='red'),\n",
    "                marker=dict(size=[0, 6], color=['red', 'red'], symbol=['circle', 'cross']),\n",
    "                name='Arrow'\n",
    "            ),\n",
    "        ],\n",
    "        name=str(i)\n",
    "    ) for i, embed in enumerate(dr_embeddings_over_time)\n",
    "]\n",
    "\n",
    "# Add frames to figure\n",
    "fig.frames = frames\n",
    "\n",
    "# Add initial data\n",
    "fig.add_trace(\n",
    "     go.Scatter3d(\n",
    "            x=dr_embeddings_over_time[0][:, 0], \n",
    "            y=dr_embeddings_over_time[0][:, 1], \n",
    "            z=dr_embeddings_over_time[0][:, 2],\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                    # symbol=symbols[:-2],\n",
    "                    symbol=\"circle\",\n",
    "                    size=5 #sizes[:-2], \n",
    "                    # opacity=opacities[:-2]\n",
    "                )\n",
    "        ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter3d(\n",
    "        x=[0, task_embed_reduced[0, 0]], y=[0, task_embed_reduced[0, 1]], z=[0, task_embed_reduced[0, 2]],\n",
    "        mode='lines+markers',\n",
    "        line=dict(width=5.0, color='red'),\n",
    "        marker=dict(size=[0, 6], color=['red', 'red'], symbol=['circle', 'cross']),\n",
    "        name='Arrow'\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# fig.add_trace(\n",
    "#     go.Bar(\n",
    "#         x=list(range(1, len(embed[1].explained_variance_ratio_) + 1)),\n",
    "#         y=embed[1].explained_variance_ratio_,\n",
    "#         name=\"Explained Variance\",\n",
    "#     ),\n",
    "#     row=1, col=2\n",
    "# )\n",
    "\n",
    "# Create slider steps\n",
    "steps = [\n",
    "    dict(\n",
    "        args=[[frame.name], {\"frame\": {\"duration\": 100, \"redraw\": True},\n",
    "                             \"mode\": \"immediate\",\n",
    "                             \"transition\": {\"duration\": 100}}],\n",
    "         label=str(step), \n",
    "              method=\"animate\") for step, frame in zip(run.checkpointer.file_ids, frames)]\n",
    "\n",
    "\n",
    "# Add slider and play button\n",
    "sliders = [dict(steps=steps,\n",
    "                active=0,\n",
    "                yanchor='top',\n",
    "                xanchor='left',\n",
    "                currentvalue={\n",
    "                    \"font\": {\"size\": 20},\n",
    "                    \"prefix\": \"Model:\",\n",
    "                    \"visible\": True,\n",
    "                    \"xanchor\": \"right\"\n",
    "                },\n",
    "                transition={\"duration\": 300, \"easing\": \"cubic-in-out\"})]\n",
    "fig.update_layout(\n",
    "    updatemenus=[\n",
    "        dict(type=\"buttons\",\n",
    "             showactive=False,\n",
    "             buttons=[\n",
    "                 dict(label=\"Play\",\n",
    "                      method=\"animate\",\n",
    "                      args=[None, {\"frame\": {\"duration\": 200, \"redraw\": True},\n",
    "                                   \"fromcurrent\": True,\n",
    "                                   \"transition\": {\"duration\": 200}}])\n",
    "             ])\n",
    "    ],\n",
    "    sliders=sliders,\n",
    "    yaxis1=dict(range=[0, 1])\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cossims_over_time = pd.DataFrame([entry for model, step in zip(models, run.checkpointer.file_ids) for entry in [\n",
    "    {\n",
    "        \"cossim\": np.dot(e, task_embed) / (np.linalg.norm(e) * np.linalg.norm(task_embed)),\n",
    "        \"embed_i\": i,\n",
    "        \"step\": step\n",
    "    }\n",
    "    for i, e in enumerate(model.token_sequence_transformer.token_embedding.weight.detach().cpu().numpy())\n",
    "]])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "sns.lineplot(data=all_cossims_over_time, x=\"step\", y=\"cossim\", hue=\"embed_i\", ax=ax)\n",
    "ax.set_xscale('log')\n",
    "\n",
    "# Milestones\n",
    "for color, (start, end, label) in zip(milestone_colors, milestones):\n",
    "    ax.axvspan(start, end, alpha=0.2, label=label, color=color)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the cossims of each of the embedding vectors with their original value over time\n",
    "init_embeds = models[0].token_sequence_transformer.token_embedding.weight.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "all_cossims_with_init_over_time = pd.DataFrame([entry for model, step in zip(models, run.checkpointer.file_ids) for entry in [\n",
    "    {\n",
    "        \"cossim\": np.dot(e, init_embeds[i]) / (np.linalg.norm(e) * np.linalg.norm(init_embeds[i])),\n",
    "        \"rel_magnitude\": np.linalg.norm(e) / np.linalg.norm(init_embeds[i]),\n",
    "        \"embed_i\": i,\n",
    "        \"step\": step\n",
    "    }\n",
    "    for i, e in enumerate(model.token_sequence_transformer.token_embedding.weight.detach().cpu().numpy())\n",
    "]])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "sns.lineplot(data=all_cossims_with_init_over_time, x=\"step\", y=\"cossim\", hue=\"embed_i\", ax=ax, alpha=0.5)\n",
    "ax.set_xscale('log')\n",
    "\n",
    "for color, (start, end, label) in zip(milestone_colors, milestones):\n",
    "    ax.axvspan(start, end, alpha=0.2, label=label, color=color)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "sns.lineplot(data=all_cossims_with_init_over_time, x=\"step\", y=\"rel_magnitude\", hue=\"embed_i\", ax=ax, alpha=0.5)\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "\n",
    "for color, (start, end, label) in zip(milestone_colors, milestones):\n",
    "    ax.axvspan(start, end, alpha=0.2, label=label, color=color)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "sns.lineplot(data=all_cossims_with_init_over_time.loc[all_cossims_with_init_over_time.step < 5000], x=\"step\", y=\"rel_magnitude\", hue=\"embed_i\", ax=ax, alpha=0.5)\n",
    "ax.set_xscale('log')\n",
    "\n",
    "for color, (start, end, label) in zip(milestone_colors, milestones):\n",
    "    end = min(end, 5000)\n",
    "\n",
    "    if start < 5000:\n",
    "        ax.axvspan(start, end, alpha=0.2, label=label, color=color)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the cossims of each of the unembedding vectors with their original value over time\n",
    "init_unembeds = models[0].token_sequence_transformer.unembedding[1].weight.detach().cpu().numpy().T\n",
    "\n",
    "all_cossims_with_init_over_time = pd.DataFrame([entry for model, step in zip(models, run.checkpointer.file_ids) for entry in [\n",
    "    {\n",
    "        \"cossim\": np.dot(e, init_unembeds[i]) / (np.linalg.norm(e) * np.linalg.norm(init_unembeds[i])),\n",
    "        \"1_min_cossim\": 1 - np.dot(e, init_unembeds[i]) / (np.linalg.norm(e) * np.linalg.norm(init_unembeds[i])),\n",
    "        \"rel_magnitude\": np.linalg.norm(e) / np.linalg.norm(init_unembeds[i]),\n",
    "        \"unembed_i\": i,\n",
    "        \"step\": step\n",
    "    }\n",
    "    for i, e in enumerate(model.token_sequence_transformer.unembedding[1].weight.detach().cpu().numpy().T)\n",
    "]])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "sns.lineplot(data=all_cossims_with_init_over_time, x=\"step\", y=\"cossim\", hue=\"unembed_i\", ax=ax, alpha=0.5)\n",
    "ax.set_xscale('log')\n",
    "\n",
    "ax.set_ylim(0.9, 1.)\n",
    "\n",
    "for color, (start, end, label) in zip(milestone_colors, milestones):\n",
    "    ax.axvspan(start, end, alpha=0.2, label=label, color=color)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "sns.lineplot(data=all_cossims_with_init_over_time, x=\"step\", y=\"rel_magnitude\", hue=\"unembed_i\", ax=ax, alpha=0.5)\n",
    "ax.set_xscale('log')\n",
    "\n",
    "for color, (start, end, label) in zip(milestone_colors, milestones):\n",
    "    ax.axvspan(start, end, alpha=0.2, label=label, color=color)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to look at the cossims of the activation vectors with the original value over time\n",
    "\n",
    "activations = []\n",
    "\n",
    "resid_layers = [\n",
    "    \"token_sequence_transformer.token_embedding\",\n",
    "    \"token_sequence_transformer.blocks.0.resid_after_attn\",\n",
    "    \"token_sequence_transformer.blocks.0\",\n",
    "    \"token_sequence_transformer.blocks.1.resid_after_attn\",\n",
    "    \"token_sequence_transformer.blocks.1\",\n",
    "    \"token_sequence_transformer.unembedding.0\"       \n",
    "]\n",
    "\n",
    "init_activations = {}\n",
    "\n",
    "for step, model in tqdm(zip(run.checkpointer.file_ids, models)):\n",
    "    model.to('mps')\n",
    "    hooked_model = hook(model)\n",
    "    model_acts = []\n",
    "\n",
    "    for x in torch.eye(4, device=\"mps\"):\n",
    "        y = torch.zeros((1, 1, 1), device=\"mps\")\n",
    "        model_acts.append(hooked_model.run_with_cache(x.unsqueeze(0).unsqueeze(0), y)[1])\n",
    "\n",
    "    cossims = []\n",
    "\n",
    "    for j, layer in enumerate(resid_layers):\n",
    "        layer_acts = torch.stack([acts[layer] for acts in model_acts])[:, 0, 0, :].T.detach().cpu().numpy()\n",
    "\n",
    "        if step == 0:\n",
    "            init_activations[layer]= layer_acts\n",
    "\n",
    "        init_acts = init_activations[layer]\n",
    "        cossims.append([np.dot(layer_acts[i], init_acts[i]) / (np.linalg.norm(layer_acts[i]) * np.linalg.norm(init_acts[i])) for i in range(64)])\n",
    "\n",
    "    for i in range(64):\n",
    "        activations.append({\n",
    "            \"step\": step,\n",
    "            **{layer: cossim[i] for layer, cossim in zip(resid_layers, cossims)},\n",
    "            \"embed_i\": i\n",
    "        })\n",
    "\n",
    "activations = pd.DataFrame(activations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(len(resid_layers), 1, figsize=(15, 15))\n",
    "\n",
    "MAX_STEP = 10_000\n",
    "\n",
    "for layer, ax in zip(resid_layers, axes):\n",
    "    sns.lineplot(data=activations.loc[activations.step < MAX_STEP], x=\"step\", y=layer, hue=\"embed_i\", alpha=0.5, ax=ax)\n",
    "    ax.set_title(layer.replace(\"token_sequence_transformer.\", \"\"))\n",
    "    ax.set_xscale(\"log\")\n",
    "    \n",
    "    for color, (start, end, label) in zip(milestone_colors, milestones):\n",
    "        end = min(end, MAX_STEP)\n",
    "\n",
    "        if start < MAX_STEP:\n",
    "            ax.axvspan(start, end, alpha=0.2, label=label, color=color)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "\n",
    "def fit_transform_explained_var(model, n_components=5):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    transforms = pca.fit_transform(model.token_sequence_transformer.token_embedding.weight.detach().cpu().numpy())\n",
    "    return transforms, pca\n",
    "\n",
    "dr_embeddings_over_time_fit = [\n",
    "    fit_transform_explained_var(model, 5)\n",
    "    for model in models\n",
    "]\n",
    "\n",
    "# Create a subplot\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=('3D PCA', 'Explained Variance'),\n",
    "    column_widths=[0.7, 0.3],\n",
    "    specs=[[{'type': 'scatter3d'}, {'type': 'bar'}]]\n",
    ")\n",
    "\n",
    "\n",
    "# Create frames for each PCA projection and explained variance\n",
    "frames = [\n",
    "    go.Frame(\n",
    "        data=[\n",
    "            go.Scatter3d(\n",
    "            x=embed[0][:, 0], \n",
    "            y=embed[0][:, 1], \n",
    "            z=embed[0][:, 2],\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                    # symbol=symbols[:-2],\n",
    "                    symbol=\"circle\",\n",
    "                    size=5 #sizes[:-2], \n",
    "                    # opacity=opacities[:-2]\n",
    "                )\n",
    "        ),\n",
    "            go.Bar(\n",
    "                x=list(range(1, len(embed[1].explained_variance_ratio_) + 1)),\n",
    "                y=embed[1].explained_variance_ratio_,\n",
    "                name=\"Explained Variance\",\n",
    "            )\n",
    "        ],\n",
    "        name=str(i)\n",
    "    ) for i, embed in enumerate(dr_embeddings_over_time_fit)\n",
    "]\n",
    "\n",
    "# Add frames to figure\n",
    "fig.frames = frames\n",
    "\n",
    "# Add initial data\n",
    "fig.add_trace(\n",
    "     go.Scatter3d(\n",
    "            x=dr_embeddings_over_time_fit[0][0][:, 0], \n",
    "            y=dr_embeddings_over_time_fit[0][0][:, 1], \n",
    "            z=dr_embeddings_over_time_fit[0][0][:, 2],\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                    # symbol=symbols[:-2],\n",
    "                    symbol=\"circle\",\n",
    "                    size=5 #sizes[:-2], \n",
    "                    # opacity=opacities[:-2]\n",
    "                )\n",
    "        ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=list(range(1, len(dr_embeddings_over_time_fit[0][1].explained_variance_ratio_) + 1)),\n",
    "        y=dr_embeddings_over_time_fit[0][1].explained_variance_ratio_,\n",
    "        name=\"Explained Variance\",\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# Create slider steps\n",
    "steps = [\n",
    "    dict(\n",
    "        args=[[frame.name], {\"frame\": {\"duration\": 100, \"redraw\": True},\n",
    "                             \"mode\": \"immediate\",\n",
    "                             \"transition\": {\"duration\": 100}}],\n",
    "         label=str(step), \n",
    "              method=\"animate\") for step, frame in zip(run.checkpointer.file_ids, frames)]\n",
    "\n",
    "\n",
    "# Add slider and play button\n",
    "sliders = [dict(steps=steps,\n",
    "                active=0,\n",
    "                yanchor='top',\n",
    "                xanchor='left',\n",
    "                currentvalue={\n",
    "                    \"font\": {\"size\": 20},\n",
    "                    \"prefix\": \"Model:\",\n",
    "                    \"visible\": True,\n",
    "                    \"xanchor\": \"right\"\n",
    "                },\n",
    "                transition={\"duration\": 300, \"easing\": \"cubic-in-out\"})]\n",
    "fig.update_layout(\n",
    "    updatemenus=[\n",
    "        dict(type=\"buttons\",\n",
    "             showactive=False,\n",
    "             buttons=[\n",
    "                 dict(label=\"Play\",\n",
    "                      method=\"animate\",\n",
    "                      args=[None, {\"frame\": {\"duration\": 200, \"redraw\": True},\n",
    "                                   \"fromcurrent\": True,\n",
    "                                   \"transition\": {\"duration\": 200}}])\n",
    "             ])\n",
    "    ],\n",
    "    sliders=sliders,\n",
    "    yaxis1=dict(range=[0, 1])\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Let's look at the 5 layer norms over time\n",
    "\n",
    "ln_layers = [\n",
    "    \"token_sequence_transformer.blocks.0.layer_norms.0\",\n",
    "    \"token_sequence_transformer.blocks.0.layer_norms.1\",\n",
    "    \"token_sequence_transformer.blocks.1.layer_norms.0\",\n",
    "    \"token_sequence_transformer.blocks.1.layer_norms.1\",\n",
    "    \"token_sequence_transformer.unembedding.0\"\n",
    "]\n",
    "\n",
    "lns_over_time = []\n",
    "\n",
    "for step, model in zip(run.checkpointer.file_ids, models):\n",
    "    for layer in ln_layers:\n",
    "        lns_over_time.append({\n",
    "            \"step\": step,\n",
    "            \"layer\": layer,\n",
    "            \"weight\": model.state_dict()[layer + \".weight\"].detach().cpu().numpy(),\n",
    "            \"bias\": model.state_dict()[layer + \".bias\"].detach().cpu().numpy()\n",
    "        })\n",
    "\n",
    "lns_over_time = pd.DataFrame(lns_over_time)\n",
    "\n",
    "max_y_weight = {}\n",
    "max_y_bias = {}\n",
    "for layer in ln_layers:\n",
    "    all_weights = [item for item in lns_over_time.loc[lns_over_time['layer'] == layer]['weight']]\n",
    "    all_biases = [item for item in lns_over_time.loc[lns_over_time['layer'] == layer]['bias']]\n",
    "    max_y_weight[layer] = max([val.max() for val in all_weights])\n",
    "    max_y_bias[layer] = max([val.max() for val in all_biases])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize subplots, 2 rows (for weight and bias) and 5 columns (for each layer)\n",
    "fig = make_subplots(rows=2, cols=5, subplot_titles=[(\".\").join(ln_layer.replace(\"layer_norms\", \"ln\").split('.')[1:]) + \".weight\" for ln_layer in ln_layers] + [(\".\").join(ln_layer.replace(\"layer_norms\", \"ln\").split('.')[1:]) + \".bias\" for ln_layer in ln_layers])\n",
    "\n",
    "for index, layer in enumerate(ln_layers):\n",
    "    initial_data = lns_over_time[(lns_over_time['layer'] == layer) & (lns_over_time['step'] == 0)]\n",
    "    \n",
    "    # Weight bar plot\n",
    "    fig.add_trace(\n",
    "        go.Bar(x=list(range(len(initial_data['weight'].iloc[0]))), y=initial_data['weight'].iloc[0]),\n",
    "        row=1, col=index+1\n",
    "    )\n",
    "    fig.update_yaxes(range=[0, max_y_weight[layer]], row=1, col=index+1)\n",
    "    \n",
    "    # Bias bar plot\n",
    "    fig.add_trace(\n",
    "        go.Bar(x=list(range(len(initial_data['bias'].iloc[0]))), y=initial_data['bias'].iloc[0]),\n",
    "        row=2, col=index+1\n",
    "    )\n",
    "    fig.update_yaxes(range=[0, max_y_bias[layer]], row=2, col=index+1)\n",
    "\n",
    "# Define animation frames\n",
    "frames = []\n",
    "for step in lns_over_time['step'].unique():\n",
    "    frame_data = []\n",
    "    \n",
    "    for index, layer in enumerate(ln_layers):\n",
    "        step_data = lns_over_time[(lns_over_time['layer'] == layer) & (lns_over_time['step'] == step)]\n",
    "        \n",
    "        # Weight\n",
    "        frame_data.append(go.Bar(x=list(range(len(step_data['weight'].iloc[0]))), y=step_data['weight'].iloc[0]))\n",
    "        \n",
    "        # Bias\n",
    "        frame_data.append(go.Bar(x=list(range(len(step_data['bias'].iloc[0]))), y=step_data['bias'].iloc[0]))\n",
    "    \n",
    "    frames.append(go.Frame(data=frame_data, name=f\"Step {step}\"))\n",
    "\n",
    "fig.frames = frames\n",
    "\n",
    "# Add play and pause buttons\n",
    "animation_settings = dict(frame=dict(duration=300, redraw=True), fromcurrent=True)\n",
    "fig.update_layout(updatemenus=[dict(type=\"buttons\", showactive=False, buttons=[dict(label=\"Play\",\n",
    "                                            method=\"animate\", args=[None, animation_settings]),\n",
    "                                          dict(label=\"Pause\", method=\"animate\", args=[[None], dict(frame=dict(duration=0, redraw=False), mode=\"immediate\")])])])\n",
    "\n",
    "\n",
    "# Add sliders\n",
    "sliders = [dict(steps=[dict(method='animate', args=[[f'Step {s}'], dict(mode='immediate', frame=dict(duration=300, redraw=True))], label=f'Step {s}') for s in lns_over_time['step'].unique()], active=0)]\n",
    "\n",
    "fig.update_layout(sliders=sliders)\n",
    "\n",
    "# Show figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import patches\n",
    "from icl.model import to_token_sequence, from_predicted_token_sequence\n",
    "\n",
    "class EmbedUnembedOnlyV2(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.to_token_sequence = to_token_sequence\n",
    "        self.token_embedding = model.token_sequence_transformer.token_embedding\n",
    "        self.positional_embedding = model.token_sequence_transformer.postn_embedding\n",
    "        self.unembedding = model.token_sequence_transformer.unembedding\n",
    "        self.from_predicted_token_sequence = from_predicted_token_sequence\n",
    "\n",
    "    def forward(self, xs, ys):\n",
    "        tokens = self.to_token_sequence(xs, ys)\n",
    "\n",
    "        T = tokens.shape[1]\n",
    "        x = self.token_embedding(tokens) + self.positional_embedding.weight.T[:T, :]\n",
    "        # Set everything to zero except for dimensions 46 and 51\n",
    "        # embedded[:, :, :46] = 0\n",
    "        # embedded[:, :, 47:51] = 0\n",
    "        # embedded[:, :, 52:] = 0\n",
    "\n",
    "        x = self.unembedding[0](x)\n",
    "        unembedded = self.unembedding[1](x)\n",
    "\n",
    "        # raise ValueError(\"Done\")\n",
    "    \n",
    "        return self.from_predicted_token_sequence(unembedded)\n",
    "\n",
    "\n",
    "# embed_unembed_only_model = EmbedUnembedOnly(run.model)\n",
    "\n",
    "def get_embed_unembed_with_bias(model):\n",
    "    eu_model = EmbedUnembedOnlyV2(model).to('cpu')\n",
    "\n",
    "    w = np.zeros(4)\n",
    "    basis = torch.eye(4, device=\"cpu\")\n",
    "    ys = torch.zeros(1, 1, 1, device=\"cpu\")\n",
    "\n",
    "    for i in range(4):\n",
    "        w[i] = eu_model(basis[i].unsqueeze(0).unsqueeze(0), ys)[0].item()\n",
    "\n",
    "    return w\n",
    "\n",
    "\n",
    "embed_unembed_with_bias = [\n",
    "    get_embed_unembed_with_bias(model)\n",
    "    for model in models\n",
    "]\n",
    "\n",
    "print(embed_unembed_with_bias[0].shape, task_embed.shape)\n",
    "\n",
    "cossims = [\n",
    "    (v @ task_np) / (np.linalg.norm(v) * np.linalg.norm(task_np) ) for v in embed_unembed_with_bias\n",
    "]\n",
    "\n",
    "def to_slopes(steps, values):\n",
    "    slope = np.zeros(len(steps))\n",
    "\n",
    "    # Compute Slope and Curvature\n",
    "    for i in range(1, len(steps) - 1):\n",
    "        dx1 = steps[i+1] - steps[i]\n",
    "        dx0 = steps[i] - steps[i-1]\n",
    "        \n",
    "        dy1 = values[i+1] - values[i]\n",
    "        dy0 = values[i] - values[i-1]\n",
    "        \n",
    "        slope[i] = (dy1 / dx1 + dy0 / dx0) / 2\n",
    "\n",
    "    return slope\n",
    "\n",
    "cossims_slopes = to_slopes(run.checkpointer.file_ids, cossims)\n",
    "\n",
    "fig, (ax0, ax1) = plt.subplots(1, 2, figsize=(16, 5))\n",
    "ax0.plot(run.checkpointer.file_ids, cossims)\n",
    "ax0.set_xscale(\"log\")\n",
    "ax0.set_xlabel(\"step\")\n",
    "ax0.set_ylabel(r\"Cosine similarity with $w_1$\")\n",
    "ax0.set_title(\"Effective weight using only embedding (both token & positional), unembedding (both LN & linear), with biases\")\n",
    "\n",
    "ax1.plot(run.checkpointer.file_ids, cossims_slopes)\n",
    "ax1.set_xscale(\"log\")\n",
    "ax1.set_xlabel(\"step\")\n",
    "ax1.set_ylabel(r\"Slope of cosine similarity with $w_1$\")\n",
    "ax1.set_title(\"Slope of effective weight using only embedding (both token & positional), unembedding (both LN & linear), with biases\")\n",
    "\n",
    "# Milestones\n",
    "for ax in (ax0, ax1):\n",
    "    for color, (start, end, label) in zip(milestone_colors, milestones):\n",
    "        ax.axvspan(start, end, alpha=0.2, label=label, color=color)\n",
    "\n",
    "# Add milestone legend\n",
    "patchList = []\n",
    "for color, (start, end, label) in zip(milestone_colors, milestones):\n",
    "    data_key = patches.Patch(color=color, alpha=0.2, label=label)\n",
    "    patchList.append(data_key)\n",
    "\n",
    "fig.set_facecolor('white')\n",
    "plt.legend(handles=patchList, loc='lower left')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import patches\n",
    "from icl.model import to_token_sequence, from_predicted_token_sequence\n",
    "\n",
    "class EmbedUnembedOnlyV2(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.to_token_sequence = to_token_sequence\n",
    "        self.token_embedding = model.token_sequence_transformer.token_embedding\n",
    "        self.positional_embedding = model.token_sequence_transformer.postn_embedding\n",
    "        self.unembedding = model.token_sequence_transformer.unembedding\n",
    "        self.from_predicted_token_sequence = from_predicted_token_sequence\n",
    "\n",
    "    def forward(self, xs, ys):\n",
    "        tokens = self.to_token_sequence(xs, ys)\n",
    "\n",
    "        T = tokens.shape[1]\n",
    "        x = self.token_embedding(tokens) #+ self.positional_embedding.weight.T[:T, :]\n",
    "        # Set everything to zero except for dimensions 46 and 51\n",
    "        # embedded[:, :, :46] = 0\n",
    "        # embedded[:, :, 47:51] = 0\n",
    "        # embedded[:, :, 52:] = 0\n",
    "\n",
    "        # x = self.unembedding[0](x)\n",
    "        unembedded = self.unembedding[1](x)\n",
    "\n",
    "        # raise ValueError(\"Done\")\n",
    "    \n",
    "        return self.from_predicted_token_sequence(unembedded)\n",
    "\n",
    "\n",
    "# embed_unembed_only_model = EmbedUnembedOnly(run.model)\n",
    "\n",
    "def get_embed_unembed_with_bias(model):\n",
    "    eu_model = EmbedUnembedOnlyV2(model).to('cpu')\n",
    "\n",
    "    w = np.zeros(4)\n",
    "    basis = torch.eye(4, device=\"cpu\")\n",
    "    ys = torch.zeros(1, 1, 1, device=\"cpu\")\n",
    "\n",
    "    for i in range(4):\n",
    "        w[i] = eu_model(basis[i].unsqueeze(0).unsqueeze(0), ys)[0].item()\n",
    "\n",
    "    return w\n",
    "\n",
    "\n",
    "embed_unembed_with_bias = [\n",
    "    get_embed_unembed_with_bias(model)\n",
    "    for model in models\n",
    "]\n",
    "\n",
    "print(embed_unembed_with_bias[0].shape, task_embed.shape)\n",
    "\n",
    "cossims = [\n",
    "    (v @ task_np) / (np.linalg.norm(v) * np.linalg.norm(task_np)) for v in embed_unembed_with_bias\n",
    "]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "ax.plot(run.checkpointer.file_ids, cossims)\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_xlabel(\"step\")\n",
    "ax.set_ylabel(r\"Cosine similarity with $w_1$\")\n",
    "ax.set_title(\"Effective weight using only embedding (token only), unembedding (linear only), with biases\")\n",
    "\n",
    "# Milestones\n",
    "for color, (start, end, label) in zip(milestone_colors, milestones):\n",
    "    ax.axvspan(start, end, alpha=0.2, label=label, color=color)\n",
    "\n",
    "# Add milestone legend\n",
    "patchList = []\n",
    "for color, (start, end, label) in zip(milestone_colors, milestones):\n",
    "    data_key = patches.Patch(color=color, alpha=0.2, label=label)\n",
    "    patchList.append(data_key) \n",
    "\n",
    "fig.set_facecolor('white')\n",
    "\n",
    "\n",
    "plt.legend(handles=patchList, loc='lower left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict = dict(zip(run.checkpointer.file_ids, models))\n",
    "print(models_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diff_norm(step1, step2):\n",
    "    model1 = models_dict[step1]\n",
    "    model2 = models_dict[step2]\n",
    "    diffs = {}\n",
    "    for key in model1.state_dict().keys():\n",
    "        diffs[key] = (model1.state_dict()[key] - model2.state_dict()[key]).std().item() # / model1.state_dict()[key].norm().item() #  model1.state_dict()[key].numel()\n",
    "\n",
    "    return diffs\n",
    "\n",
    "\n",
    "def get_closest_step(step):\n",
    "    return min(models_dict.keys(), key=lambda x: abs(int(x) - step))\n",
    "\n",
    "milestone_steps = sorted(list({m for milestone in milestones for m in milestone[:2]}))\n",
    "milestone_steps = [get_closest_step(m) for m in milestone_steps]\n",
    "\n",
    "for m1, m2 in zip(milestone_steps, milestone_steps[1:]):\n",
    "    diffs = get_diff_norm(m1, m2)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "\n",
    "    ax.bar(np.arange(len(diffs)), list(diffs.values()))\n",
    "    ax.set_xticks(np.arange(len(diffs)), list(diffs.keys()), rotation=90)\n",
    "    ax.set_ylabel(\"Norm of difference\")\n",
    "    ax.set_title(f\"Norm of difference between step {m1} and {m2}\")\n",
    "\n",
    "    fig.set_facecolor('white')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It makes perfect sense that the layer norm biases are changing most from this perspective because they start at 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's happening at the start? \n",
    "# I think the model is learning something like linear regression (using the unembedding) on mostly random features (due to the attention & MLPs).\n",
    "# The randomness has a regularlizing effect.\n",
    "# By 5000 steps, the model has ~perfect performance. If we throw out the attention and MLP and positional encoding, this performance is reduced.\n",
    "# When we find this solution, the model then starts trying to reduce its dependence on the MLP and attention. \n",
    "# By 10k steps, the model only needs the embedding/unembedding to actually solve the task. However, the LN continues to have a regularizing effect akin to dropout or random noise applied to logits.\n",
    "# To get around this, the model starts increasing the scale of its activations. To accomplish this while maintaining a zero mean, the embedding collapses in rank. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait if my layer norm theory is right. Then we should see a sudden improvement in the ability of the model to make predictions for out-of-distribution xs/ys (not ws). \n",
    "from devinfra.utils.seed import set_seed\n",
    "from icl.tasks import apply_transformations\n",
    "\n",
    "DEVICE = \"mps\"\n",
    "\n",
    "pretrain_dist_noiseless = run.config.task_config.pretrain_dist_factory().to(\n",
    "    DEVICE\n",
    ")\n",
    "pretrain_dist_noiseless.std = 0.\n",
    "\n",
    "set_seed(run.config.task_config.true_seed)\n",
    "\n",
    "\n",
    "# shorthands\n",
    "B = 1024\n",
    "K = 8\n",
    "D = 4\n",
    "\n",
    "# sample a batch of random tasks\n",
    "ws = pretrain_dist_noiseless.task_distribution.sample_tasks(B) # -> B D\n",
    "\n",
    "# sample i.i.d. inputs and outputs for each task according to the\n",
    "# regression model\n",
    "xs = torch.normal(\n",
    "    mean=0.,\n",
    "    std=1.,\n",
    "    size=(B, K, D,),\n",
    "    device=DEVICE\n",
    ")\n",
    "xs100 = 100 * xs\n",
    "ys = apply_transformations(ws, xs, 0, DEVICE)\n",
    "ys100 = apply_transformations(ws, xs100, 0, DEVICE)\n",
    "\n",
    "def eval_loss(model, xs, ys):\n",
    "    return torch.nn.functional.mse_loss(\n",
    "        model(xs, ys),\n",
    "        ys,\n",
    "    ).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_over_time = []\n",
    "\n",
    "for step, model in zip(run.checkpointer.file_ids, models):\n",
    "    model.to('mps')\n",
    "    losses_over_time.append({\n",
    "        \"step\": step,\n",
    "        \"loss\": eval_loss(model, xs, ys).item(),\n",
    "        \"loss100\": eval_loss(model, xs100, ys100).item()\n",
    "    })\n",
    "\n",
    "losses_over_time = pd.DataFrame(losses_over_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_output_magnitude(model, xs, ys):\n",
    "    norms = model(xs, ys).squeeze(-1).norm(dim=-1)\n",
    "    # norms = model(xs, ys).squeeze(-1).abs().mean(dim=-1)\n",
    "    return norms.mean().item(), norms.std().item()\n",
    "\n",
    "output_magnitudes_over_time = []\n",
    "\n",
    "for step, model in zip(run.checkpointer.file_ids, models):\n",
    "    norm, norm_std = eval_output_magnitude(model, xs, ys)\n",
    "    output_magnitudes_over_time.append({\n",
    "        \"step\": step,\n",
    "        \"output_magnitude\": norm,\n",
    "        \"output_magnitude_std\": norm_std\n",
    "    })\n",
    "\n",
    "output_magnitudes_over_time = pd.DataFrame(output_magnitudes_over_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(16, 5))\n",
    "\n",
    "sns.lineplot(data=output_magnitudes_over_time, x=\"step\", y=\"output_magnitude\", label=\"Loss\", ax=ax)\n",
    "\n",
    "ax.fill_between(\n",
    "    output_magnitudes_over_time[\"step\"],\n",
    "    output_magnitudes_over_time[\"output_magnitude\"] - output_magnitudes_over_time[\"output_magnitude_std\"],\n",
    "    output_magnitudes_over_time[\"output_magnitude\"] + output_magnitudes_over_time[\"output_magnitude_std\"],\n",
    "    alpha=0.2\n",
    ")\n",
    "\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_xlabel(\"step\")\n",
    "ax.set_yscale('log')\n",
    "ax.set_ylabel(\"MSE Loss\")\n",
    "\n",
    "ax.set_title(\"Output magnitude\")\n",
    "\n",
    "for color, (start, end, label) in zip(milestone_colors, milestones):\n",
    "    ax.axvspan(start, end, alpha=0.2, label=label, color=color)\n",
    "\n",
    "ax.set_xscale('log')\n",
    "\n",
    "# Add milestone legend\n",
    "patchList = []\n",
    "\n",
    "fig.set_facecolor('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see how this compares to the learning curve if we train models to predict 0\n",
    "from collections import defaultdict\n",
    "from devinfra.io.logging import DataFrameLogger\n",
    "from torch.nn import functional as F\n",
    "from tqdm import trange\n",
    "import yaml \n",
    "\n",
    "# model_trained_0s = deepcopy(models[0]) \n",
    "model_trained_normal = deepcopy(models[0]) \n",
    "\n",
    "# gradients = []\n",
    "# logs = defaultdict(dict)\n",
    "\n",
    "log_steps = sorted(list(run.config.logger_config.logging_steps))\n",
    "\n",
    "for i, model in [(1, model_trained_normal)]:\n",
    "# for i, model in enumerate([model_trained_0s, model_trained_normal]):\n",
    "    optimizer = run.config.optimizer_config.factory(model.parameters())\n",
    "    scheduler = run.config.scheduler_config.factory(optimizer)\n",
    "    num_steps = 5000\n",
    "\n",
    "    batch_losses = np.zeros(num_steps)\n",
    "\n",
    "\n",
    "    # training loop\n",
    "    for step in trange(num_steps, desc=\"Training...\"):\n",
    "        set_seed(\n",
    "            run.config.task_config.sampling_seed + step\n",
    "        )  # For reproducibility if we resume training\n",
    "\n",
    "        # data generation and forward pass\n",
    "        xs, ys = run.pretrain_dist.get_batch(\n",
    "            num_examples=run.config.task_config.max_examples,\n",
    "            batch_size=run.config.batch_size,\n",
    "        )\n",
    "\n",
    "        ys_pred = model(xs, ys)\n",
    "        target_ys = torch.zeros_like(ys) if i == 0 else ys\n",
    "\n",
    "        loss = F.mse_loss(target_ys, ys_pred)\n",
    "        # backward pass and gradient step\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            batch_losses[step] = loss.mean().item()\n",
    "\n",
    "        # Log to wandb & save checkpoints according to log_steps\n",
    "        if step in run.config.logger_config.logging_steps:\n",
    "            log_idx = log_steps.index(step)\n",
    "\n",
    "            model.eval()\n",
    "            magnitudes = eval_output_magnitude(model, xs, ys)\n",
    "            metrics = {\n",
    "                f\"loss/{i}\": eval_loss(model, xs, ys).item(),\n",
    "                f\"magnitudes/{i}\": magnitudes[0],\n",
    "                f\"magnitudes_std/{i}\": magnitudes[1],\n",
    "            }\n",
    "            if i == 0:\n",
    "                gradients.append([p.data for p in model.parameters()])\n",
    "            else:\n",
    "                # norm0 = sum([p.norm() ** 2 for p in gradients[log_idx]]) ** 0.5\n",
    "                # norm1 = sum([p.norm() ** 2 for p in model.parameters()]) ** 0.5\n",
    "                # dot = sum([(p1 * p2.data).sum() for p1, p2 in zip(gradients[log_idx], model.parameters())])\n",
    "                norms0 = ([p.norm() ** 2 for p in gradients[log_idx]])\n",
    "                norms1 = ([p.norm() ** 2 for p in model.parameters()])\n",
    "                dots = ([(p1 * p2.data).sum() for p1, p2 in zip(gradients[log_idx], model.parameters())])\n",
    "                grad_cossims = dot / (norm0 * norm1)\n",
    "\n",
    "                metrics[\"cossim\"] = grad_cossims.item()\n",
    "\n",
    "            logs[step].update(metrics)\n",
    "\n",
    "            model.train()\n",
    "            # print(yaml.dump(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(16, 5))\n",
    "\n",
    "sns.lineplot(data=output_magnitudes_over_time, x=\"step\", y=\"output_magnitude\", label=\"Loss\", ax=ax)\n",
    "\n",
    "ax.fill_between(\n",
    "    output_magnitudes_over_time[\"step\"],\n",
    "    output_magnitudes_over_time[\"output_magnitude\"] - output_magnitudes_over_time[\"output_magnitude_std\"],\n",
    "    output_magnitudes_over_time[\"output_magnitude\"] + output_magnitudes_over_time[\"output_magnitude_std\"],\n",
    "    alpha=0.2\n",
    ")\n",
    "\n",
    "sns.lineplot(data=df_trained_to_0, x=\"step\", y=\"magnitudes\", label=\"Loss\", ax=ax)\n",
    "\n",
    "ax.fill_between(\n",
    "    df_trained_to_0[\"step\"],\n",
    "    df_trained_to_0[\"magnitudes\"] - df_trained_to_0[\"magnitudes_std\"],\n",
    "    df_trained_to_0[\"magnitudes\"] + df_trained_to_0[\"magnitudes_std\"],\n",
    "    alpha=0.2\n",
    ")\n",
    "\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_xlabel(\"step\")\n",
    "ax.set_yscale('log')\n",
    "ax.set_ylabel(\"Prediction norm\")\n",
    "\n",
    "ax.set_title(\"Output magnitude\")\n",
    "\n",
    "for color, (start, end, label) in zip(milestone_colors, milestones):\n",
    "    ax.axvspan(start, end, alpha=0.2, label=label, color=color)\n",
    "\n",
    "ax.set_xscale('log')\n",
    "\n",
    "# Add milestone legend\n",
    "patchList = []\n",
    "\n",
    "fig.set_facecolor('white')\n",
    "plt.savefig(\"../figures/L2H4M1-output_magnitude.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(16, 5))\n",
    "\n",
    "sns.lineplot(data=logs_df, x=\"step\", y=\"cossim\", label=\"Cossim between gradients\", ax=ax)\n",
    "\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_xlabel(\"step\")\n",
    "ax.set_yscale('log')\n",
    "ax.set_ylabel(\"Cosine similarity\")\n",
    "\n",
    "ax.set_title(\"Cosine similarity between gradients of model trained to predict $y_k$ and model trained to predict 0\")\n",
    "\n",
    "for color, (start, end, label) in zip(milestone_colors, milestones):\n",
    "    ax.axvspan(start, end, alpha=0.2, label=label, color=color)\n",
    "\n",
    "ax.set_xscale('log')\n",
    "\n",
    "# Add milestone legend\n",
    "patchList = []\n",
    "\n",
    "fig.set_facecolor('white')\n",
    "plt.savefig(\"../figures/L2H4M1-output_magnitude.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_df.cossim = [cs.item() for cs in logs_df.cossim]\n",
    "logs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from devinfra.utils.seed import set_seed\n",
    "\n",
    "DEVICE = 'mps'\n",
    "\n",
    "# Gonna override activations sorry.\n",
    "losses_over_time = []\n",
    "outputs_over_time = []\n",
    "activations_over_time = []\n",
    "\n",
    "train_xs_noise, train_ys_noise = run.evaluator.pretrain_xs, run.evaluator.pretrain_ys\n",
    "\n",
    "pretrain_dist_noiseless = run.config.task_config.pretrain_dist_factory().to(\n",
    "    DEVICE\n",
    ")\n",
    "pretrain_dist_noiseless.std = 0.\n",
    "\n",
    "set_seed(run.config.task_config.true_seed)\n",
    "\n",
    "train_xs, train_ys = pretrain_dist_noiseless.get_batch(8, 1024)\n",
    "\n",
    "assert torch.allclose(train_xs, train_xs_noise)\n",
    "\n",
    "\n",
    "for model in models:\n",
    "    hooked_model = hook(model)\n",
    "    output, activation = hooked_model.run_with_cache(train_xs, train_ys)\n",
    "    outputs_over_time.append(output)\n",
    "    losses_over_time.append(nn.MSELoss()(output, train_ys).item())\n",
    "    activations_over_time.append(activation)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
