{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Essential dynamics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "True"
                        ]
                    },
                    "execution_count": 1,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "import os\n",
                "from dotenv import load_dotenv\n",
                "\n",
                "load_dotenv()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "from torch import nn\n",
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import tqdm\n",
                "import seaborn as sns\n",
                "from sklearn.decomposition import PCA\n",
                "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
                "import matplotlib.patches as mpatches\n",
                "\n",
                "import matplotlib.pyplot as plt\n",
                "from mpl_toolkits.mplot3d import Axes3D\n",
                "from matplotlib.patches import FancyArrowPatch\n",
                "from mpl_toolkits.mplot3d import proj3d\n",
                "import seaborn as sns\n",
                "import numpy as np\n",
                "from sklearn.decomposition import PCA\n",
                "from torch.nn import functional as F\n",
                "from sklearn.manifold import TSNE\n",
                "import gc\n",
                "import itertools\n",
                "from scipy.ndimage import gaussian_filter1d\n",
                "import plotly.graph_objects as go\n",
                "from plotly.subplots import make_subplots\n",
                "import plotly.offline as pyo\n",
                "import numpy as np\n",
                "import tqdm\n",
                "from infra.utils.iterables import int_linspace\n",
                "from copy import deepcopy\n",
                "from pathlib import Path\n",
                "\n",
                "# import sys\n",
                "# del sys.modules['icl.figures.colors']\n",
                "# del sys.modules['icl.figures.notation']\n",
                "\n",
                "from devinterp.slt.forms import get_osculating_circle\n",
                "from icl.analysis.utils import get_unique_run\n",
                "from icl.constants import ANALYSIS, FIGURES, SWEEPS, DATA\n",
                "from icl.figures.notation import str_d_dlogt, str_d_dt, str_dlog_dlogt\n",
                "from icl.figures.colors import (\n",
                "    plot_transitions,\n",
                "    gen_transition_colors,\n",
                "    get_transition_type,\n",
                "    PRIMARY,\n",
                "    SECONDARY,\n",
                "    TERTIARY,\n",
                "    BRED,\n",
                "    BBLUE,\n",
                "    BRED,\n",
                "    BGREEN,\n",
                ")\n",
                "from icl.constants import DEVICE\n",
                "\n",
                "# from devinterp.slt.forms import\n",
                "sns.set_style(\"white\")\n",
                "DEVICE\n",
                "\n",
                "NUM_LAYERS = 2\n",
                "MAX_LR = 0.003\n",
                "MODEL_SEED = 0\n",
                "NUM_TASKS = list(2 ** np.arange(0, 21))\n",
                "\n",
                "steps = int_linspace(0, 500_000, 10_000)[::2]\n",
                "\n",
                "\n",
                "plt.rcParams[\"figure.dpi\"] = 300"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_models_and_optimizers(run, steps, model_id):\n",
                "    if os.path.exists(Path(\"../checkpoints\") / f\"{model_id}-models.pt\"):\n",
                "        print(\"Loading models from disk\")\n",
                "        models = torch.load(Path(\"../checkpoints\") / f\"{model_id}-models.pt\")\n",
                "        optimizer_state_dicts = torch.load(\n",
                "            Path(\"../checkpoints\") / f\"{model_id}-optimizer_state_dicts.pt\"\n",
                "        )\n",
                "\n",
                "    else:\n",
                "        print(\"Retrieving models from AWS\")\n",
                "        # Let's generate these same plots and also look at their evolution.\n",
                "        models = []\n",
                "        optimizer_state_dicts = []\n",
                "\n",
                "        for step in tqdm.tqdm(steps):\n",
                "            checkpoint = run.checkpointer.load_file(step)\n",
                "\n",
                "            m = deepcopy(run.model)\n",
                "            m.load_state_dict(checkpoint[\"model\"])\n",
                "            models.append(m)\n",
                "            optimizer_state_dicts.append(checkpoint[\"optimizer\"])\n",
                "\n",
                "        print(\"Saving models to disk\")\n",
                "        torch.save(models, Path(\"../checkpoints\") / f\"{model_id}-models.pt\")\n",
                "        torch.save(\n",
                "            optimizer_state_dicts,\n",
                "            Path(\"../checkpoints\") / f\"{model_id}-optimizer_state_dicts.pt\",\n",
                "        )\n",
                "    \n",
                "    return models, optimizer_state_dicts"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pickle\n",
                "from icl.regression.model import to_token_sequence, from_predicted_token_sequence\n",
                "\n",
                "K = 16\n",
                "B = 1024\n",
                "D = 4\n",
                "\n",
                "def get_tokens(run, batch_size, max_examples, seed=0):\n",
                "    torch.manual_seed(seed)\n",
                "\n",
                "    xs, ys = run.pretrain_dist.get_batch(max_examples, batch_size, return_ws=False)\n",
                "    tokens = to_token_sequence(xs, ys)\n",
                "    return tokens\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_outputs(models, tokens, model_id, force_reeval=False):\n",
                "    B, K, D = tokens.shape\n",
                "    K = K // 2  \n",
                "    D = D - 1 \n",
                "\n",
                "    outputs = np.zeros((len(models), K * B * (D + 1) * 2), dtype=np.float32)\n",
                "\n",
                "    if not os.path.exists(DATA / f\"{model_id}-outputs.pkl\") or force_reeval:\n",
                "        print(\"Computing outputs\")\n",
                "        for i, model in enumerate(tqdm.tqdm(models, desc=\"Computing outputs\")):\n",
                "            with torch.no_grad():\n",
                "                output = model.token_sequence_transformer(tokens).flatten()\n",
                "                outputs[i, :] = output.cpu().numpy()\n",
                "\n",
                "        with open(DATA / f\"{model_id}-outputs.pkl\", \"wb\") as f:\n",
                "            pickle.dump(outputs, f)\n",
                "    else:\n",
                "        print(\"Loading outputs from disk\")\n",
                "        with open(DATA / f\"{model_id}-outputs.pkl\", \"rb\") as f:\n",
                "            outputs = pickle.load(f)\n",
                "\n",
                "    return outputs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_pca_and_reduced(outputs, model_id, n_components=30, force_reeval=False):\n",
                "    if not os.path.exists(DATA / f\"{model_id}-pca.pkl\") or force_reeval:\n",
                "        print(\"Computing PCA\")\n",
                "        pca = PCA(n_components=n_components)\n",
                "        pca.fit(outputs)\n",
                "        reduced = pca.transform(outputs)\n",
                "        with open(DATA / f\"{model_id}-pca.pkl\", \"wb\") as f:\n",
                "            pickle.dump((pca, reduced), f)\n",
                "    else:\n",
                "        print(\"Loading PCA from disk\")\n",
                "        with open(DATA / f\"{model_id}-pca.pkl\", \"rb\") as f:\n",
                "            pca, reduced = pickle.load(f)\n",
                "    return pca, reduced"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from typing import List, TypedDict\n",
                "import yaml\n",
                "\n",
                "class FormDict(TypedDict):\n",
                "    name: str\n",
                "    components: List[float]\n",
                "\n",
                "def get_forms(model_id) -> List[FormDict]:\n",
                "    if os.path.exists(DATA / f\"{model_id}/forms.yaml\"):\n",
                "        print(\"Loading forms from disk\")\n",
                "        with open(DATA / f\"{model_id}/forms.yaml\", \"r\") as f:\n",
                "            forms = yaml.safe_load(f)\n",
                "    else:\n",
                "        print(\"Computing forms\")\n",
                "        forms = []\n",
                "        \n",
                "    return forms"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import plotly.express as px\n",
                "from sklearn.decomposition import PCA\n",
                "import seaborn as sns\n",
                "\n",
                "cmap = sns.color_palette(\"Spectral\", as_cmap=True)\n",
                "color_indices = np.linspace(0, 1, len(steps))\n",
                "colors = np.array([cmap(c) for c in color_indices])\n",
                "\n",
                "def to_color_string(color):\n",
                "    # return (256 * color[0], 256 * color[1], 256 * color[2], color[3])\n",
                "    return f\"rgb({int(256 * color[0])}, {int(256 * color[1])}, {int(256 * color[2])}, {color[3]})\"\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def plot_ed(pca, reduced, reduced_smooth, forms, model_id, form_cmap='rainbow', evolute_cmap='Spectral', num_components=3, title=\"\", slug=\"pca\", auto_open=True, tmin=0, tmax=-1,\n",
                "            save_png=False, kmeans=None):\n",
                "    labels = {\n",
                "        str(i): f\"PC {i+1} ({var:.1f}%)\"\n",
                "        for i, var in enumerate(pca.explained_variance_ratio_ * 100)\n",
                "    }\n",
                "\n",
                "    subplot_titles = []\n",
                "    fig = make_subplots(rows=num_components, cols=num_components, subplot_titles=subplot_titles)\n",
                "\n",
                "    if isinstance(form_cmap, str):\n",
                "        form_cmap = sns.color_palette(form_cmap, as_cmap=True)\n",
                "    if isinstance(evolute_cmap, str):\n",
                "        evolute_cmap = sns.color_palette(evolute_cmap, as_cmap=True)\n",
                "\n",
                "    form_colors = np.array([to_color_string(form_cmap(c)) for c in np.linspace(0, 1, len(forms))])   \n",
                "    evolute_colors = np.array([to_color_string(evolute_cmap(c)) for c in np.linspace(0, 1, len(reduced_smooth)-4)])\n",
                "\n",
                "    for i, j in tqdm.tqdm(itertools.product(range(num_components), range(num_components)), total=num_components ** 2): \n",
                "        row, col = i + 1, j + 1\n",
                "            \n",
                "        ymin, ymax = (\n",
                "            reduced[tmin:tmax, i].min(),\n",
                "            reduced[tmin:tmax, i].max(),\n",
                "        )\n",
                "        xmin, xmax = (\n",
                "            reduced[tmin:tmax, j].min(),\n",
                "            reduced[tmin:tmax, j].max(),\n",
                "        )\n",
                "\n",
                "        # Forms\n",
                "        for f, form in enumerate(forms):\n",
                "            if j < len(form['components']) and form['components'][j] is not None:\n",
                "                # Vertical line\n",
                "                fig.add_shape(\n",
                "                    type=\"line\",\n",
                "                    x0=form['components'][j],\n",
                "                    y0=ymin * 1.25,\n",
                "                    x1=form['components'][j],\n",
                "                    y1=ymax * 1.25,\n",
                "                    line=dict(color=form_colors[f], width=1),\n",
                "                    row=row,\n",
                "                    col=col,\n",
                "                )\n",
                "            if i < len(form['components']) and form['components'][i] is not None:\n",
                "                # Horizontal line\n",
                "                fig.add_shape(\n",
                "                    type=\"line\",\n",
                "                    x0=xmin * 1.25,\n",
                "                    y0=form['components'][i],\n",
                "                    x1=xmax * 1.25,\n",
                "                    y1=form['components'][i],\n",
                "                    line=dict(color=form_colors[f], width=1),\n",
                "                    row=row,\n",
                "                    col=col,\n",
                "                )\n",
                "\n",
                "        ts = np.array(range(2, len(reduced_smooth) - 2))\n",
                "        centers = np.zeros((len(ts), 2))\n",
                "\n",
                "        # Circles\n",
                "        for ti, t in enumerate(ts):\n",
                "            center, radius = get_osculating_circle(\n",
                "                reduced_smooth[:, (j, i)], t\n",
                "            )\n",
                "            # if ti % 16 == 0:\n",
                "            #     # This seems to be cheaper than directly plotting a circle\n",
                "            #     circle = go.Scatter(\n",
                "            #         x=center[0] + radius * np.cos(np.linspace(0, 2 * np.pi, 100)),\n",
                "            #         y=center[1] + radius * np.sin(np.linspace(0, 2 * np.pi, 100)),\n",
                "            #         mode=\"lines\",\n",
                "            #         line=dict(color=\"rgba(0.1, 0.1, 1, 0.05)\", width=1),\n",
                "            #         showlegend=False,\n",
                "            #     )\n",
                "            #     fig.add_trace(circle, row=row, col=col)\n",
                "\n",
                "            centers[ti] = center\n",
                "\n",
                "        # Centers\n",
                "        fig.add_trace(\n",
                "            go.Scatter(\n",
                "                x=centers[:, 0],\n",
                "                y=centers[:, 1],\n",
                "                mode=\"markers\",\n",
                "                marker=dict(size=2, symbol=\"x\", color=evolute_colors),\n",
                "                name=\"Centers\",\n",
                "            ),\n",
                "            row=row,\n",
                "            col=col,\n",
                "        )\n",
                "\n",
                "        # Original samples\n",
                "        # fig.add_trace(\n",
                "        #     go.Scatter(\n",
                "        #         x=reduced[:, j],\n",
                "        #         y=reduced[:, i],\n",
                "        #         mode=\"markers\",\n",
                "        #         marker=dict(color=colors, size=3),\n",
                "        #         showlegend=False,\n",
                "        #     ),\n",
                "        #     row=row,\n",
                "        #     col=col,\n",
                "        # )\n",
                "\n",
                "        # Smoothed trajectory\n",
                "        fig.add_trace(\n",
                "            go.Scatter(\n",
                "                x=reduced_smooth[:, j],\n",
                "                y=reduced_smooth[:, i],\n",
                "                mode=\"lines\",\n",
                "                line=dict(color=\"black\", width=2),\n",
                "                showlegend=False,\n",
                "            ),\n",
                "            row=row,\n",
                "            col=col,\n",
                "        )\n",
                "\n",
                "        if kmeans is not None:\n",
                "            fig.add_trace(\n",
                "                go.Scatter(\n",
                "                    x=kmeans.cluster_centers_[:, j],\n",
                "                    y=kmeans.cluster_centers_[:, i],\n",
                "                    mode=\"markers\",\n",
                "                    marker=dict(size=8, symbol=\"x\", color=\"black\"),\n",
                "                    showlegend=False,\n",
                "                ),\n",
                "                row=row,\n",
                "                col=col,\n",
                "            )\n",
                "\n",
                "        if j == 0:\n",
                "            fig.update_yaxes(title_text=labels[str(i)], row=row, col=col)\n",
                "\n",
                "        fig.update_xaxes(title_text=labels[str(j)], row=row, col=col)\n",
                "\n",
                "        fig.update_xaxes(\n",
                "            range=(xmin * 1.25, xmax * 1.25),\n",
                "            row=row,\n",
                "            col=col,\n",
                "        )\n",
                "        fig.update_yaxes(\n",
                "            range=(ymin * 1.25, ymax * 1.25),\n",
                "            row=row,\n",
                "            col=col,\n",
                "        )\n",
                "\n",
                "    fig.update_layout(width=2500, height=2500)  # Adjust the size as needed\n",
                "    fig.update_layout(title_text=title, showlegend=False)\n",
                "\n",
                "    # Save as html\n",
                "    pyo.plot(fig, filename=str(FIGURES / model_id / f\"{slug}.html\"), auto_open=auto_open)\n",
                "\n",
                "    if save_png:\n",
                "        fig.write_image(str(FIGURES / model_id /  f\"{slug}.png\"), scale=0.25)\n",
                "\n",
                "    return fig"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# steps\n",
                "\n",
                "from icl.analysis.smoothing import gaussian_filter1d_variable_sigma\n",
                "\n",
                "TOKENS_SEED = 0\n",
                "\n",
                "for num_tasks in NUM_TASKS[4:]:\n",
                "    model_id = f\"L2H4M{num_tasks}\"\n",
                "\n",
                "    os.makedirs(str(FIGURES / model_id), exist_ok=True)\n",
                "    os.makedirs(str(DATA / model_id), exist_ok=True)\n",
                "\n",
                "    print(\"Retrieving run...\")\n",
                "    run = get_unique_run(\n",
                "        str(SWEEPS / \"regression/training-runs/L2H4Mfin.yaml\"),\n",
                "        task_config={\n",
                "            \"num_tasks\": num_tasks,\n",
                "            \"num_layers\": NUM_LAYERS,\n",
                "            \"model_seed\": MODEL_SEED,\n",
                "        },\n",
                "        optimizer_config={\"lr\": MAX_LR},\n",
                "    )\n",
                "    print(\"Retrieved run.\")\n",
                "\n",
                "    models, optimizer_state_dicts = get_models_and_optimizers(run, steps, model_id)\n",
                "    tokens = get_tokens(run, B, K, seed=TOKENS_SEED)\n",
                "    print(f\"Tokens generated from seed {TOKENS_SEED} with shape {tokens.shape}\")\n",
                "\n",
                "    outputs = get_outputs(models, tokens, model_id, force_reeval=False)\n",
                "    pca, reduced = get_pca_and_reduced(outputs, model_id, n_components=30, force_reeval=False)\n",
                "\n",
                "    start, end = 0.1, 300\n",
                "    reduced_smooth = gaussian_filter1d_variable_sigma(reduced, np.linspace(start, end, len(reduced)), axis=0)\n",
                "\n",
                "    forms = get_forms(model_id)\n",
                "    num_forms = len(forms)\n",
                "    form_cmap = sns.color_palette(\"rainbow\", as_cmap=True)\n",
                "\n",
                "    fig = plot_ed(pca, reduced, reduced_smooth, forms, model_id, num_components=8, title=model_id)\n",
                "    "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "forms"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# steps\n",
                "\n",
                "from icl.analysis.smoothing import gaussian_filter1d_variable_sigma\n",
                "\n",
                "TOKENS_SEED = 0\n",
                "\n",
                "for num_tasks in NUM_TASKS[:1]:\n",
                "    model_id = f\"L2H4M{num_tasks}\"\n",
                "\n",
                "    print(\"Retrieving run...\")\n",
                "    # run = get_unique_run(\n",
                "    #     str(SWEEPS / \"regression/training-runs/L2H4Mfin.yaml\"),\n",
                "    #     task_config={\n",
                "    #         \"num_tasks\": num_tasks,\n",
                "    #         \"num_layers\": NUM_LAYERS,\n",
                "    #         \"model_seed\": MODEL_SEED,\n",
                "    #     },\n",
                "    #     optimizer_config={\"lr\": MAX_LR},\n",
                "    # )\n",
                "    # print(\"Retrieved run.\")\n",
                "\n",
                "    # models, optimizer_state_dicts = get_models_and_optimizers(run, steps, model_id)\n",
                "    # tokens = get_tokens(run, B, K, seed=TOKENS_SEED)\n",
                "    # print(f\"Tokens generated from seed {TOKENS_SEED} with shape {tokens.shape}\")\n",
                "\n",
                "    # outputs = get_outputs(models, tokens, model_id, force_reeval=False)\n",
                "    pca, reduced = get_pca_and_reduced(None, model_id, n_components=30, force_reeval=False)\n",
                "\n",
                "    start, end = 0.1, 300\n",
                "    reduced_smooth = gaussian_filter1d_variable_sigma(reduced, np.linspace(start, end, len(reduced)), axis=0)\n",
                "\n",
                "    forms = get_forms(model_id)\n",
                "    num_forms = len(forms)\n",
                "    form_cmap = sns.color_palette(\"rainbow\", as_cmap=True)\n",
                "\n",
                "    fig = plot_ed(pca, reduced, reduced_smooth, forms, model_id, num_components=8, title=model_id, save_png=False)\n",
                "    "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Cross-ED\n",
                "\n",
                "Now let's see what happens when we transform the data from one training run using data from another training run. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# steps\n",
                "\n",
                "from icl.analysis.smoothing import gaussian_filter1d_variable_sigma\n",
                "\n",
                "REF_SEED = 0\n",
                "TOKENS_SEED = 0\n",
                "\n",
                "# Get reference pca\n",
                "ref_model_id = f\"L2H4Minf{REF_SEED}\"\n",
                "ref_outputs = get_outputs(steps, tokens, ref_model_id, force_reeval=False)\n",
                "ref_pca, ref_reduced = get_pca_and_reduced(None, ref_model_id, n_components=30, force_reeval=False)\n",
                "\n",
                "ref_mean = np.mean(ref_outputs, axis=0)\n",
                "\n",
                "for model_seed in tqdm.tqdm(MODEL_SEEDS[3:], desc=\"Sweeping over model seeds\"):\n",
                "    model_id = f\"L2H4Minf{model_seed}\"\n",
                "\n",
                "    outputs = get_outputs(steps, tokens, model_id, force_reeval=False)\n",
                "    # outputs -= np.mean(outputs, axis=0)\n",
                "    reduced = ref_pca.transform(outputs)\n",
                "    \n",
                "    # Reevaluate explained variance on this new dataset\n",
                "    print(\"Evaluating explained variance on new dataset\")\n",
                "    total_variance_new_dataset = np.sum(np.var(outputs, axis=0))\n",
                "    explained_variances = np.var(reduced, axis=0)  # Variance of each PC in the new dataset\n",
                "    explained_variance_ratio = explained_variances / total_variance_new_dataset\n",
                "    total_explained_variance = np.sum(explained_variance_ratio)\n",
                "\n",
                "    pca.explained_variance_ = explained_variances\n",
                "    pca.explained_variance_ratio_ = explained_variance_ratio\n",
                "\n",
                "    print(\"Applying smoothing\")\n",
                "    start, end = 0.1, 300\n",
                "    reduced_smooth = gaussian_filter1d_variable_sigma(reduced, np.linspace(start, end, len(reduced)), axis=0)\n",
                "\n",
                "    fig = plot_ed(pca, reduced, reduced_smooth, [], model_id, num_components=8, title=f\"ED of {model_id} using {ref_model_id}\", slug=f\"pca-via-{ref_model_id}.html\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from icl.figures.derivatives import d_dt, d_dlogt\n",
                "\n",
                "\n",
                "def plot_pc_over_time(pca, reduced, reduced_smooth, forms, model_id, form_cmap='rainbow', evolute_cmap='Spectral', num_components=3, title=\"\", slug=\"pca-over-time\", auto_open=True, tmin=0, tmax=-1,\n",
                "            save_png=False):\n",
                "    labels = {\n",
                "        str(i): f\"PC {i+1} ({var:.1f}%)\"\n",
                "        for i, var in enumerate(pca.explained_variance_ratio_ * 100)\n",
                "    }\n",
                "\n",
                "    pc_row = 1\n",
                "    slope_row = 2\n",
                "    curvature_row = 3\n",
                "    center_row = 4\n",
                "    radius_row = 5\n",
                "\n",
                "    subplot_titles = []\n",
                "    fig = make_subplots(rows=5, cols=num_components, subplot_titles=subplot_titles)\n",
                "\n",
                "    if isinstance(form_cmap, str):\n",
                "        form_cmap = sns.color_palette(form_cmap, as_cmap=True)\n",
                "\n",
                "    form_colors = np.array([to_color_string(form_cmap(c)) for c in np.linspace(0, 1, len(forms))])   \n",
                "\n",
                "    ts = np.arange(len(reduced_smooth))\n",
                "\n",
                "    # Principal components\n",
                "    for j in tqdm.trange(num_components):\n",
                "        col = j + 1\n",
                "        # Centers\n",
                "        fig.add_trace(\n",
                "            go.Scatter(\n",
                "                x=ts,\n",
                "                y=reduced_smooth[:, j],\n",
                "                mode=\"lines\",\n",
                "                line=dict(width=1),\n",
                "                name=\"Centers\",\n",
                "            ),\n",
                "            row=1,\n",
                "            col=col,\n",
                "        )\n",
                "        \n",
                "    max_center, max_radius = -np.inf, -np.inf\n",
                "\n",
                "    # Fit osculating circles\n",
                "    for j in tqdm.trange(num_components): \n",
                "        col= j + 1\n",
                "\n",
                "        _ts = ts[2:-2]\n",
                "        centers = np.zeros((len(ts), 2))\n",
                "        radiuses = np.zeros(len(ts))\n",
                "\n",
                "        slopes = d_dlogt(ts, reduced_smooth[:, j])\n",
                "        curvatures = d_dlogt(ts[1:-1], slopes[1:-1])\n",
                "\n",
                "        fig.add_trace(\n",
                "            go.Scatter(\n",
                "                x=ts[1:-1],\n",
                "                y=slopes[1:-1],\n",
                "                mode=\"lines\",\n",
                "                line=dict(width=1),\n",
                "                name=\"Slopes\",\n",
                "            ),\n",
                "            row=slope_row,\n",
                "            col=col,\n",
                "        )\n",
                "\n",
                "        fig.add_trace(\n",
                "            go.Scatter(\n",
                "                x=ts[2:-2],\n",
                "                y=curvatures[2:-2],\n",
                "                mode=\"lines\",\n",
                "                line=dict(width=1),\n",
                "                name=\"Curvatures\",\n",
                "            ),\n",
                "            row=curvature_row,\n",
                "            col=col,\n",
                "        )\n",
                "\n",
                "        # Circles\n",
                "        for i in range(num_components):\n",
                "                \n",
                "            for ti, t in enumerate(ts):\n",
                "                center, radius = get_osculating_circle(\n",
                "                    reduced_smooth[:, (i, j)], t\n",
                "                )\n",
                "                centers[ti] = center\n",
                "                radiuses[ti] = 1/radius\n",
                "\n",
                "            # Centers\n",
                "            fig.add_trace(\n",
                "                go.Scatter(\n",
                "                    x=_ts,\n",
                "                    y=centers[:, 1],\n",
                "                    mode=\"lines\",\n",
                "                    line=dict(width=0.5),\n",
                "                    name=f\"Evolute in PC{i+1}-{j+1} plane\",\n",
                "                ),\n",
                "                row=center_row,\n",
                "                col=col,\n",
                "            )\n",
                "\n",
                "            # Radius\n",
                "            fig.add_trace(\n",
                "                go.Scatter(\n",
                "                    x=_ts,\n",
                "                    y=radiuses,\n",
                "                    mode=\"lines\",\n",
                "                    line=dict(width=0.5),\n",
                "                    name=f\"Radius of osculating circle in PC{i+1}-{j+1} plane\",\n",
                "                ),\n",
                "                row=radius_row,\n",
                "                col=col,\n",
                "            )\n",
                "\n",
                "        # Remove outliers from centers & radiuses, then compute maxima\n",
                "        normal_centers = np.where(np.abs(centers[:, 1]) < 1e3, centers[:, 1], 0)\n",
                "        normal_radiuses = np.where(np.abs(radiuses) < 1e3, radiuses, 0)\n",
                "        max_center = max(max_center, np.max(normal_centers))\n",
                "        max_radius = max(max_radius, np.max(normal_radiuses))\n",
                "\n",
                "    for j in tqdm.trange(num_components):\n",
                "        col = j + 1\n",
                "\n",
                "        max_center = reduced_smooth[:, j].max()\n",
                "        max_radius = reduced_smooth[:, j].max()\n",
                "\n",
                "        for row in range(1, 3):\n",
                "            fig.update_xaxes(\n",
                "                row=row,\n",
                "                col=col,\n",
                "                type='log'\n",
                "            )\n",
                "\n",
                "        # Update scale\n",
                "        fig.update_yaxes(\n",
                "            range=(-max_center * 1.25, max_center * 1.25),\n",
                "            row=center_row,\n",
                "            col=col,\n",
                "\n",
                "        )\n",
                "        fig.update_yaxes(\n",
                "            range=(0, max_radius * 1.25),\n",
                "            row=radius_row,\n",
                "            col=col,\n",
                "            type='log'\n",
                "        )\n",
                "\n",
                "\n",
                "        # if j == 0:\n",
                "        #     fig.update_yaxes(title_text=labels[str(i)], row=1, col=col)\n",
                "\n",
                "        # fig.update_xaxes(title_text=labels[str(j)], row=row, col=col)\n",
                "\n",
                "        # fig.update_xaxes(\n",
                "        #     range=(xmin * 1.25, xmax * 1.25),\n",
                "        #     row=row,\n",
                "        #     col=col,\n",
                "        # )\n",
                "        # fig.update_yaxes(\n",
                "        #     range=(ymin * 1.25, ymax * 1.25),\n",
                "        #     row=row,\n",
                "        #     col=col,\n",
                "        # )\n",
                "\n",
                "    fig.update_layout(width=2000, height=1500)  # Adjust the size as needed\n",
                "    fig.update_layout(title_text=title, showlegend=False)\n",
                "\n",
                "    # Save as html\n",
                "    pyo.plot(fig, filename=str(FIGURES / model_id / f\"{slug}.html\"), auto_open=auto_open)\n",
                "\n",
                "    if save_png:\n",
                "        fig.write_image(str(FIGURES / model_id /  f\"{slug}.png\"), scale=0.25)\n",
                "\n",
                "    return fig\n",
                "    \n",
                "\n",
                "plot_pc_over_time(pca, reduced, reduced_smooth, forms, model_id, num_components=8, title=model_id, tmin=0, tmax=1000, save_png=False)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.cluster import KMeans\n",
                "\n",
                "print(reduced_smooth.shape)\n",
                "\n",
                "kmeans = KMeans(n_clusters=8, random_state=0).fit(reduced_smooth)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "from sklearn.metrics import pairwise_distances\n",
                "from sklearn.cluster import KMeans\n",
                "\n",
                "class KVars(KMeans):\n",
                "    def __init__(self, n_clusters=8, max_iter=300, tol=1e-4, verbose=0, random_state=None, copy_x=True):\n",
                "        super().__init__(\n",
                "            n_clusters=n_clusters,\n",
                "            init='random',\n",
                "            max_iter=max_iter,\n",
                "            tol=tol,\n",
                "            verbose=verbose,\n",
                "            random_state=random_state,\n",
                "            copy_x=copy_x,\n",
                "            n_init=1\n",
                "        )\n",
                "    \n",
                "    def fit(self, X, sample_weight=None):\n",
                "        random_state = np.random.RandomState(self.random_state)\n",
                "\n",
                "        # Initialize centroids randomly from the dataset\n",
                "        initial_centroids = random_state.permutation(X.shape[0])[:self.n_clusters]\n",
                "        self.cluster_centers_ = X[initial_centroids]\n",
                "\n",
                "        for i in range(self.max_iter):\n",
                "            # Assign clusters based on closest centroid\n",
                "            labels = pairwise_distances_argmin_min(X, self.cluster_centers_)[0]\n",
                "\n",
                "            # Compute new centroids and the within-cluster variance\n",
                "            new_centroids = np.zeros_like(self.cluster_centers_)\n",
                "            cluster_variances = np.zeros(self.n_clusters)\n",
                "            for k in range(self.n_clusters):\n",
                "                cluster_points = X[labels == k]\n",
                "                if len(cluster_points) > 0:\n",
                "                    # Calculate the variance within the cluster\n",
                "                    cluster_variance = np.var(pairwise_distances(cluster_points, [self.cluster_centers_[k]]))\n",
                "                    cluster_variances[k] = cluster_variance\n",
                "\n",
                "                    # Update the centroid to minimize the variance (use the current centroid)\n",
                "                    # This is where you can modify the centroid update rule to minimize the variance\n",
                "                    new_centroids[k] = self.cluster_centers_[k] - (self.tol / np.sqrt(cluster_variance)) * (cluster_points - self.cluster_centers_[k]).sum(axis=0)\n",
                "\n",
                "            # Check for convergence\n",
                "            shift = np.sqrt(np.sum((new_centroids - self.cluster_centers_) ** 2, axis=1)).max()\n",
                "            if shift <= self.tol:\n",
                "                if self.verbose:\n",
                "                    print(f\"Converged at iteration {i}: center shift {shift} within tolerance {self.tol}.\")\n",
                "                break\n",
                "\n",
                "            self.cluster_centers_ = new_centroids\n",
                "\n",
                "        self.labels_ = labels\n",
                "        self.inertia_ = np.sum([cluster_variances[k] * len(X[labels == k]) for k in range(self.n_clusters)])\n",
                "        self.n_iter_ = i\n",
                "\n",
                "        return self\n",
                "    \n",
                "\n",
                "kvars = KVars(n_clusters=8, random_state=0, verbose=False).fit(reduced_smooth)\n",
                "fig = plot_ed(pca, reduced, reduced_smooth, forms, model_id, num_components=8, title=model_id, save_png=False, slug='pca-kmeans', kmeans=kvars)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig = plot_ed(pca, reduced, reduced_smooth, forms, model_id, num_components=8, title=model_id, save_png=False, slug='pca-kmeans', kmeans=kmeans)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.15"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
