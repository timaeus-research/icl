{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Essential dynamics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "from dotenv import load_dotenv\n",
                "\n",
                "load_dotenv()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "from torch import nn\n",
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import tqdm\n",
                "import seaborn as sns\n",
                "from sklearn.decomposition import PCA\n",
                "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
                "import matplotlib.patches as mpatches\n",
                "\n",
                "import matplotlib.pyplot as plt\n",
                "from mpl_toolkits.mplot3d import Axes3D\n",
                "from matplotlib.patches import FancyArrowPatch\n",
                "from mpl_toolkits.mplot3d import proj3d\n",
                "import seaborn as sns\n",
                "import numpy as np\n",
                "from sklearn.decomposition import PCA\n",
                "from torch.nn import functional as F\n",
                "from sklearn.manifold import TSNE\n",
                "import gc\n",
                "import itertools\n",
                "from scipy.ndimage import gaussian_filter1d\n",
                "import plotly.graph_objects as go\n",
                "from plotly.subplots import make_subplots\n",
                "import plotly.offline as pyo\n",
                "import numpy as np\n",
                "import tqdm\n",
                "from infra.utils.iterables import int_linspace\n",
                "from copy import deepcopy\n",
                "from pathlib import Path\n",
                "\n",
                "# import sys\n",
                "# del sys.modules['icl.figures.colors']\n",
                "# del sys.modules['icl.figures.notation']\n",
                "\n",
                "from devinterp.slt.forms import get_osculating_circle\n",
                "from icl.analysis.utils import get_unique_run\n",
                "from icl.constants import ANALYSIS, FIGURES, SWEEPS, DATA\n",
                "from icl.figures.notation import str_d_dlogt, str_d_dt, str_dlog_dlogt\n",
                "from icl.figures.colors import (\n",
                "    plot_transitions,\n",
                "    gen_transition_colors,\n",
                "    get_transition_type,\n",
                "    PRIMARY,\n",
                "    SECONDARY,\n",
                "    TERTIARY,\n",
                "    BRED,\n",
                "    BBLUE,\n",
                "    BRED,\n",
                "    BGREEN,\n",
                ")\n",
                "from icl.constants import DEVICE\n",
                "\n",
                "# from devinterp.slt.forms import\n",
                "sns.set_style(\"white\")\n",
                "DEVICE\n",
                "\n",
                "NUM_TASKS = \"inf\"\n",
                "NUM_LAYERS = 2\n",
                "MAX_LR = 0.003\n",
                "MODEL_SEEDS = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
                "\n",
                "steps = int_linspace(0, 500_000, 10_000)[::2]\n",
                "\n",
                "\n",
                "plt.rcParams[\"figure.dpi\"] = 300"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_models_and_optimizers(run, steps, model_id):\n",
                "    if os.path.exists(Path(\"../checkpoints\") / f\"{model_id}-models.pt\"):\n",
                "        print(\"Loading models from disk\")\n",
                "        models = torch.load(Path(\"../checkpoints\") / f\"{model_id}-models.pt\")\n",
                "        optimizer_state_dicts = torch.load(\n",
                "            Path(\"../checkpoints\") / f\"{model_id}-optimizer_state_dicts.pt\"\n",
                "        )\n",
                "\n",
                "    else:\n",
                "        print(\"Retrieving models from AWS\")\n",
                "        # Let's generate these same plots and also look at their evolution.\n",
                "        models = []\n",
                "        optimizer_state_dicts = []\n",
                "\n",
                "        for step in tqdm.tqdm(steps):\n",
                "            checkpoint = run.checkpointer.load_file(step)\n",
                "\n",
                "            m = deepcopy(run.model)\n",
                "            m.load_state_dict(checkpoint[\"model\"])\n",
                "            models.append(m)\n",
                "            optimizer_state_dicts.append(checkpoint[\"optimizer\"])\n",
                "\n",
                "        print(\"Saving models to disk\")\n",
                "        torch.save(models, Path(\"../checkpoints\") / f\"{model_id}-models.pt\")\n",
                "        torch.save(\n",
                "            optimizer_state_dicts,\n",
                "            Path(\"../checkpoints\") / f\"{model_id}-optimizer_state_dicts.pt\",\n",
                "        )\n",
                "    \n",
                "    return models, optimizer_state_dicts"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pickle\n",
                "from icl.regression.model import to_token_sequence, from_predicted_token_sequence\n",
                "\n",
                "K = 16\n",
                "B = 1024\n",
                "D = 4\n",
                "\n",
                "def get_data(run, batch_size, max_examples, seed=0):\n",
                "    torch.manual_seed(seed)\n",
                "\n",
                "    xs, ys = run.pretrain_dist.get_batch(max_examples, batch_size, return_ws=False)\n",
                "    return xs, ys"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_outputs(models, xs, ys, model_id, force_reeval=False):\n",
                "    B, K, D = xs.shape\n",
                "\n",
                "    outputs = np.zeros((len(models), K * B), dtype=np.float32)\n",
                "\n",
                "    if not os.path.exists(DATA / f\"{model_id}-outputs-y-only.pkl\") or force_reeval:\n",
                "        print(\"Computing outputs\")\n",
                "        for i, model in enumerate(tqdm.tqdm(models, desc=\"Computing outputs\")):\n",
                "            with torch.no_grad():\n",
                "                output = model(xs, ys).flatten()\n",
                "                outputs[i, :] = output.cpu().numpy()\n",
                "\n",
                "        with open(DATA / f\"{model_id}-outputs-y-only.pkl\", \"wb\") as f:\n",
                "            pickle.dump(outputs, f)\n",
                "    else:\n",
                "        print(\"Loading outputs from disk\")\n",
                "        with open(DATA / f\"{model_id}-outputs-y-only.pkl\", \"rb\") as f:\n",
                "            outputs = pickle.load(f)\n",
                "\n",
                "    return outputs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_pca_and_reduced(outputs, model_id, n_components=30, force_reeval=False):\n",
                "    if not os.path.exists(DATA / f\"{model_id}-pca-y-only.pkl\") or force_reeval:\n",
                "        print(\"Computing PCA\")\n",
                "        pca = PCA(n_components=n_components)\n",
                "        pca.fit(outputs)\n",
                "        reduced = pca.transform(outputs)\n",
                "        with open(DATA / f\"{model_id}-pca-y-only.pkl\", \"wb\") as f:\n",
                "            pickle.dump((pca, reduced), f)\n",
                "    else:\n",
                "        print(\"Loading PCA from disk\")\n",
                "        with open(DATA / f\"{model_id}-pca-y-only.pkl\", \"rb\") as f:\n",
                "            pca, reduced = pickle.load(f)\n",
                "    return pca, reduced"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from typing import List, TypedDict\n",
                "import yaml\n",
                "\n",
                "class FormDict(TypedDict):\n",
                "    name: str\n",
                "    components: List[float]\n",
                "\n",
                "def get_forms(model_id) -> List[FormDict]:\n",
                "    if os.path.exists(DATA / f\"{model_id}-forms-y-only.yaml\"):\n",
                "        print(\"Loading forms from disk\")\n",
                "        with open(DATA / f\"{model_id}-forms-y-only.yaml\", \"r\") as f:\n",
                "            forms = yaml.safe_load(f)\n",
                "    else:\n",
                "        print(\"Computing forms\")\n",
                "        forms = []\n",
                "        \n",
                "    return forms"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import plotly.express as px\n",
                "from sklearn.decomposition import PCA\n",
                "import seaborn as sns\n",
                "\n",
                "cmap = sns.color_palette(\"Spectral\", as_cmap=True)\n",
                "color_indices = np.linspace(0, 1, len(steps))\n",
                "colors = np.array([cmap(c) for c in color_indices])\n",
                "\n",
                "def to_color_string(color):\n",
                "    # return (256 * color[0], 256 * color[1], 256 * color[2], color[3])\n",
                "    return f\"rgb({int(256 * color[0])}, {int(256 * color[1])}, {int(256 * color[2])}, {color[3]})\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def plot_ed(pca, reduced, reduced_smooth, forms, model_id, form_cmap='rainbow', evolute_cmap='Spectral', num_components=3, title=\"\", slug=\"pca.html\"):\n",
                "    labels = {\n",
                "        str(i): f\"PC {i+1} ({var:.1f}%)\"\n",
                "        for i, var in enumerate(pca.explained_variance_ratio_ * 100)\n",
                "    }\n",
                "\n",
                "    subplot_titles = []\n",
                "    fig = make_subplots(rows=num_components, cols=num_components, subplot_titles=subplot_titles)\n",
                "\n",
                "    if isinstance(form_cmap, str):\n",
                "        form_cmap = sns.color_palette(form_cmap, as_cmap=True)\n",
                "    if isinstance(evolute_cmap, str):\n",
                "        evolute_cmap = sns.color_palette(evolute_cmap, as_cmap=True)\n",
                "\n",
                "    form_colors = np.array([to_color_string(form_cmap(c)) for c in np.linspace(0, 1, len(forms))])   \n",
                "    evolute_colors = np.array([to_color_string(evolute_cmap(c)) for c in np.linspace(0, 1, len(reduced_smooth)-4)])\n",
                "\n",
                "    for i, j in tqdm.tqdm(itertools.product(range(num_components), range(num_components)), total=num_components ** 2): \n",
                "        row, col = i + 1, j + 1\n",
                "            \n",
                "        ymin, ymax = (\n",
                "            reduced[:, i].min(),\n",
                "            reduced[:, i].max(),\n",
                "        )\n",
                "        xmin, xmax = (\n",
                "            reduced[:, j].min(),\n",
                "            reduced[:, j].max(),\n",
                "        )\n",
                "\n",
                "        # Forms\n",
                "        for f, form in enumerate(forms):\n",
                "            if form[j] is not None:\n",
                "                # Vertical line\n",
                "                fig.add_shape(\n",
                "                    type=\"line\",\n",
                "                    x0=form[j],\n",
                "                    y0=ymin * 1.25,\n",
                "                    x1=form[j],\n",
                "                    y1=ymax * 1.25,\n",
                "                    line=dict(color=form_colors[f], width=1),\n",
                "                    row=row,\n",
                "                    col=col,\n",
                "                )\n",
                "            if form[i] is not None:\n",
                "                # Horizontal line\n",
                "                fig.add_shape(\n",
                "                    type=\"line\",\n",
                "                    x0=xmin * 1.25,\n",
                "                    y0=form[i],\n",
                "                    x1=xmax * 1.25,\n",
                "                    y1=form[i],\n",
                "                    line=dict(color=form_colors[f], width=1),\n",
                "                    row=row,\n",
                "                    col=col,\n",
                "                )\n",
                "\n",
                "        ts = np.array(range(2, len(reduced_smooth) - 2))\n",
                "        centers = np.zeros((len(ts), 2))\n",
                "\n",
                "        # Circles\n",
                "        for ti, t in enumerate(ts):\n",
                "            center, radius = get_osculating_circle(\n",
                "                reduced_smooth[:, (j, i)], t\n",
                "            )\n",
                "            # if ti % 16 == 0:\n",
                "            #     # This seems to be cheaper than directly plotting a circle\n",
                "            #     circle = go.Scatter(\n",
                "            #         x=center[0] + radius * np.cos(np.linspace(0, 2 * np.pi, 100)),\n",
                "            #         y=center[1] + radius * np.sin(np.linspace(0, 2 * np.pi, 100)),\n",
                "            #         mode=\"lines\",\n",
                "            #         line=dict(color=\"rgba(0.1, 0.1, 1, 0.05)\", width=1),\n",
                "            #         showlegend=False,\n",
                "            #     )\n",
                "            #     fig.add_trace(circle, row=row, col=col)\n",
                "\n",
                "            centers[ti] = center\n",
                "\n",
                "        # Centers\n",
                "        fig.add_trace(\n",
                "            go.Scatter(\n",
                "                x=centers[:, 0],\n",
                "                y=centers[:, 1],\n",
                "                mode=\"markers\",\n",
                "                marker=dict(size=2, symbol=\"x\", color=evolute_colors),\n",
                "                name=\"Centers\",\n",
                "            ),\n",
                "            row=row,\n",
                "            col=col,\n",
                "        )\n",
                "\n",
                "        # Original samples\n",
                "        # fig.add_trace(\n",
                "        #     go.Scatter(\n",
                "        #         x=reduced[:, j],\n",
                "        #         y=reduced[:, i],\n",
                "        #         mode=\"markers\",\n",
                "        #         marker=dict(color=colors, size=3),\n",
                "        #         showlegend=False,\n",
                "        #     ),\n",
                "        #     row=row,\n",
                "        #     col=col,\n",
                "        # )\n",
                "\n",
                "        # Smoothed trajectory\n",
                "        fig.add_trace(\n",
                "            go.Scatter(\n",
                "                x=reduced_smooth[:, j],\n",
                "                y=reduced_smooth[:, i],\n",
                "                mode=\"lines\",\n",
                "                line=dict(color=\"black\", width=2),\n",
                "                showlegend=False,\n",
                "            ),\n",
                "            row=row,\n",
                "            col=col,\n",
                "        )\n",
                "\n",
                "        if j == 0:\n",
                "            fig.update_yaxes(title_text=labels[str(i)], row=row, col=col)\n",
                "\n",
                "        fig.update_xaxes(title_text=labels[str(j)], row=row, col=col)\n",
                "\n",
                "        fig.update_xaxes(\n",
                "            range=(xmin * 1.25, xmax * 1.25),\n",
                "            row=row,\n",
                "            col=col,\n",
                "        )\n",
                "        fig.update_yaxes(\n",
                "            range=(ymin * 1.25, ymax * 1.25),\n",
                "            row=row,\n",
                "            col=col,\n",
                "        )\n",
                "\n",
                "    fig.update_layout(width=2500, height=2500)  # Adjust the size as needed\n",
                "    fig.update_layout(title_text=title, showlegend=False)\n",
                "\n",
                "    # Save as png\n",
                "    fig.write_image(str(FIGURES / model_id / slug + \".png\"), )\n",
                "\n",
                "    # Save as html\n",
                "    pyo.plot(fig, filename=str(FIGURES / model_id / slug + \".html\"))\n",
                "\n",
                "    return fig"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# steps\n",
                "\n",
                "from icl.analysis.smoothing import gaussian_filter1d_variable_sigma\n",
                "\n",
                "REF_SEED = 0\n",
                "TOKENS_SEED = 0\n",
                "\n",
                "B = 2 ** 10\n",
                "K = 16\n",
                "\n",
                "# Get reference pca\n",
                "ref_model_id = f\"L2H4Minf{REF_SEED}\"\n",
                "\n",
                "print(\"Retrieving run...\")\n",
                "ref_run = get_unique_run(\n",
                "    str(SWEEPS / \"regression/training-runs/L2H4Minf.yaml\"),\n",
                "    task_config={\n",
                "        \"num_tasks\": NUM_TASKS,\n",
                "        \"num_layers\": NUM_LAYERS,\n",
                "        \"model_seed\": REF_SEED,\n",
                "    },\n",
                "    optimizer_config={\"lr\": MAX_LR},\n",
                ")\n",
                "print(\"Retrieved run.\")\n",
                "\n",
                "# Get reference pca\n",
                "xs, ys = get_data(ref_run, B, K, TOKENS_SEED)\n",
                "\n",
                "for model_seed in MODEL_SEEDS[1:3]:\n",
                "    model_id = f\"L2H4Minf{model_seed}\"\n",
                "\n",
                "    os.makedirs(str(FIGURES / model_id), exist_ok=True)\n",
                "    os.makedirs(str(DATA / model_id), exist_ok=True)\n",
                "\n",
                "    run = get_unique_run(\n",
                "        str(SWEEPS / \"regression/training-runs/L2H4Minf.yaml\"),\n",
                "        task_config={\n",
                "            \"num_tasks\": NUM_TASKS,\n",
                "            \"num_layers\": NUM_LAYERS,\n",
                "            \"model_seed\": model_seed,\n",
                "        },\n",
                "        optimizer_config={\"lr\": MAX_LR},\n",
                "    )\n",
                "\n",
                "    print(f\"Tokens generated from seed {TOKENS_SEED} with shape {xs.shape, ys.shape}\")\n",
                "\n",
                "    models, optimizer_state_dicts = get_models_and_optimizers(run, steps, model_id)\n",
                "    outputs = get_outputs(models, xs, ys, model_id, force_reeval=False)\n",
                "    pca, reduced = get_pca_and_reduced(outputs, model_id, n_components=30, force_reeval=False)\n",
                "\n",
                "    start, end = 0.1, 300\n",
                "    reduced_smooth = gaussian_filter1d_variable_sigma(reduced, np.linspace(start, end, len(reduced)), axis=0)\n",
                "\n",
                "    forms = get_forms(model_id)\n",
                "    num_forms = len(forms)\n",
                "    form_cmap = sns.color_palette(\"rainbow\", as_cmap=True)\n",
                "\n",
                "    fig = plot_ed(pca, reduced, reduced_smooth, forms, model_id, num_components=8, title=f\"ED of {model_id} (y-only)\", slug=\"pca-y-only\")\n",
                "    "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig = plot_ed(pca, reduced, reduced_smooth, forms, model_id, num_components=3, title=model_id)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Cross-ED\n",
                "\n",
                "Now let's see what happens when we transform the data from one training run using data from another training run. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# steps\n",
                "\n",
                "from icl.analysis.smoothing import gaussian_filter1d_variable_sigma\n",
                "\n",
                "REF_SEED = 0\n",
                "TOKENS_SEED = 0\n",
                "\n",
                "ref_model_id = f\"L2H4Minf{REF_SEED}\"\n",
                "xs, ys = get_data(ref_run, B, K, TOKENS_SEED) # Larger batch size (bc fewer components per sample)\n",
                "ref_outputs = get_outputs(steps, xs, ys, ref_model_id, force_reeval=False)\n",
                "ref_pca, ref_reduced = get_pca_and_reduced(None, ref_model_id, n_components=30, force_reeval=False)\n",
                "\n",
                "ref_mean = np.mean(ref_outputs, axis=0)\n",
                "\n",
                "for model_seed in tqdm.tqdm(MODEL_SEEDS, desc=\"Sweeping over model seeds\"):\n",
                "    model_id = f\"L2H4Minf{model_seed}\"\n",
                "    outputs = get_outputs(steps, xs, ys, model_id, force_reeval=False)\n",
                "    # outputs -= np.mean(outputs, axis=0)\n",
                "    reduced = ref_pca.transform(outputs)\n",
                "    \n",
                "    # Reevaluate explained variance on this new dataset\n",
                "    print(\"Evaluating explained variance on new dataset\")\n",
                "    total_variance_new_dataset = np.sum(np.var(outputs, axis=0))\n",
                "    explained_variances = np.var(reduced, axis=0)  # Variance of each PC in the new dataset\n",
                "    explained_variance_ratio = explained_variances / total_variance_new_dataset\n",
                "    total_explained_variance = np.sum(explained_variance_ratio)\n",
                "\n",
                "    pca.explained_variance_ = explained_variances\n",
                "    pca.explained_variance_ratio_ = explained_variance_ratio\n",
                "\n",
                "    print(\"Applying smoothing\")\n",
                "    start, end = 0.1, 300\n",
                "    reduced_smooth = gaussian_filter1d_variable_sigma(reduced, np.linspace(start, end, len(reduced)), axis=0)\n",
                "\n",
                "    fig = plot_ed(pca, reduced, reduced_smooth, [], model_id, num_components=8, title=f\"ED of {model_id} using {ref_model_id}\", slug=f\"pca-via-{ref_model_id}.html\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.15"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
