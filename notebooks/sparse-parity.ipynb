{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import torch\n",
    "from tqdm import tqdm, trange\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from devinterp.slt.forms import get_osculating_circle\n",
    "from skimage.measure import EllipseModel\n",
    "from icl.other.parity import MultitaskSparseParity, MLP\n",
    "import wandb\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader \n",
    "\n",
    "EVAL_BATCH_SIZE = 256\n",
    "BATCH_SIZE = 1024\n",
    "NUM_STEPS = 2_500\n",
    "DATASET_SIZE = NUM_STEPS * BATCH_SIZE\n",
    "NUM_TASKS = 8\n",
    "NUM_FEATURES = 16\n",
    "NUM_TASK_BITS = 3\n",
    "NUM_BITS = NUM_TASKS + NUM_FEATURES\n",
    "HIDDEN_DIM = 50\n",
    "ALPHA = .5\n",
    "NUM_CHECKPOINTS = 1_000\n",
    "LR=0.003\n",
    "SEED = 0\n",
    "\n",
    "log_interval=list(np.linspace(0, NUM_STEPS, NUM_CHECKPOINTS).astype(int)) \n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "dataset = MultitaskSparseParity(n=NUM_FEATURES, k=NUM_TASK_BITS, num_tasks=NUM_TASKS, alpha=ALPHA)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "# Show task probabilities\n",
    "ax.bar(range(NUM_TASKS), dataset.task_frequencies.detach().cpu().numpy())\n",
    "ax.set_title(f\"Task Probabilities ($\\\\alpha = {ALPHA}$)\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "eval_sets = [dataset.generate_batch(EVAL_BATCH_SIZE, task_idx=t) for t in trange(NUM_TASKS, desc=\"Generating eval sets\")]\n",
    "\n",
    "model = MLP(input_dim=NUM_BITS, hidden_dim=HIDDEN_DIM, output_dim=2)\n",
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "# Log on exponential scale\n",
    "\n",
    "log_wandb=True\n",
    "wandb_entity=\"devinterp\"\n",
    "wandb_project_name=\"multitask-parity\"\n",
    "models = []\n",
    "\n",
    "# Train the model\n",
    "if log_wandb:\n",
    "    wandb.init(entity=wandb_entity, project=wandb_project_name)\n",
    "    wandb.config.update({\n",
    "        \"num_features\": NUM_FEATURES,\n",
    "        \"num_tasks\": NUM_TASKS,\n",
    "        \"hidden_dim\": HIDDEN_DIM,\n",
    "        \"num_steps\": NUM_STEPS,\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"eval_batch_size\": EVAL_BATCH_SIZE,\n",
    "        \"alpha\": ALPHA,\n",
    "        \"lr\": LR,\n",
    "        \"num_checkpoints\": NUM_CHECKPOINTS,\n",
    "        \"num_task_bits\": NUM_TASK_BITS,\n",
    "        \"seed\": SEED,\n",
    "    })\n",
    "    wandb.watch(model)\n",
    "    \n",
    "\n",
    "model.to('mps')\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "def accuracy_score(labels, predictions):\n",
    "    return (labels == predictions).sum() / len(labels)\n",
    "\n",
    "def eval_model(model, eval_sets):\n",
    "    accuracies = []\n",
    "    losses = []\n",
    "\n",
    "    for task_idx, (inputs, labels) in enumerate(eval_sets):\n",
    "        inputs = inputs.to('mps')\n",
    "        labels = labels.to('mps')\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        losses.append(loss.item())\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        accuracies.append(accuracy_score(labels, predictions).item())\n",
    "\n",
    "    accuracies = np.array(accuracies)\n",
    "    losses = np.array(losses)\n",
    "    task_freqs = dataset.task_frequencies.detach().cpu().numpy()\n",
    "\n",
    "    results = {\n",
    "        \"Loss\": (losses @ task_freqs),\n",
    "        \"Accuracy\": (accuracies @ task_freqs),\n",
    "    }\n",
    "\n",
    "    for task_idx in range(NUM_TASKS):\n",
    "        results[f\"Loss/{task_idx}\"] = losses[task_idx]\n",
    "        results[f\"Accuracy/{task_idx}\"] = accuracies[task_idx]\n",
    "\n",
    "    return results\n",
    "\n",
    "def log_to_wandb(step=None):\n",
    "    with torch.no_grad():\n",
    "        results = eval_model(model, eval_sets)\n",
    "        wandb.log(results, step=step)\n",
    "\n",
    "        # task_losses = [results[f\"Loss/{task_idx}\"] for task_idx in range(NUM_TASKS)]\n",
    "        # task_accuracies = [results[f\"Accuracy/{task_idx}\"] for task_idx in range(NUM_TASKS)]\n",
    "\n",
    "        # Create a line plot for task losses\n",
    "        # loss_data = [[x, loss] for x, loss in enumerate(task_losses)]\n",
    "        # loss_table = wandb.Table(data=loss_data, columns=[\"Task\", \"Loss\"])\n",
    "        # loss_plot = wandb.plot.line(loss_table, \"Task\", \"Loss\", title=\"Task Losses\")\n",
    "\n",
    "        # # Create a line plot for task accuracies\n",
    "        # accuracy_data = [[x, accuracy] for x, accuracy in enumerate(task_accuracies)]\n",
    "        # accuracy_table = wandb.Table(data=accuracy_data, columns=[\"Task\", \"Accuracy\"])\n",
    "        # accuracy_plot = wandb.plot.line(accuracy_table, \"Task\", \"Accuracy\", title=\"Task Accuracies\")\n",
    "\n",
    "        # Log the plots\n",
    "        # wandb.log({\"Task Losses\": loss_plot, \"Task Accuracies\": accuracy_plot, **results}, step=step)\n",
    "        # loss, accuracy = results[\"Loss\"], results[\"Accuracy\"]\n",
    "        # wandb.log({\"Task Losses\": loss_plot, \"Task Accuracies\": accuracy_plot, \"Loss\": loss, \"Accuracy\": accuracy})\n",
    "\n",
    "step = 0\n",
    "log_to_wandb()\n",
    "\n",
    "for i, (inputs, labels) in enumerate(tqdm(dataloader, total=NUM_STEPS, desc=\"Training\")):\n",
    "    if step > NUM_STEPS:\n",
    "        break\n",
    "\n",
    "    inputs = inputs.to('mps')\n",
    "    labels = labels.to('mps')\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # forward + backward + optimize\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (step in log_interval) and log_wandb:\n",
    "        log_to_wandb(step=step)  \n",
    "        models.append(deepcopy(model.state_dict()))\n",
    "\n",
    "    step += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from sklearn.decomposition import PCA\n",
    "from icl.constants import FIGURES\n",
    "import plotly\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import plotly.offline as pyo\n",
    "from plotly.subplots import make_subplots\n",
    "import itertools\n",
    "from math import isnan\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "from icl.analysis.smoothing import gaussian_filter1d_variable_sigma\n",
    "\n",
    "EVAL_SEED = 42\n",
    "INIT_SMOOTHING = 0.1\n",
    "FINAL_SMOOTHING = 30\n",
    "# EVAL_SEED = 42\n",
    "torch.manual_seed(EVAL_SEED)\n",
    "\n",
    "ed_outputs = []\n",
    "eval_inputs = torch.cat([x for x, _ in eval_sets], dim=0).to('mps')\n",
    "eval_labels = torch.cat([y for _, y in eval_sets], dim=0).to('mps')\n",
    "\n",
    "print(eval_inputs.shape, eval_labels.shape)\n",
    "\n",
    "losses = []\n",
    "\n",
    "eval_criterion = nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "for state_dict in tqdm(models, desc=\"Evaluating models\"):\n",
    "    model.load_state_dict(state_dict)\n",
    "    preds = model(eval_inputs)\n",
    "    loss = eval_criterion(preds, eval_labels)\n",
    "    losses.append(loss.mean().item())\n",
    "    ed_outputs.append(loss.cpu().detach().numpy().flatten())\n",
    "    # ed_outputs.append(preds.cpu().detach().numpy().flatten())\n",
    "\n",
    "ed_outputs_np = np.stack(ed_outputs)\n",
    "\n",
    "NUM_COMPONENTS = 5\n",
    "pca = PCA(n_components=NUM_COMPONENTS)\n",
    "\n",
    "ed_projections = pca.fit_transform(ed_outputs_np)\n",
    "ed_projections_smooth = gaussian_filter1d_variable_sigma(ed_projections, sigma=np.linspace(INIT_SMOOTHING, FINAL_SMOOTHING, ed_projections.shape[0]), axis=0)\n",
    "\n",
    "print(pca.explained_variance_ratio_)\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "fig = make_subplots(rows=1, cols=1+NUM_COMPONENTS, subplot_titles=[\"Loss\"] + [f\"Component {i} ({pca.explained_variance_ratio_[i-1]:.2f})\" for i in range(1, NUM_COMPONENTS+1)])\n",
    "\n",
    "fig.add_trace(go.Scatter(x=log_interval, y=losses, mode=\"lines\", name=\"Loss\", showlegend=False), row=1, col=1)\n",
    "\n",
    "for i in range(1, NUM_COMPONENTS+1):\n",
    "    fig.add_trace(go.Scatter(x=log_interval, y=ed_projections[:, i-1], mode=\"markers\", marker=dict(color='black', opacity=0.1), name=f\"Component {i}\", showlegend=False), row=1, col=i+1)\n",
    "    fig.add_trace(go.Scatter(x=log_interval, y=ed_projections_smooth[:, i-1], mode=\"lines\", line=dict(color='red', width=4), name=f\"Component {i} (Smooth)\", showlegend=False), row=1, col=i+1)\n",
    "    fig.update_xaxes(title_text=\"Step\", row=1, col=i+1)\n",
    "\n",
    "fig.update_layout(height=500, width=2000, title_text=\"PCA Components\")\n",
    "fig.show()\n",
    "\n",
    "wandb.log({\"PCA/Components\": fig}, step=step, commit=True)\n",
    "\n",
    "# fig, axes = plt.subplots(1, 1+NUM_COMPONENTS, figsize=(20, 5))\n",
    "\n",
    "# axes[0].plot(losses)\n",
    "# axes[0].set_title(\"Loss\")\n",
    "# axes[0].set_xlabel(\"Step\")\n",
    "\n",
    "# for i in range(1, NUM_COMPONENTS+1):\n",
    "#     axes[i].scatter(range(ed_projections.shape[0]), ed_projections[:, i-1], color='k', alpha=0.1)\n",
    "#     axes[i].plot(ed_projections_smooth[:, i-1], color='r', lw=4)\n",
    "#     axes[i].set_title(f\"Component {i} ({pca.explained_variance_ratio_[i-1]:.2f})\")\n",
    "#     axes[i].set_xlabel(\"Step\")\n",
    "\n",
    "# plt.tight_layout()\n",
    "# wandb.log({\"PCA/Components\": fig}, step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_references = []\n",
    "\n",
    "for t in range(NUM_TASKS):\n",
    "    task_reference = np.ones(EVAL_BATCH_SIZE * NUM_TASKS) * -np.log(0.5)\n",
    "    task_reference[0:(t+1)* EVAL_BATCH_SIZE] = 0\n",
    "    task_references.append(task_reference)\n",
    "    \n",
    "task_references = np.stack(task_references)\n",
    "task_references_reduced = pca.transform(task_references)\n",
    "task_references.shape, task_references_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "form_potentials = np.zeros((NUM_TASKS, len(log_interval)))\n",
    "\n",
    "for t in range(NUM_TASKS):\n",
    "    form_potentials[t, :] = np.sum((ed_outputs_np - task_references[t, :]) ** 2, axis=1)\n",
    "\n",
    "fig = make_subplots(rows=1, cols=NUM_TASKS, subplot_titles=[f\"Task {i}\" for i in range(1, NUM_TASKS+1)])\n",
    "\n",
    "for i in range(NUM_TASKS):\n",
    "    fig.add_trace(go.Scatter(x=log_interval, y=form_potentials[i], mode=\"lines\", name=f\"Task {i+1}\", showlegend=False), row=1, col=i+1)\n",
    "\n",
    "fig.update_layout(height=500, width=2000, title_text=\"Form Potentials\")\n",
    "fig.show()\n",
    "\n",
    "wandb.log({\"PCA/Form Potentials\": fig}, commit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_color_string(color):\n",
    "    # return (256 * color[0], 256 * color[1], 256 * color[2], color[3])\n",
    "    return f\"rgb({int(256 * color[0])}, {int(256 * color[1])}, {int(256 * color[2])}, {color[3]})\"\n",
    "\n",
    "\n",
    "def plot_ed(pca, reduced, reduced_smooth, task_references, model_id, form_cmap='rainbow', evolute_cmap='Spectral', num_components=3, title=\"\", slug=\"pca.html\"):\n",
    "    labels = {\n",
    "        str(i): f\"PC {i+1} ({var:.1f}%)\"\n",
    "        for i, var in enumerate(pca.explained_variance_ratio_ * 100)\n",
    "    }\n",
    "\n",
    "    subplot_titles = []\n",
    "    fig = make_subplots(rows=num_components, cols=num_components, subplot_titles=subplot_titles)\n",
    "\n",
    "    if isinstance(form_cmap, str):\n",
    "        form_cmap = sns.color_palette(form_cmap, as_cmap=True)\n",
    "    if isinstance(evolute_cmap, str):\n",
    "        evolute_cmap = sns.color_palette(evolute_cmap, as_cmap=True)\n",
    "\n",
    "    colors = np.array([to_color_string(form_cmap(c)) for c in np.linspace(0, 1, reduced.shape[0])])   \n",
    "    evolute_colors = np.array([to_color_string(evolute_cmap(c)) for c in np.linspace(0, 1, len(reduced_smooth)-4)])\n",
    "\n",
    "    for i, j in tqdm(itertools.product(range(num_components), range(num_components)), total=num_components ** 2): \n",
    "        row, col = i + 1, j + 1\n",
    "            \n",
    "        ymin, ymax = (\n",
    "            reduced[:, i].min(),\n",
    "            reduced[:, i].max(),\n",
    "        )\n",
    "        xmin, xmax = (\n",
    "            reduced[:, j].min(),\n",
    "            reduced[:, j].max(),\n",
    "        )\n",
    "\n",
    "\n",
    "        ts = np.array(range(2, len(reduced_smooth) - 2))\n",
    "        centers = np.zeros((len(ts), 2))\n",
    "\n",
    "        # Circles\n",
    "        for ti, t in enumerate(ts):\n",
    "            center, radius = get_osculating_circle(\n",
    "                reduced_smooth[:, (j, i)], t\n",
    "            )\n",
    "            if ti % 3 == 0:\n",
    "                # This seems to be cheaper than directly plotting a circle\n",
    "                circle = go.Scatter(\n",
    "                    x=center[0] + radius * np.cos(np.linspace(0, 2 * np.pi, 100)),\n",
    "                    y=center[1] + radius * np.sin(np.linspace(0, 2 * np.pi, 100)),\n",
    "                    mode=\"lines\",\n",
    "                    line=dict(color=\"rgba(0.1, 0.1, 1, 0.05)\", width=1),\n",
    "                    showlegend=False,\n",
    "                )\n",
    "                fig.add_trace(circle, row=row, col=col)\n",
    "\n",
    "            centers[ti] = center\n",
    "\n",
    "        # Centers\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=centers[:, 0],\n",
    "                y=centers[:, 1],\n",
    "                mode=\"markers\",\n",
    "                marker=dict(size=4, symbol=\"x\", color=evolute_colors),\n",
    "                name=\"Centers\",\n",
    "            ),\n",
    "            row=row,\n",
    "            col=col,\n",
    "        )\n",
    "\n",
    "        # Original samples\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=reduced[:, j],\n",
    "                y=reduced[:, i],\n",
    "                mode=\"markers\",\n",
    "                marker=dict(color=colors, size=3),\n",
    "                showlegend=False,\n",
    "            ),\n",
    "            row=row,\n",
    "            col=col,\n",
    "        )\n",
    "\n",
    "        # Smoothed trajectory\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=reduced_smooth[:, j],\n",
    "                y=reduced_smooth[:, i],\n",
    "                mode=\"lines\",\n",
    "                line=dict(color=\"black\", width=2),\n",
    "                showlegend=False,\n",
    "            ),\n",
    "            row=row,\n",
    "            col=col,\n",
    "        )\n",
    "\n",
    "        # Task references\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=task_references_reduced[:, j],\n",
    "                y=task_references_reduced[:, i],\n",
    "                mode=\"markers\",\n",
    "                marker=dict(color=\"rgba(0, 0, 0, 1)\", size=10),\n",
    "                showlegend=False,\n",
    "            ),\n",
    "            row=row,\n",
    "            col=col,\n",
    "        )\n",
    "\n",
    "        if j == 0:\n",
    "            fig.update_yaxes(title_text=labels[str(i)], row=row, col=col)\n",
    "\n",
    "        fig.update_xaxes(title_text=labels[str(j)], row=row, col=col)\n",
    "\n",
    "        fig.update_xaxes(\n",
    "            range=(xmin * 1.25, xmax * 1.25),\n",
    "            row=row,\n",
    "            col=col,\n",
    "        )\n",
    "        fig.update_yaxes(\n",
    "            range=(ymin * 1.25, ymax * 1.25),\n",
    "            row=row,\n",
    "            col=col,\n",
    "        )\n",
    "\n",
    "    fig.update_layout(width=2000, height=2000)  # Adjust the size as needed\n",
    "    fig.update_layout(title_text=title, showlegend=False)\n",
    "\n",
    "    # Save as html\n",
    "    pyo.plot(fig, filename=str(FIGURES / model_id / f\"{slug}.html\"), auto_open=False)\n",
    "    fig.write_image(str(FIGURES / model_id / f\"{slug}.png\"))\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "if not (FIGURES / \"multitask-parity\").exists():\n",
    "    (FIGURES / \"multitask-parity\").mkdir(parents=True)\n",
    "\n",
    "fig = plot_ed(pca, ed_projections, ed_projections_smooth, task_references, \"multitask-parity\", title=\"Multitask Parity PCA\", slug=\"pca\", num_components=5)\n",
    "\n",
    "# table = wandb.Table(columns=[\"figure\"])\n",
    "# table.add_data(wandb.Html(str(FIGURES / \"multitask-parity\" / \"pca.html\")))\n",
    "# wandb.log({\"PCA/Essential Dynamics\": table}, commit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
