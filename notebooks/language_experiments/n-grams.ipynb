{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "from copy import deepcopy\n",
    "from transformer_lens import HookedTransformer\n",
    "from transformer_lens import HookedTransformerConfig\n",
    "from transformer_lens.utils import lm_cross_entropy_loss\n",
    "from transformer_lens.utils import tokenize_and_concatenate\n",
    "\n",
    "from transformer_lens import HookedTransformerConfig, HookedTransformer\n",
    "\n",
    "DEVICE = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from icl.language.model import get_model_cfg\n",
    "from icl.language.utils import load_hf_checkpoint\n",
    "\n",
    "model_cfgs = {}\n",
    "model_cfgs[1] = get_model_cfg(num_layers=1)\n",
    "model_cfgs[2] = get_model_cfg(num_layers=2)\n",
    "\n",
    "model = HookedTransformer(model_cfgs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# small tokenizer\n",
    "tokenizer_tiny = model.tokenizer\n",
    "\n",
    "# big tokenizer\n",
    "model_cfg_big = HookedTransformerConfig(\n",
    "    n_layers=2,\n",
    "    d_model=256,\n",
    "    d_head=32,\n",
    "    n_heads=8,\n",
    "    n_ctx=1024,\n",
    "    tokenizer_name='oknMswoztTPaAVreBrWy/GPT2-tokenizer',\n",
    "    normalization_type='LN',\n",
    "    attn_only=True,\n",
    "    seed=1,\n",
    "    positional_embedding_type='shortformer',\n",
    ")\n",
    "model_big = HookedTransformer(model_cfg_big)\n",
    "tokenizer_big = model_big.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_int_to_str(token_int):\n",
    "    t = torch.tensor([[token_int]], device=DEVICE)\n",
    "    return model.to_str_tokens(t)\n",
    "\n",
    "def translate_int_to_str_big(token_int):\n",
    "    t = torch.tensor([[token_int]], device=DEVICE)\n",
    "    return model_big.to_str_tokens(t)\n",
    "\n",
    "big_vocab = {}\n",
    "# get plaintext vocabs\n",
    "for i in tqdm(range(len(tokenizer_big.vocab))):\n",
    "  token = translate_int_to_str_big(i)\n",
    "  big_vocab[i] = token[0]\n",
    "  big_vocab[token[0]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "d_vocab_long = 50257\n",
    "\n",
    "# tokenize big vocab list\n",
    "tokenized_vocab = {}\n",
    "length_counter = defaultdict(int)\n",
    "\n",
    "for i in tqdm(range(d_vocab_long)):\n",
    "  token = big_vocab[i]\n",
    "  tokenized = tokenizer_tiny(token)\n",
    "  tokenized = tokenized['input_ids']\n",
    "  tokenized_vocab[i] = tokenized\n",
    "  length_counter[len(tokenized)] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_grams(n=2, max_vocab=None, exclude_spaces=True, add_bos_token=False):\n",
    "  output = []\n",
    "  for i in range(d_vocab_long):\n",
    "    if max_vocab and i == max_vocab - 1:\n",
    "      break\n",
    "    tokenized = tokenized_vocab[i]\n",
    "    if len(tokenized) == n:\n",
    "      if exclude_spaces and 220 in tokenized:\n",
    "        continue\n",
    "      if add_bos_token:\n",
    "        tokenized = [4999] + tokenized\n",
    "      output.append((big_vocab[i], tokenized))\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_grams = n_grams(n=2, add_bos_token=True)\n",
    "three_grams = n_grams(n=3, add_bos_token=True)\n",
    "four_grams = n_grams(n=4, add_bos_token=True)\n",
    "len(three_grams)\n",
    "three_grams[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_gram_loss(model, n_grams, max_n_grams=1000):\n",
    "  losses = []\n",
    "  for n_gram in tqdm(n_grams[:max_n_grams]):\n",
    "    tokens = n_gram[1]\n",
    "    t = torch.tensor([tokens], device=model.cfg.device)\n",
    "    logits = model(t).detach()\n",
    "    loss = lm_cross_entropy_loss(logits, t, per_token=True)\n",
    "    losses.append(loss[0][-1].cpu().item())\n",
    "  return np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "x_steps = list(range(0, 50001, 100))\n",
    "losses = defaultdict(list)\n",
    "loss_pairs = []\n",
    "for n in range(2, 5):\n",
    "  for layer in range(1, 3):\n",
    "    loss_pairs.append((n, layer))\n",
    "\n",
    "all_grams = {}\n",
    "all_grams[2] = two_grams\n",
    "all_grams[3] = three_grams\n",
    "all_grams[4] = four_grams\n",
    "\n",
    "for step in x_steps:\n",
    "  print(step)\n",
    "  model = load_hf_checkpoint(step)\n",
    "  for n in range(2, 5):\n",
    "    for layer in range(1, 3):\n",
    "      model = load_hf_checkpoint(step, n_layers=layer)\n",
    "      grams = all_grams[n]\n",
    "      losses[(n, layer)].append(np.mean(n_gram_loss(model, grams)))\n",
    "\n",
    "# one layer and two layer versions were originally run separately, \n",
    "# so either save this as both L1-n-grams.pkl and L2-n-grams.pkl or \n",
    "# update the imports for figure generation"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
