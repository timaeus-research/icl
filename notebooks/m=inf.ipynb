{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $M\\to\\infty$ Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.patches import FancyArrowPatch\n",
    "from mpl_toolkits.mplot3d import proj3d\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from torch.nn import functional as F\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# import sys\n",
    "# del sys.modules['icl.figures.colors']\n",
    "# del sys.modules['icl.figures.notation']\n",
    "\n",
    "from icl.analysis.utils import get_unique_run\n",
    "from icl.constants import ANALYSIS, FIGURES, SWEEPS\n",
    "from icl.figures.notation import str_d_dlogt, str_d_dt, str_dlog_dlogt\n",
    "from icl.figures.colors import plot_transitions, gen_transition_colors, get_transition_type, PRIMARY, SECONDARY, TERTIARY, BRED, BBLUE, BRED, BGREEN\n",
    "from icl.constants import DEVICE\n",
    "\n",
    "MODEL_ID = \"L2H4Minf\"\n",
    "LLC_RUN_ID = \"zk7pqalk\"  # TODO: Placeholder from m=20\n",
    "\n",
    "sns.set_style('white')\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TASKS = 2 ** 20  # TODO: Placeholder\n",
    "NUM_LAYERS = 2\n",
    "MAX_LR = 0.01\n",
    "\n",
    "# shorthands\n",
    "BATCH_SIZE = 8192\n",
    "K = 8\n",
    "D = 4\n",
    "\n",
    "run = get_unique_run(\n",
    "    str(SWEEPS / \"training-runs/small-L-2.yaml\"), \n",
    "    task_config={\"num_tasks\": NUM_TASKS, \"num_layers\": NUM_LAYERS},\n",
    "    optimizer_config={\"lr\": MAX_LR}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy \n",
    "# Let's generate these same plots and also look at their evolution. \n",
    "models = []\n",
    "optimizer_state_dicts = []\n",
    "\n",
    "steps = run.checkpointer.file_ids\n",
    "\n",
    "for checkpoint in tqdm.tqdm(run.checkpointer):\n",
    "    m = deepcopy(run.model)\n",
    "    m.load_state_dict(checkpoint[\"model\"])\n",
    "    models.append(m)\n",
    "    optimizer_state_dicts.append(checkpoint[\"optimizer\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at how the curvature of the llc changes over time. \n",
    "\n",
    "import wandb\n",
    "\n",
    "api = wandb.Api()\n",
    "llc_run = api.run(f\"devinterp/icl/{LLC_RUN_ID}\")\n",
    "history_df = llc_run.history()\n",
    "\n",
    "llc_mean_columns = [f'llc/mean/{i}' for i in range(8)]\n",
    "history_df[llc_mean_columns] = history_df[llc_mean_columns].replace(\"NaN\", np.nan)\n",
    "\n",
    "llc_std_columns = [f'llc/std/{i}' for i in range(8)]\n",
    "history_df[llc_std_columns] = history_df[llc_std_columns].replace(\"NaN\", np.nan)\n",
    "\n",
    "# Calculate the average of non-NaN values in llc-chain columns\n",
    "# and the fraction of NaN values\n",
    "llc_chain_values = history_df[llc_mean_columns]\n",
    "mean_llc_chain = llc_chain_values.mean(axis=1, skipna=True)\n",
    "mean_std_llc_chain = history_df[llc_std_columns].mean(axis=1, skipna=True)\n",
    "frac_nan = llc_chain_values.isna().mean(axis=1)\n",
    "\n",
    "history_df[\"llc/mean\"] = mean_llc_chain\n",
    "history_df[\"llc/std\"] = mean_std_llc_chain\n",
    "history_df[\"llc/frac-nan\"] = frac_nan\n",
    "history_df[\"log_num_tasks\"] = 20\n",
    "\n",
    "\n",
    "# history_df[[\"llc/mean\", \"llc/std\"]] = history_df[[\"llc/mean\", \"llc/std\"]].replace(\"NaN\", np.nan)\n",
    "\n",
    "llc_steps = history_df[\"_step\"]\n",
    "llcs = history_df[\"llc/mean\"]\n",
    "llcs_std = history_df[\"llc/std\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from icl.figures.derivatives import d_dt, d_dlogt, dlog_dlogt\n",
    "\n",
    "weight_norms = [(sum(torch.norm(p) ** 2 for p in model.parameters()) ** 0.5).item() for model in models]\n",
    "\n",
    "d_llc_dt = d_dt(steps, llcs)\n",
    "d_llc_dlogt = d_dlogt(steps, llcs)\n",
    "\n",
    "d_weight_norm_dt = d_dt(run.checkpointer.file_ids, weight_norms)\n",
    "d_weight_norm_dlogt = d_dlogt(run.checkpointer.file_ids, weight_norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from icl.analysis.evals import ICLEvaluator\n",
    "\n",
    "FORCE_REEVAL = False\n",
    "\n",
    "evaluator = ICLEvaluator(\n",
    "    pretrain_dist=run.pretrain_dist,\n",
    "    true_dist=run.true_dist,\n",
    "    max_examples=run.config.task_config.max_examples,\n",
    "    eval_batch_size=BATCH_SIZE,\n",
    "    seed=run.config.task_config.true_seed,   \n",
    ")\n",
    "\n",
    "if os.path.exists(ANALYSIS / f\"{MODEL_ID}_evals_over_time.csv\") and not FORCE_REEVAL:\n",
    "    evals_over_time_df = pd.read_csv(ANALYSIS / f\"{MODEL_ID}_evals_over_time.csv\")\n",
    "    evals_over_time = evals_over_time_df.to_dict(\"records\")\n",
    "else:\n",
    "    evals_over_time = [evaluator(model) for model in models]\n",
    "    evals_over_time_df = pd.DataFrame(evals_over_time)\n",
    "    evals_over_time_df.to_csv(ANALYSIS / f\"{MODEL_ID}_evals_over_time.csv\")\n",
    "\n",
    "evals_over_time_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evals_over_time_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import colorsys\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "\n",
    "# TRANSITIONS = [\n",
    "#     (30, 1200, 'A1'),\n",
    "#     (1200, 12500, 'A2'),\n",
    "#     (12500, 60000, 'B1'),\n",
    "#     (60000, 110000, 'B2'),\n",
    "#     (110000, 180000, 'B3'),\n",
    "#     (180000, 280000, \"B4\"),\n",
    "#     (280000, 320000, \"B5\"),\n",
    "#     (320000, 500000, \"B6\")\n",
    "# ]\n",
    "\n",
    "\n",
    "TRANSITIONS = [\n",
    "    # PCA-based\n",
    "    # (0, 600, 'A1a'),\n",
    "    # (600, 2000, 'A1b'),\n",
    "    # (2000, 3000, 'A2a'),\n",
    "    # (3000, 15000, 'A2b'),\n",
    "    # (15000, 28000, 'B1a'),\n",
    "    # (28000, 60000, 'B1b'),\n",
    "    # (60000, 140000, 'B2a'),\n",
    "    # (140000, 500000, 'B2b'),\n",
    "    # LLC-based\n",
    "    (0, 600, 'A1a'),\n",
    "    (600, 1200, 'A1b'),\n",
    "    (1200, 4000, 'A2a'),\n",
    "    (4000, 15000, 'A2b'),\n",
    "    (15000, 28000, 'B1a'),\n",
    "    (28000, 60000, 'B1b'),\n",
    "    (60000, 120000, 'B2a'),\n",
    "    (120000, 500000, 'B2b'),\n",
    "    # (110000, 180000, 'B3'),\n",
    "    # (180000, 280000, \"B4\"),\n",
    "    # (280000, 320000, \"B5\"),\n",
    "    # (320000, 500000, \"B6\")\n",
    "]\n",
    "\n",
    "# def gen_transition_colors(types):\n",
    "#     \"\"\"Generates a palette for transition colors. Orange-flavored for Type A. Blue-flavored for Type B.\"\"\"\n",
    "#     num_type_a = sum([t == \"A\" for t in types])\n",
    "#     num_type_b = sum([t == \"B\" for t in types])\n",
    "#     num_other = sum([t == \"Other\" for t in types])\n",
    "\n",
    "#     type_a_palette = sns.color_palette(\"Oranges_r\", num_type_a)\n",
    "#     type_b_palette = sns.color_palette(\"Blues_r\", num_type_b)\n",
    "#     other_palette = sns.color_palette(\"Greys_r\", num_other)\n",
    "\n",
    "#     palette = []\n",
    "\n",
    "#     for t in types:\n",
    "#         if t == \"A\":\n",
    "#             palette.append(type_a_palette.pop())\n",
    "#         elif t == \"B\":\n",
    "#             palette.append(type_b_palette.pop())\n",
    "#         else:\n",
    "#             palette.append(other_palette.pop())\n",
    "\n",
    "#     return palette\n",
    "\n",
    "\n",
    "def increase_saturation(rgb, saturation_factor):\n",
    "    # Convert RGB to HSV\n",
    "    hsv = colorsys.rgb_to_hsv(*rgb)\n",
    "    \n",
    "    # Increase saturation by the given factor, making sure it stays in [0, 1]\n",
    "    new_s = min(max(hsv[1] * saturation_factor, 0), 1)\n",
    "    \n",
    "    # Convert back to RGB\n",
    "    new_rgb = colorsys.hsv_to_rgb(hsv[0], new_s, hsv[2])\n",
    "    return new_rgb\n",
    "\n",
    "\n",
    "def increase_contrast(rgb, contrast_factor):\n",
    "    # Midpoint\n",
    "    midpoint = 128.0 / 255\n",
    "    \n",
    "    # Increase contrast\n",
    "    new_rgb = [(0.5 + contrast_factor * (component - 0.5)) for component in rgb]\n",
    "    \n",
    "    # Clip to the range [0, 1]\n",
    "    new_rgb = [min(max(component, 0), 1) for component in new_rgb]\n",
    "    return new_rgb\n",
    "\n",
    "\n",
    "\n",
    "transition_types = [get_transition_type(t) for t in TRANSITIONS]\n",
    "transition_colors = gen_transition_colors(transition_types)\n",
    "\n",
    "transition_colors = [increase_saturation(rgb, 2) for rgb in transition_colors]\n",
    "transition_colors = [increase_contrast(rgb, 2) for rgb in transition_colors]\n",
    "\n",
    "transitions_cmap = LinearSegmentedColormap.from_list(\"transitions\", transition_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_to_plot = [\n",
    "    (r\"L_{\\mathcal{T}}(t)\", evals_over_time_df[\"pretrain/mse_subsequence\"], {\"logy\": True}, ),\n",
    "    # (r\"L_\\mathcal{G}(t)\", evals_over_time_df[\"true/mse\"], {\"logy\": False}),\n",
    "    (r\"\\hat \\lambda(t)\", llcs, {}),\n",
    "    (r\"|\\theta(t)|\", weight_norms, {\"derivative\": \"dlog_dlogt\", \"logy\": True}),\n",
    "] \n",
    "\n",
    "fig, axes = plt.subplots(2, len(metrics_to_plot), figsize=(12, 6))\n",
    "\n",
    "axes = axes.reshape(2, len(metrics_to_plot))\n",
    "\n",
    "for i, (metric_name, metric_values, kwargs) in enumerate(metrics_to_plot):\n",
    "    axes[0, i].plot(run.checkpointer.file_ids, metric_values, label=metric_name, marker='.')\n",
    "    axes[0, i].set_title(f\"${metric_name}$\")\n",
    "    axes[0, i].set_xlabel('Step, $t$')\n",
    "    axes[0, i].set_ylabel(metric_name)\n",
    "\n",
    "    if kwargs.get(\"logy\", False):\n",
    "        axes[0, i].set_yscale('log')\n",
    "\n",
    "    slope_type = kwargs.get(\"derivative\", \"d_dlogt\")\n",
    "\n",
    "    if slope_type == \"d_dlogt\":\n",
    "        slope = d_dlogt(run.checkpointer.file_ids, metric_values)\n",
    "        slope_name = str_d_dlogt(metric_name)\n",
    "    elif slope_type == \"d_dt\":\n",
    "        slope = d_dt(run.checkpointer.file_ids, metric_values)\n",
    "        slope_name = str_d_dt(metric_name)\n",
    "    elif slope_type == \"dlog_dlogt\":\n",
    "        slope = dlog_dlogt(run.checkpointer.file_ids, metric_values)\n",
    "        slope_name = str_dlog_dlogt(metric_name)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown slope type {slope_type}\")\n",
    "\n",
    "    axes[1, i].axhline(0, linestyle='--', color='gray')\n",
    "    axes[1, i].plot(run.checkpointer.file_ids, slope, label=metric_name + \" Slope\", marker='.')\n",
    "    axes[1, i].set_title(slope_name)\n",
    "    axes[1, i].set_xlabel('Step, $t$')\n",
    "    axes[1, i].set_ylabel(slope_name)\n",
    "\n",
    "for ax in axes.flatten():\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xlim(30, 500_000)\n",
    "\n",
    "\n",
    "# axes[0, 1].set_ylim(0, 100)\n",
    "# axes[1, 1].set_ylim(0, 200)\n",
    "# axes[1,1].set_ylim(-2, 2)\n",
    "\n",
    "patch_list = plot_transitions(axes, TRANSITIONS, limit=True)\n",
    "\n",
    "axes[1, 1].set_yscale('symlog')\n",
    "# axes[1,0].set_yscale('symlog')\n",
    "# axes[0,0].set_ylim(0, 70)\n",
    "\n",
    "milestone_labels = [label for _, _, label in TRANSITIONS]\n",
    "fig.legend(patch_list, milestone_labels, loc='upper center', bbox_to_anchor=(0.5, -0.025), ncol=len(TRANSITIONS))\n",
    "\n",
    "fig.set_facecolor(\"white\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Behavioral Indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss, Prediction Norm, OOD Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait if my layer norm theory is right. Then we should see a sudden improvement in the ability of the model to make predictions for out-of-distribution xs/ys (not ws). \n",
    "from devinfra.utils.seed import set_seed\n",
    "from icl.tasks import apply_transformations\n",
    "from devinfra.utils.iterables import flatten_dict\n",
    "\n",
    "pretrain_dist_noiseless = run.config.task_config.pretrain_dist_factory().to(\n",
    "    DEVICE\n",
    ")\n",
    "pretrain_dist_noiseless.std = 0.\n",
    "\n",
    "set_seed(run.config.task_config.pretrain_seed)\n",
    "\n",
    "\n",
    "# sample a batch of random tasks\n",
    "ws = pretrain_dist_noiseless.task_distribution.sample_tasks(BATCH_SIZE) # -> B D\n",
    "\n",
    "# sample i.i.d. inputs and outputs for each task according to the\n",
    "# regression model\n",
    "xs = torch.normal(\n",
    "    mean=0.,\n",
    "    std=1.,\n",
    "    size=(BATCH_SIZE, K, D,),\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "OOD_MULTIPLIER = 3\n",
    "\n",
    "ood_xs = 3 * xs\n",
    "ys = apply_transformations(ws, xs, 0.125, DEVICE)\n",
    "ood_ys = apply_transformations(ws, ood_xs, 0.125, DEVICE)\n",
    "\n",
    "def eval_loss(yhats, ys):\n",
    "    losses = ((yhats - ys) ** 2).mean(dim=0)[:, 0]\n",
    "    return [loss.item() for loss in losses] + [losses.mean().item()]\n",
    "\n",
    "losses_over_time = []\n",
    "\n",
    "for step, model in zip(run.checkpointer.file_ids, models):\n",
    "    losses = eval_loss(model(xs, ys), ys)\n",
    "    ood_losses = eval_loss(model(ood_xs, ood_ys), ood_ys)\n",
    "    losses_0s = eval_loss(model(xs, ys), torch.zeros_like(ys))\n",
    "\n",
    "    for i in range(9):\n",
    "        losses_over_time.append({\n",
    "            \"step\": step,\n",
    "            \"loss\": losses[i],\n",
    "            \"ood_loss\": ood_losses[i],\n",
    "            \"loss_0\": losses_0s[i],\n",
    "            # \"token\": f\"$\\hat y_{i+1}$\" if i < 8 else \"$\\overline{\\hat y}$\"\n",
    "            \"token\": i + 1 if i < 8 else \"$\\overline{\\hat y}$\"\n",
    "        })\n",
    "\n",
    "losses_over_time = pd.DataFrame(losses_over_time)\n",
    "losses_over_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.cm import ScalarMappable\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "token_losses_over_time = losses_over_time.loc[losses_over_time.token != \"$\\overline{\\hat y}$\"]\n",
    "mean_losses_over_time = losses_over_time.loc[losses_over_time.token == \"$\\overline{\\hat y}$\"]\n",
    "\n",
    "sns.lineplot(data=token_losses_over_time, x=\"step\", y=f\"loss\", hue=\"token\", palette=\"viridis\", ax=axes[0], alpha=0.5)\n",
    "sns.lineplot(data=token_losses_over_time, x=\"step\", y=f\"loss_0\", hue=\"token\", palette=\"viridis\", ax=axes[1], alpha=0.5)\n",
    "sns.lineplot(data=token_losses_over_time, x=\"step\", y=f\"ood_loss\", hue=\"token\", palette=\"viridis\", ax=axes[2], alpha=0.5)\n",
    "\n",
    "sns.lineplot(data=mean_losses_over_time, x=\"step\", y=\"loss\", label=\"Mean\", ax=axes[0], color=BRED)\n",
    "sns.lineplot(data=mean_losses_over_time, x=\"step\", y=f\"loss_0\", label=\"Mean\", ax=axes[1], color=BRED)\n",
    "sns.lineplot(data=mean_losses_over_time, x=\"step\", y=\"ood_loss\", label=\"Mean\", ax=axes[2], color=BRED)\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_xlabel(\"Step, $t$\")\n",
    "    ax.set_yscale('log')\n",
    "    legend = ax.legend()\n",
    "    legend.remove()\n",
    "    ax.set_xlim(100, 500_000)\n",
    "\n",
    "legend = axes[1].legend(loc='upper center', bbox_to_anchor=(0.5, -0.2), ncol=6)\n",
    "legend.set_title(\"Per-Token Losses\")\n",
    "\n",
    "# Move legend to be likee fig.legend(patch_list, milestone_labels, loc='upper center', bbox_to_anchor=(0.5, -0.025), ncol=len(TRANSITIONS))\n",
    "\n",
    "axes[0].set_title(\"MSE on in-distribution inputs over time\")\n",
    "axes[0].set_ylabel(\"MSE\")\n",
    "\n",
    "axes[1].set_title(\"Mean squared prediction over time\")\n",
    "axes[1].set_ylabel(\"$\\|\\hat y_k\\|^2$\")\n",
    "\n",
    "axes[2].set_title(\"MSE on out-of-distribution inputs over time\")\n",
    "axes[2].set_ylabel(\"MSE\")\n",
    "\n",
    "plot_transitions(axes, TRANSITIONS)\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "# Add color bar on the far right\n",
    "\n",
    "fig.set_facecolor('white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In-context learning score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import colors as mcolors\n",
    "\n",
    "LINE_PALETTE=\"viridis\"\n",
    "ALPHA=1\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "\n",
    "sns.lineplot(data=losses_over_time, x=\"step\", y=\"loss\", hue=\"token\", palette=LINE_PALETTE, alpha=ALPHA, ax=ax)\n",
    "\n",
    "ax.set_yscale('log')\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_xlabel(\"Step, $t$\")\n",
    "ax.set_ylabel(\"$L_\\mathrm{val}$\")\n",
    "ax.legend().remove()\n",
    "\n",
    "plot_transitions(ax, TRANSITIONS, limit=True) #, alpha=0.25)\n",
    "\n",
    "cbar_ax = fig.add_axes([0.93, 0.15, 0.02, 0.7])  # Adjust as necessary for position and size\n",
    "\n",
    "# custom_cmap = mcolors.LinearSegmentedColormap.from_list(\"custom_cmap\", LINE_PALETTE)\n",
    "\n",
    "sm = plt.cm.ScalarMappable(cmap='viridis', norm=plt.Normalize(vmin=1, vmax=8), )\n",
    "sm._A = []  # Dummy array for the ScalarMappable. \n",
    "cbar = fig.colorbar(sm, cax=cbar_ax)\n",
    "\n",
    "tick_positions = range(1, len(LINE_PALETTE)+1)  # Positions for each color\n",
    "tick_labels = [f\"${i}$\" for i in range(1, len(LINE_PALETTE) + 1)] # Replace with your labels\n",
    "cbar.set_ticks(tick_positions)\n",
    "cbar.set_ticklabels(tick_labels)\n",
    "cbar.set_label(\"$k$\")\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 0.91, 1])  # Adjust layout to make room for colorbar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import colors as mcolors\n",
    "\n",
    "LINE_PALETTE=\"viridis\"\n",
    "ALPHA=1\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "\n",
    "icl_score = losses_over_time.loc[losses_over_time.token == 8, \"loss\"].values - losses_over_time.loc[losses_over_time.token == 1, \"loss\"].values\n",
    "sns.lineplot(x=steps, y=icl_score, alpha=ALPHA, ax=ax)\n",
    "    \n",
    "# ax.set_yscale('log')\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_xlabel(\"Step, $t$\")\n",
    "ax.set_ylabel(\"$L_\\mathrm{val}$\")\n",
    "ax.legend().remove()\n",
    "\n",
    "plot_transitions(ax, TRANSITIONS, limit=True) #, alpha=0.25)\n",
    "\n",
    "cbar_ax = fig.add_axes([0.93, 0.15, 0.02, 0.7])  # Adjust as necessary for position and size\n",
    "\n",
    "# custom_cmap = mcolors.LinearSegmentedColormap.from_list(\"custom_cmap\", LINE_PALETTE)\n",
    "\n",
    "sm = plt.cm.ScalarMappable(cmap='viridis', norm=plt.Normalize(vmin=1, vmax=8), )\n",
    "sm._A = []  # Dummy array for the ScalarMappable. \n",
    "cbar = fig.colorbar(sm, cax=cbar_ax)\n",
    "\n",
    "tick_positions = range(1, len(LINE_PALETTE)+1)  # Positions for each color\n",
    "tick_labels = [f\"${i}$\" for i in range(1, len(LINE_PALETTE) + 1)] # Replace with your labels\n",
    "cbar.set_ticks(tick_positions)\n",
    "cbar.set_ticklabels(tick_labels)\n",
    "cbar.set_label(\"$k$\")\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 0.91, 1])  # Adjust layout to make room for colorbar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Behavioral Essential Dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the PCAs again. \n",
    "from typing import Dict, Iterable, Tuple\n",
    "from sklearn.decomposition import PCA\n",
    "from collections import defaultdict\n",
    "from devinterp.mechinterp.hooks import hook\n",
    "import numpy as np\n",
    "from icl.analysis.utils import map_evals_over_checkpoints, get_unique_run\n",
    "from icl.train import Run\n",
    "from devinfra.utils.tensors import convert_tensor, ReturnTensor\n",
    "from matplotlib import colors as mcolors\n",
    "\n",
    "\n",
    "def extract_activations_over_checkpoints(models: Iterable[nn.Module], xs, ys, *paths, return_type: ReturnTensor=\"np\"):\n",
    "    def eval_activations(model):\n",
    "        model.to(DEVICE)\n",
    "        xs.to(model.device)\n",
    "        ys.to(model.device)\n",
    "        hooked_model = hook(model, *paths)\n",
    "        outputs, activations = hooked_model.run_with_cache(xs, ys)\n",
    "        activations[\"\"] = outputs\n",
    "        return {k: convert_tensor(v, return_type) for k, v in activations.items() if (k in paths or k == \"\") and v is not None}\n",
    "    \n",
    "    for model in models:\n",
    "        yield eval_activations(model)\n",
    "\n",
    "\n",
    "def get_vectorized_activations_trace(models: Iterable[nn.Module], xs, ys, *paths, normalize=False):\n",
    "    evals: Dict[str, list] = defaultdict(list)\n",
    "    \n",
    "    for activations in extract_activations_over_checkpoints(models, xs, ys, *paths):\n",
    "        for path, activation in activations.items():\n",
    "            if normalize:\n",
    "                activation = activation / np.linalg.norm(activation)\n",
    "\n",
    "            evals[path].append(activation)\n",
    "\n",
    "    return {\n",
    "        k: np.array(v).reshape(len(v), -1) for k, v in evals.items()\n",
    "    }\n",
    "\n",
    "def get_pca_activations_trace(models: Iterable[nn.Module], xs, ys, *paths, num_components=3, normalize=False) -> Dict[str, Tuple[PCA, np.ndarray]]:\n",
    "    results = {}\n",
    "\n",
    "    for path, activations in get_vectorized_activations_trace(models, xs, ys, *paths, normalize=normalize).items():\n",
    "        pca = PCA(n_components=num_components)\n",
    "        activations_reduced = pca.fit_transform(activations)\n",
    "        results[path] = pca, activations_reduced\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "tab10 = plt.cm.get_cmap('tab10', 10)  # Get the tab10 colormap\n",
    "colors = tab10.colors[:len(TRANSITIONS)]  # Get the first 6 colors \n",
    "# Add an extra gray to this np array for extra colors\n",
    "colors = np.vstack((colors, np.array([0.8, 0.8, 0.8, 1.0])))\n",
    "\n",
    "# Create a new colormap from the extracted colors\n",
    "custom_cmap = mcolors.ListedColormap(colors)\n",
    "\n",
    "# plot_multiple_slices(steps, demo_logits_reduced_3, demo_logits_pca_3, title=demo.config.to_latex(), connect_dots=True)\n",
    "train_xs_1, train_ys_1 = pretrain_dist_noiseless.get_batch(8, 1024)\n",
    "\n",
    "traces = get_pca_activations_trace(\n",
    "    models,\n",
    "    train_xs_1, \n",
    "    train_ys_1, \n",
    "    \"token_sequence_transformer\",\n",
    "    # \"token_sequence_transformer.blocks.1\",\n",
    "    # \"token_sequence_transformer.token_embedding\",\n",
    "    num_components=10,\n",
    "    normalize=False\n",
    ") \n",
    "\n",
    "# traces_small = get_pca_activations_trace(\n",
    "#     models,\n",
    "#     train_xs_1[:1024], \n",
    "#     train_ys_1[:1024], \n",
    "#     \"\",\n",
    "#     \"token_sequence_transformer.blocks.1\",\n",
    "#     # \"token_sequence_transformer.token_embedding\",\n",
    "#     num_components=3,\n",
    "#     normalize=False\n",
    "# ) \n",
    "\n",
    "pca_outputs, logits_outputs = traces[\"\"]\n",
    "pca_logits, logits_reduced = traces[\"token_sequence_transformer\"]\n",
    "# pca_internal, activations_reduced = traces_small[\"token_sequence_transformer.blocks.1\"]\n",
    "\n",
    "traces_normalized = get_pca_activations_trace(\n",
    "    models,\n",
    "    train_xs_1, \n",
    "    train_ys_1, \n",
    "    \"token_sequence_transformer\",\n",
    "    # \"token_sequence_transformer.blocks.1\",\n",
    "    # \"token_sequence_transformer.token_embedding\",\n",
    "    num_components=10,\n",
    "    normalize=True\n",
    ") \n",
    "\n",
    "# traces_small_normalized = get_pca_activations_trace(\n",
    "#     models,\n",
    "#     train_xs_1[:1024], \n",
    "#     train_ys_1[:1024], \n",
    "#     # \"token_sequence_transformer\",\n",
    "#     \"token_sequence_transformer.blocks.1\",\n",
    "#     # \"token_sequence_transformer.token_embedding\",\n",
    "#     num_components=3,\n",
    "#     normalize=True\n",
    "# ) \n",
    "\n",
    "pca_outputs_normalized, activations_outputs_normalized = traces_normalized[\"\"]\n",
    "pca_internal_normalized, activations_reduced_normalized = traces_normalized[\"token_sequence_transformer\"]\n",
    "# pca_internal, activations_reduced = traces_small[\"token_sequence_transformer.blocks.1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from typing import Optional\n",
    "\n",
    "def get_transition_indices(steps, transitions):\n",
    "    transition_indices = []\n",
    "    for step in steps:\n",
    "        # Find the index of the transition that the current step falls into\n",
    "        index = next((i for i, transition in enumerate(transitions) if transition[0] <= step < transition[1]), None)\n",
    "        transition_indices.append(index if index is not None else -1)\n",
    "\n",
    "    return transition_indices\n",
    "\n",
    "def get_nearest_step(step):\n",
    "    idx = np.argmin(np.abs(np.array(steps) - step))\n",
    "    return steps[idx]\n",
    "\n",
    "def plot_explained_variance(pca, title=\"Explained Variance\", ax: Optional[plt.Axes] = None, num_pca_components=None):\n",
    "    num_pca_components = num_pca_components or len(pca.explained_variance_ratio_)\n",
    "\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "    ax.bar(range(num_pca_components), pca.explained_variance_ratio_[:num_pca_components])\n",
    "\n",
    "    for i, ratio in enumerate(pca.explained_variance_ratio_[:num_pca_components]):\n",
    "        ax.text(i, ratio, f\"{ratio:.2f}\", fontsize=12, ha='center', va='bottom')\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('PC')\n",
    "    ax.set_ylabel('Explained Variance')\n",
    "\n",
    "    ax.set_xticks(range(num_pca_components), range(1, num_pca_components + 1))\n",
    "\n",
    "\n",
    "def plot_multiple_slices(steps, samples, pca, transitions, highlighted_steps=None, connect_dots=False, palette='tab10', alpha=0.8, save=False, line_color=\"auto\"):\n",
    "    transition_idxs = get_transition_indices(steps, transitions)\n",
    "    # transition_idxs = [(0 if i != 4 else 1) for i in transition_idxs]\n",
    "\n",
    "    # for i in range(1, 5):\n",
    "    #     transition_idxs[-i] = 10  \n",
    "\n",
    "    if highlighted_steps is None:\n",
    "        highlighted_steps = list(map(get_nearest_step, [t[0] for t in transitions][1:]))\n",
    "\n",
    "    num_pca_components = samples.shape[-1]\n",
    "    \n",
    "    # Create a single row of subplots\n",
    "    num_pca_combos = (num_pca_components * (num_pca_components-1)) // 2\n",
    "    \n",
    "    fig, axes = plt.subplots(1, num_pca_combos + 1, figsize=(20, 4))\n",
    "    # fig.suptitle(title)\n",
    "\n",
    "    # Ensure ax is iterable by converting to a list if there's only one subplot\n",
    "    if num_pca_components == 2:\n",
    "        axes = [axes]\n",
    "\n",
    "    I = 0\n",
    "    for i in range(1, num_pca_components):\n",
    "        for j in range(i):\n",
    "\n",
    "            if connect_dots:\n",
    "                axes[I].plot(samples[:, i], samples[:, j], c='black', alpha=0.2)\n",
    "\n",
    "            # sc = axes[I].scatter(samples[:, i], samples[:, j], c=transition_idxs, cmap=cmap, s=50, alpha=alpha)\n",
    "            sns.scatterplot(x=samples[:, i], y=samples[:, j], hue=transition_idxs, palette=palette, s=50, alpha=alpha, ax=axes[I], legend=False)\n",
    "            axes[I].set_xlabel(f'PC {i}')\n",
    "            axes[I].set_ylabel(f'PC {j}')\n",
    "            axes[I].set_title(f'PC {i} vs PC {j}')\n",
    "\n",
    "            # Label some points\n",
    "            total_samples = len(samples)\n",
    "            for step in highlighted_steps:\n",
    "                k = steps.index(step)  # Find the index of the highlighted step\n",
    "                axes[I].text(samples[k, i], samples[k, j], str(step), fontsize=8, ha='right', va='bottom', alpha=0.8)\n",
    "\n",
    "            I += 1\n",
    "\n",
    "    plot_explained_variance(pca, ax=axes[-1], num_pca_components=num_pca_components)\n",
    "    # for I in range( num_pca_combos):\n",
    "    #     axes[I].axis('off')\n",
    "            \n",
    "    # Colorbar for the last plot\n",
    "    # cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])  # Adjust as necessary\n",
    "        # plt.colorbar(sc, cax=cbar_ax, label='Milestones')\n",
    "\n",
    "    cmap = sns.palettes.color_palette(palette, n_colors=len(transitions) + 1)\n",
    "\n",
    "    # Plot the legend on the first subplot on the left\n",
    "    legend_ax = axes[0]\n",
    "    scatter_proxy = [plt.Line2D([0], [0], linestyle='none', marker='o', alpha=alpha, color=cmap[i]) for i in range(len(transitions))]\n",
    "    legend_labels = [label for _, _, label in transitions]\n",
    "    legend_ax.legend(scatter_proxy, legend_labels, loc='center', ncol=1, frameon=False, bbox_to_anchor=(-0.5, 0.5), title='Developmental Stages')\n",
    "    # legend_ax.set_title()\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 0.9, 1])  # Adjust the right side to make room for the colorbar\n",
    "\n",
    "    if save:\n",
    "        parent_dir = os.path.dirname(save)\n",
    "        if not os.path.exists(parent_dir):\n",
    "            os.makedirs(parent_dir)\n",
    "        plt.savefig(save)\n",
    "\n",
    "\n",
    "    fig.set_facecolor('white')\n",
    "    \n",
    "# Usage of the function\n",
    "# Call the function with your data and the list of highlighted steps\n",
    "# plot_multiple_slices(steps, samples, pca, highlighted_steps=[100, 1000, 10000], title=\"Your Title\", num_points_to_label=10, save=\"path/to/save.png\", connect_dots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_multiple_slices(\n",
    "    steps, \n",
    "    logits_reduced[:, :3], \n",
    "    pca_logits, \n",
    "    TRANSITIONS,\n",
    "    connect_dots=True, \n",
    "    save=None,\n",
    "    # cmap=transitions_cmap\n",
    ")\n",
    "plt.suptitle(\"Essential Dynamics of Behavioral Proxy\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plot_multiple_slices(\n",
    "    steps, \n",
    "    exp_avg_grads_reduced[:, :3], \n",
    "    pca_1, \n",
    "    TRANSITIONS,\n",
    "    connect_dots=True, \n",
    "    save=None,\n",
    "    # cmap=transitions_cmap\n",
    ")\n",
    "plt.suptitle(\"Essential Dynamics of Exponentially Averaged Square Gradients\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geometric Indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "gradient_stats = []\n",
    "\n",
    "xs, ys = run.evaluator.pretrain_xs, run.evaluator.pretrain_ys\n",
    "xs, ys = xs.to(DEVICE), ys.to(DEVICE)\n",
    "\n",
    "\n",
    "for step, model in zip(steps, models):\n",
    "    model.to(DEVICE)\n",
    "    model.zero_grad()\n",
    "\n",
    "    yhats = model(xs, ys)\n",
    "\n",
    "    loss = F.mse_loss(yhats, ys)\n",
    "    loss.backward()\n",
    "\n",
    "    for n, p in model.named_parameters():\n",
    "\n",
    "        if p.grad is None:\n",
    "            continue\n",
    "\n",
    "        grad_sq_mean = (p.grad ** 2).mean().item()\n",
    "        grad_sq_std = (p.grad ** 2).std().item()\n",
    "\n",
    "        gradient_stats.append({\n",
    "            \"step\": step,\n",
    "            \"layer\": n,\n",
    "            \"grad/norm\": grad_sq_mean ** 0.5,\n",
    "            \"grad_sq/mean\": grad_sq_mean,\n",
    "            \"grad_sq/std\": grad_sq_std,\n",
    "            \"numel\": p.numel(),\n",
    "            \"loss\": loss.item(),\n",
    "        })          \n",
    "\n",
    "        p.grad = None \n",
    "\n",
    "gradient_stats = pd.DataFrame(gradient_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(20, 5))\n",
    "\n",
    "avg_gradients = gradient_stats.groupby(['step']).mean()\n",
    "\n",
    "grad_norm_thresholded = gradient_stats['grad/norm'].values + 0.00001\n",
    "\n",
    "sns.lineplot(data=gradient_stats, x='step', y=grad_norm_thresholded, hue=\"layer\", ax=ax, legend=False, alpha=0.5)\n",
    "sns.lineplot(data=avg_gradients, x='step', y='grad/norm', ax=ax, legend=False, color=BRED)\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel(\"Step, $t$\")\n",
    "ax.set_ylabel(\"Gradient norm, $\\|w_t\\|$\")\n",
    "\n",
    "_ = plot_transitions(ax, TRANSITIONS, limit=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the optimizer state\n",
    "\n",
    "names = [n for n, _ in run.model.named_parameters()]\n",
    "\n",
    "optimizer_stats = []\n",
    "\n",
    "for step, optimizer_state_dict in zip(steps, optimizer_state_dicts):\n",
    "    for layer, g in optimizer_state_dict[\"state\"].items():\n",
    "        optimizer_stats.append({\n",
    "            \"step\": step,\n",
    "            \"layer\": layer,\n",
    "            \"layer_name\": list(model.state_dict().keys())[layer],\n",
    "            \"exp_avg_sq_norm\": g[\"exp_avg_sq\"].norm().item() + 0.0000001\n",
    "        })\n",
    "\n",
    "optimizer_stats = pd.DataFrame(optimizer_stats)\n",
    "avg_optimizer_stats = optimizer_stats.groupby('step').mean()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "sns.lineplot(data=optimizer_stats, x=\"step\", y=\"exp_avg_sq_norm\", hue=\"layer_name\", palette=\"tab10\", ax=ax, alpha=0.8)\n",
    "sns.lineplot(data=avg_optimizer_stats, x=\"step\", y=\"exp_avg_sq_norm\", palette=\"viridis\", ax=ax, color=BRED)\n",
    "ax.set_ylabel(\"Exponentially Averaged Squared Gradient Norm\")\n",
    "ax.set_xlabel(\"Step\")\n",
    "ax.set_title(\"Exponentially averaged gradient norms by Layer and Step\")\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "plot_transitions(ax, TRANSITIONS, limit=True)\n",
    "\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_xlim(100, 500_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to see in what order the layers reach \"zero\"\n",
    "# 1. Figure out the earliest step for each layer where exp_avg_sq_norm < 1e-5\n",
    "# 2. Order by this earliest step\n",
    "# 3. List the names\n",
    "\n",
    "threshold = 3e-7\n",
    "\n",
    "# Find the earliest step where exp_avg_sq_norm < threshold for each layer\n",
    "earliest_zero_step = optimizer_stats[optimizer_stats['exp_avg_sq_norm'] < threshold] \\\n",
    "    .groupby('layer_name') \\\n",
    "    .agg(earliest_step=('step', 'min'))\n",
    "\n",
    "# Now, sort the layers by the earliest step where their norm goes below the threshold\n",
    "sorted_layers_by_earliest_zero_step = earliest_zero_step.sort_values(by='earliest_step')\n",
    "sorted_layers_by_earliest_zero_step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient essential dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del gradients_over_time\n",
    "    del gradients_reduced\n",
    "    del gradients_reduced_normalized\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "PERPLEXITY = 15\n",
    "\n",
    "for layer_name in [\n",
    "    \"token_sequence_transformer.token_embedding\",\n",
    "    \"token_sequence_transformer.unembedding.0\",\n",
    "    \"token_sequence_transformer.blocks.0.compute.0\",\n",
    "    \"token_sequence_transformer.blocks.0.compute.2\",\n",
    "    \"token_sequence_transformer.blocks.1.compute.0\",\n",
    "    \"token_sequence_transformer.blocks.1.compute.2\"\n",
    "]:\n",
    "    layer_path = layer_name.split(\".\")\n",
    "    last_state_dict = models[-1].state_dict()\n",
    "    num_params = 0\n",
    "    \n",
    "    for subset in (\"weight\", \"bias\"):\n",
    "        subset_full_name = layer_name + \".\" + subset\n",
    "        if subset_full_name in last_state_dict:\n",
    "            num_params += models[-1].state_dict()[subset_full_name].numel()\n",
    "            \n",
    "    gradients_over_time = np.zeros((len(steps), num_params))\n",
    "\n",
    "    def get_params(model, layer_path):\n",
    "        m = model\n",
    "        for part in layer_path:\n",
    "            m = getattr(m, part)\n",
    "        \n",
    "        return m\n",
    "\n",
    "    for i, model in enumerate(models):\n",
    "        # model.train()\n",
    "        model.to(DEVICE)\n",
    "        model.zero_grad()\n",
    "\n",
    "        yhats = model(xs, ys)\n",
    "\n",
    "        loss = F.mse_loss(yhats, ys)\n",
    "        loss.backward()\n",
    "\n",
    "        layer = get_params(model, layer_path)\n",
    "\n",
    "        n = 0\n",
    "        for subset in (\"weight\", \"bias\"):\n",
    "            if layer and hasattr(layer, subset):\n",
    "                param = getattr(layer, subset)\n",
    "                if param is None:\n",
    "                    continue\n",
    "\n",
    "                numel = param.numel()\n",
    "                gradients_over_time[i, n:n+numel] = param.grad.flatten().cpu().numpy()\n",
    "                n += numel\n",
    "\n",
    "    pca = PCA(n_components=50)\n",
    "    gradients_reduced = pca.fit_transform(gradients_over_time)\n",
    "\n",
    "    norms = np.linalg.norm(gradients_over_time, axis=1, keepdims=True)\n",
    "    norms[norms == 0] = 1\n",
    "\n",
    "    gradients_reduced_normalized = pca.fit_transform(gradients_over_time / norms)\n",
    "\n",
    "    plot_multiple_slices(\n",
    "        steps, \n",
    "        gradients_reduced[:, :3], \n",
    "        pca, \n",
    "        highlight_steps,\n",
    "        transitions_of_steps,\n",
    "        connect_dots=True, \n",
    "        save=None,\n",
    "    )\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    tsne = TSNE(n_components=2, perplexity=PERPLEXITY, n_iter=1000, random_state=0)\n",
    "    gradients_tsne = tsne.fit_transform(gradients_reduced)\n",
    "\n",
    "    plt.scatter(gradients_tsne[:, 0], gradients_tsne[:, 1], c=transitions_of_steps, cmap=custom_cmap, s=50, alpha=0.6)\n",
    "    plt.show()\n",
    "\n",
    "    tsne_normalized = TSNE(n_components=2, perplexity=PERPLEXITY, n_iter=1000, random_state=0)\n",
    "    gradients_tsne_normalized = tsne.fit_transform(gradients_reduced_normalized)\n",
    "\n",
    "    plt.scatter(gradients_tsne_normalized[:, 0], gradients_tsne_normalized[:, 1], c=transitions_of_steps, cmap=custom_cmap, s=50, alpha=0.6)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "try:\n",
    "    del gradients_over_time\n",
    "    del gradients_reduced\n",
    "    del gradients_reduced_normalized\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "PERPLEXITY = 10\n",
    "\n",
    "def get_all_params_as_array(model):\n",
    "    return np.concatenate([p.cpu().numpy().flatten() for p in model.parameters()])\n",
    "\n",
    "\n",
    "def get_all_gradients_as_array(model):\n",
    "    return np.concatenate([p.grad.cpu().numpy().flatten() for p in model.parameters() if p.grad is not None])\n",
    "\n",
    "gradients_over_time = []\n",
    "gradients_normalized_over_time = []\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    # model.train()\n",
    "    model.to(DEVICE)\n",
    "    model.zero_grad()\n",
    "\n",
    "    yhats = model(xs, ys)\n",
    "\n",
    "    loss = F.mse_loss(yhats, ys)\n",
    "    loss.backward()\n",
    "\n",
    "    layer = get_params(model, layer_path)\n",
    "\n",
    "    gradients = get_all_gradients_as_array(model)\n",
    "    gradients_over_time.append(gradients)\n",
    "    gradients_normalized_over_time.append(gradients / np.linalg.norm(gradients))\n",
    "\n",
    "gradients_over_time = np.array(gradients_over_time)\n",
    "gradients_normalized_over_time = np.array(gradients_normalized_over_time)\n",
    "\n",
    "pca_1 = PCA(n_components=50)\n",
    "gradients_reduced = pca_1.fit_transform(gradients_over_time)\n",
    "\n",
    "pca_2 = PCA(n_components=50)\n",
    "gradients_reduced_normalized = pca_2.fit_transform(gradients_normalized_over_time)\n",
    "\n",
    "plot_multiple_slices(\n",
    "    steps, \n",
    "    gradients_reduced[:, :3], \n",
    "    pca_1, \n",
    "transitions,\n",
    "\n",
    "    transitions_of_steps,\n",
    "    connect_dots=True, \n",
    "    save=None,\n",
    ")\n",
    "\n",
    "plot_multiple_slices(\n",
    "    steps, \n",
    "    gradients_reduced_normalized[:, :3], \n",
    "    pca_2, \n",
    "transitions,\n",
    "\n",
    "    transitions_of_steps,\n",
    "    connect_dots=True, \n",
    "    save=None,\n",
    ")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"Full gradients\")\n",
    "print(\"Unnormalized\")\n",
    "\n",
    "tsne = TSNE(n_components=2, perplexity=PERPLEXITY, n_iter=1000, random_state=0)\n",
    "gradients_tsne = tsne.fit_transform(gradients_reduced)\n",
    "\n",
    "plt.scatter(gradients_tsne[:, 0], gradients_tsne[:, 1], c=transitions_of_steps, cmap=custom_cmap, s=50, alpha=0.6)\n",
    "plt.show()\n",
    "\n",
    "print(\"Normalized\")\n",
    "\n",
    "tsne_normalized = TSNE(n_components=2, perplexity=PERPLEXITY, n_iter=1000, random_state=0)\n",
    "gradients_tsne_normalized = tsne.fit_transform(gradients_reduced_normalized)\n",
    "\n",
    "plt.scatter(gradients_tsne_normalized[:, 0], gradients_tsne_normalized[:, 1], c=transitions_of_steps, cmap=custom_cmap, s=50, alpha=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "try:\n",
    "    del exp_avg_grads_over_time\n",
    "    del exp_avg_grads_reduced\n",
    "    del exp_avg_grads_reduced_normalized\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "PERPLEXITY = 15\n",
    "\n",
    "exp_avg_grads_over_time = []\n",
    "exp_avg_grads_normalized_over_time = []\n",
    "\n",
    "def get_exp_avg_sq_grads(optimizer_state_dict):\n",
    "    return np.concatenate([g[\"exp_avg_sq\"].cpu().numpy().flatten() for g in optimizer_state_dict[\"state\"].values()])\n",
    "\n",
    "def get_exp_avg_grads(optimizer_state_dict):\n",
    "    return np.concatenate([g[\"exp_avg\"].cpu().numpy().flatten() for g in optimizer_state_dict[\"state\"].values()])\n",
    "\n",
    "\n",
    "for i, opt_state in enumerate(optimizer_state_dicts):\n",
    "    # model.train()\n",
    "    exp_avg_grads = get_exp_avg_grads(opt_state)\n",
    "    exp_avg_grads_over_time.append(exp_avg_grads)\n",
    "    exp_avg_grads_normalized_over_time.append(exp_avg_grads / np.linalg.norm(exp_avg_grads))\n",
    "\n",
    "exp_avg_grads_over_time = np.array(exp_avg_grads_over_time)\n",
    "exp_avg_grads_normalized_over_time = np.array(exp_avg_grads_normalized_over_time)\n",
    "\n",
    "\n",
    "pca_1 = PCA(n_components=50)\n",
    "exp_avg_grads_reduced = pca_1.fit_transform(exp_avg_grads_over_time)\n",
    "\n",
    "pca_2 = PCA(n_components=50)\n",
    "exp_avg_grads_reduced_normalized = pca_2.fit_transform(exp_avg_grads_normalized_over_time)\n",
    "\n",
    "plot_multiple_slices(\n",
    "    steps, \n",
    "    exp_avg_grads_reduced[:, :3], \n",
    "    pca_1, \n",
    "transitions,\n",
    "\n",
    "    transitions_of_steps,\n",
    "    connect_dots=True, \n",
    "    save=None,\n",
    ")\n",
    "\n",
    "plot_multiple_slices(\n",
    "    steps, \n",
    "    exp_avg_grads_reduced_normalized[:, :3], \n",
    "    pca_2, \n",
    "transitions,\n",
    "\n",
    "    transitions_of_steps,\n",
    "    connect_dots=True, \n",
    "    save=None,\n",
    ")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"Exponentially averaged gradients\")\n",
    "print(\"Unnormalized\")\n",
    "\n",
    "tsne = TSNE(n_components=2, perplexity=PERPLEXITY, n_iter=1000, random_state=0)\n",
    "exp_avg_grads_tsne = tsne.fit_transform(exp_avg_grads_reduced)\n",
    "\n",
    "plt.scatter(exp_avg_grads_tsne[:, 0], exp_avg_grads_tsne[:, 1], c=transitions_of_steps, cmap=custom_cmap, s=50, alpha=0.6)\n",
    "plt.show()\n",
    "\n",
    "print(\"Normalized\")\n",
    "\n",
    "tsne_normalized = TSNE(n_components=2, perplexity=PERPLEXITY, n_iter=1000, random_state=0)\n",
    "exp_avg_grads_tsne_normalized = tsne.fit_transform(exp_avg_grads_reduced_normalized)\n",
    "\n",
    "plt.scatter(exp_avg_grads_tsne_normalized[:, 0], exp_avg_grads_tsne_normalized[:, 1], c=transitions_of_steps, cmap=custom_cmap, s=50, alpha=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "try:\n",
    "    del exp_avg_grads_over_time\n",
    "    del exp_avg_grads_reduced\n",
    "    del exp_avg_grads_reduced_normalized\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "PERPLEXITY = 15\n",
    "\n",
    "exp_avg_grads_over_time = []\n",
    "exp_avg_grads_normalized_over_time = []\n",
    "\n",
    "def get_exp_avg_sq_grads(optimizer_state_dict):\n",
    "    return np.concatenate([g[\"exp_avg_sq\"].cpu().numpy().flatten() for g in optimizer_state_dict[\"state\"].values()])\n",
    "\n",
    "def get_exp_avg_grads(optimizer_state_dict):\n",
    "    return np.concatenate([g[\"exp_avg\"].cpu().numpy().flatten() for g in optimizer_state_dict[\"state\"].values()])\n",
    "\n",
    "\n",
    "for i, opt_state in enumerate(optimizer_state_dicts):\n",
    "    # model.train()\n",
    "    exp_avg_grads = get_exp_avg_sq_grads(opt_state)\n",
    "    exp_avg_grads_over_time.append(exp_avg_grads)\n",
    "    exp_avg_grads_normalized_over_time.append(exp_avg_grads / np.linalg.norm(exp_avg_grads))\n",
    "\n",
    "exp_avg_grads_over_time = np.array(exp_avg_grads_over_time)\n",
    "exp_avg_grads_normalized_over_time = np.array(exp_avg_grads_normalized_over_time)\n",
    "\n",
    "pca_1 = PCA(n_components=50)\n",
    "exp_avg_grads_reduced = pca_1.fit_transform(exp_avg_grads_over_time)\n",
    "\n",
    "pca_2 = PCA(n_components=50)\n",
    "exp_avg_grads_reduced_normalized = pca_2.fit_transform(exp_avg_grads_normalized_over_time)\n",
    "\n",
    "plot_multiple_slices(\n",
    "    steps, \n",
    "    exp_avg_grads_reduced[:, :3], \n",
    "    pca_1, \n",
    "transitions,\n",
    "\n",
    "    transitions_of_steps,\n",
    "    connect_dots=True, \n",
    "    save=None,\n",
    "    # cmap=transitions_cmap\n",
    ")\n",
    "\n",
    "plot_multiple_slices(\n",
    "    steps, \n",
    "    exp_avg_grads_reduced_normalized[:, :3], \n",
    "    pca_2, \n",
    "transitions,\n",
    "\n",
    "    transitions_of_steps,\n",
    "    connect_dots=True, \n",
    "    save=None,\n",
    "    # cmap=transitions_cmap,\n",
    ")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"Exponentially averaged square gradients\")\n",
    "print(\"Unnormalized\")\n",
    "\n",
    "tsne = TSNE(n_components=2, perplexity=PERPLEXITY, n_iter=1000, random_state=0)\n",
    "exp_avg_grads_tsne = tsne.fit_transform(exp_avg_grads_reduced)\n",
    "\n",
    "plt.scatter(exp_avg_grads_tsne[:, 0], exp_avg_grads_tsne[:, 1], c=transitions_of_steps, cmap=custom_cmap, s=50, alpha=0.6)\n",
    "plt.show()\n",
    "\n",
    "print(\"Normalized\")\n",
    "tsne_normalized = TSNE(n_components=2, perplexity=PERPLEXITY, n_iter=1000, random_state=0)\n",
    "exp_avg_grads_tsne_normalized = tsne.fit_transform(exp_avg_grads_reduced_normalized)\n",
    "\n",
    "plt.scatter(exp_avg_grads_tsne_normalized[:, 0], exp_avg_grads_tsne_normalized[:, 1], c=transitions_of_steps, cmap=custom_cmap, s=50, alpha=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tsne = TSNE(n_components=2, perplexity=30, n_iter=1000, random_state=0)\n",
    "gradients_tsne = tsne.fit_transform(gradients_reduced)\n",
    "\n",
    "plt.scatter(gradients_tsne[:, 0], gradients_tsne[:, 1], c=transitions_of_steps, cmap=custom_cmap, s=50, alpha=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGLD PCAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pp\n",
    "import sys\n",
    "\n",
    "from icl.analysis.slt import ExpectedBatchLossEstimator\n",
    "from icl.analysis.weights import WeightsTrace \n",
    "del sys.modules['icl.analysis.sample']\n",
    "del sys.modules['icl.analysis.slt']\n",
    "del sys.modules['icl.analysis.estimators']\n",
    "\n",
    "import yaml\n",
    "from icl.analysis.sample import SamplerConfig\n",
    "\n",
    "os.environ.setdefault('PYTORCH_ENABLE_MPS_FALLBACK', '1')\n",
    "\n",
    "CORES = 1\n",
    "NUM_CHAINS = 25\n",
    "NUM_DRAWS = 1000\n",
    "NUM_SAMPLES = 1024\n",
    "DATASET_SIZE = 2 ** 14\n",
    "\n",
    "sampler_config: SamplerConfig = SamplerConfig(\n",
    "    num_chains=NUM_CHAINS,\n",
    "    num_draws=NUM_DRAWS,\n",
    "    sampling_method='sgld',\n",
    "    grad_batch_origin='eval-dataset',\n",
    "    grad_batch_size=NUM_SAMPLES,\n",
    "    noise_scale=5e-3,    \n",
    "    localization_scale=5e-2,\n",
    "    gradient_scale=1e-5 * 1024. / (2 * np.log(1024)), \n",
    "    # noise_scale=5e-4,    \n",
    "    # localization_scale=1e-1,\n",
    "    # gradient_scale=1e-6 * 1024. / (2 * np.log(1024)), \n",
    "    # eval_method='fixed-minibatch',\n",
    "    eval_method='grad-minibatch',\n",
    "    eval_metrics=['likelihood-derived', 'batch-loss', 'weights'],\n",
    "    # eval_batch_size=8192,\n",
    "    eval_dataset_size=DATASET_SIZE,\n",
    "    device='cpu',\n",
    "    cores=CORES,\n",
    "    eval_loss_fn='mse',\n",
    "    eval_online=True\n",
    ")\n",
    "\n",
    "print(yaml.dump(sampler_config.model_dump()))\n",
    "\n",
    "run.model = models[-1]\n",
    "run.model.to('cpu')\n",
    "# log_fn = lambda data, step=None: print(f\"Step: {step}\\n\", yaml.dump(data))\n",
    "sampler = sampler_config.to_sampler(run, log_fn=None)\n",
    "print(\"INIT LOSS\", sampler.init_loss)\n",
    "\n",
    "results = sampler.eval(run.model)\n",
    "\n",
    "pp(sampler.callbacks[0].estimate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llc_callback = sampler.callbacks[0]\n",
    "sgld_estimates_df = llc_callback.estimates()\n",
    "\n",
    "sgld_estimates_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "batch_losses = sampler.batch_loss.estimates()\n",
    "batch_losses['mean'] = [float(x) for x in batch_losses['mean']]\n",
    "\n",
    "#llc_callback.expected_loss_estimator.\n",
    "sns.lineplot(data=batch_losses, x=\"draw\", y=\"mean\", hue=\"chain\", palette=\"gray\", ax=ax, alpha=0.5)\n",
    "\n",
    "twin_ax = ax.twinx()\n",
    "sns.lineplot(data=sgld_estimates_df, x=\"draw\", y=\"llc/mean\", ax=twin_ax, alpha=0.5, color=PRIMARY)\n",
    "\n",
    "ax.set_ylabel(r\"Batch Loss. $L^{(\\tau)}_m$\")\n",
    "twin_ax.set_ylabel(r\"LLC, $\\hat\\lambda_\\tau$\", color=PRIMARY)\n",
    "for label in twin_ax.get_yticklabels():\n",
    "    label.set_color(PRIMARY)\n",
    "\n",
    "ax.set_xlabel(r\"Draw, $\\tau$\")\n",
    "ax.legend().remove()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_weights_np = np.concatenate([p.view(-1).detach().cpu().numpy() for p in run.model.parameters()])\n",
    "\n",
    "weights_np = sampler.callbacks[-1].weights.detach().cpu().numpy()[:, :, :]\n",
    "# del sampler.callbacks[-1].weights\n",
    "\n",
    "weights_flat = weights_np.reshape(-1, weights_np.shape[-1]) - init_weights_np\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=50)\n",
    "weights_reduced = pca.fit_transform(weights_flat)\n",
    "\n",
    "# from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=2, perplexity=30, n_iter=1000, random_state=0)\n",
    "weights_tsne = tsne.fit_transform(weights_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "plot_explained_variance(pca, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_weights_np = np.concatenate([p.view(-1).detach().cpu().numpy() for p in run.model.parameters()])\n",
    "\n",
    "weights_np = sampler.callbacks[-1].weights.detach().cpu().numpy()[:, :, :]\n",
    "# del sampler.callbacks[-1].weights\n",
    "\n",
    "weights_flat = weights_np.reshape(-1, weights_np.shape[-1]) - init_weights_np\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=50)\n",
    "weights_reduced = pca.fit_transform(weights_flat)\n",
    "\n",
    "# from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=2, perplexity=30, n_iter=1000, random_state=0)\n",
    "weights_tsne = tsne.fit_transform(weights_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chain in range(NUM_CHAINS):\n",
    "    _weights = weights_tsne[chain * NUM_DRAWS:(chain + 1) * NUM_DRAWS] \n",
    "    sns.scatterplot(x=_weights[:, 0], y=_weights[:, 1], s=50, alpha=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def plot_weights_trace_fn(model, deltas, xs, ys, device='cpu', num_components=3, num_points=10):\n",
    "    model.to(device)\n",
    "    xs.to(device)\n",
    "    ys.to(device)\n",
    "\n",
    "    num_chains = deltas.shape[0]\n",
    "    num_draws = deltas.shape[1]\n",
    "\n",
    "\n",
    "    pca = PCA(n_components=num_components)\n",
    "\n",
    "    weights_reduced = pca.fit_transform(deltas.reshape(num_chains * num_draws, -1))\n",
    "\n",
    "    def get_pc_landscape(pca, fn, pc1, pc2, pc1_lim: Tuple[int, int], pc2_lim: Tuple[int, int], num_points=100, ax=None):\n",
    "        xx, yy = np.meshgrid(np.linspace(*pc1_lim, num_points), np.linspace(*pc2_lim, num_points))\n",
    "\n",
    "        # Compute function values for the grid\n",
    "        Z = np.zeros(xx.shape)\n",
    "        for i in tqdm.tqdm(range(xx.shape[0]), \"Iterating over rows\"):\n",
    "            for j in range(xx.shape[1]):\n",
    "                u = xx[i, j] * pc1 + yy[i, j] * pc2\n",
    "                Z[i, j] = fn(u)\n",
    "\n",
    "        # Plot the density map\n",
    "        Z = (Z - Z.min()) / (Z.max() - Z.min()) # rescale\n",
    "        Z = np.log(1e-3 + Z)\n",
    "        \n",
    "        im = ax.imshow(Z, interpolation='bilinear', origin='lower',\n",
    "            extent=(*pc1_lim, *pc2_lim), cmap='Blues', alpha=1., aspect='auto')\n",
    "        \n",
    "        return Z\n",
    "\n",
    "    def weights_to_model(weights):\n",
    "        m = deepcopy(model)\n",
    "        m.to(device)\n",
    "\n",
    "        i = 0\n",
    "        for n, p in m.named_parameters():\n",
    "            p.data += torch.from_numpy(weights[i:i+p.numel()]).view(p.shape).to(device)\n",
    "            i += p.numel()\n",
    "        \n",
    "        return m\n",
    "\n",
    "\n",
    "    def weights_to_loss(weights):\n",
    "        m = weights_to_model(weights)\n",
    "        yhats = m(xs, ys)\n",
    "        return F.mse_loss(yhats, ys).item()\n",
    "\n",
    "    xs.to(device)\n",
    "    ys.to(device)\n",
    "\n",
    "    pc_combos = list(itertools.combinations(range(num_components), 2))\n",
    "\n",
    "    fig, axes = plt.subplots(1, len(pc_combos) + 1, figsize=(20, 5))\n",
    "\n",
    "    for ax,  (pc1_idx, pc2_idx) in zip(axes, pc_combos):\n",
    "        pc1 = pca.components_[pc1_idx]\n",
    "        pc2 = pca.components_[pc2_idx]\n",
    "\n",
    "        min_pc1, max_pc1 = weights_reduced[:, pc1_idx].min(), weights_reduced[:, pc1_idx].max()\n",
    "        min_pc2, max_pc2 = weights_reduced[:, pc2_idx].min(), weights_reduced[:, pc2_idx].max()\n",
    "\n",
    "        pc1_lims = (min_pc1 - 0.1 * (max_pc1 - min_pc1), max_pc1 + 0.1 * (max_pc1 - min_pc1))\n",
    "        pc2_lims = (min_pc2 - 0.1 * (max_pc2 - min_pc2), max_pc2 + 0.1 * (max_pc2 - min_pc2))\n",
    "\n",
    "        get_pc_landscape(pca, weights_to_loss, pc1, pc2, pc1_lims, pc2_lims, num_points=num_points, ax=ax)\n",
    "\n",
    "        for chain in range(num_chains):\n",
    "            # _weights = pca.transform(deltas[chain])\n",
    "            _weights = weights_reduced[chain * num_draws:(chain + 1) * num_draws] \n",
    "            sns.scatterplot(x=_weights[:, pc1_idx], y=_weights[:, pc2_idx], ax=ax, s=2, alpha=0.2)\n",
    "\n",
    "        ax.set_xlim(*pc1_lims)\n",
    "        ax.set_ylim(*pc2_lims)\n",
    "\n",
    "        ax.set_title(f\"PC {pc1_idx + 1} vs PC {pc2_idx + 1}\")\n",
    "        ax.set_xlabel(f\"PC {pc1_idx + 1}\")\n",
    "        ax.set_ylabel(f\"PC {pc2_idx + 1}\")\n",
    "\n",
    "    # Plot explained variance\n",
    "    plot_explained_variance(pca, title=\"Explained Variance\", ax=axes[-1])        \n",
    "\n",
    "\n",
    "plot_weights_trace_fn(run.model, sampler.weights.deltas(), xs=xs, ys=ys, device=DEVICE, num_components=4, num_points=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mps.current_allocated_memory() / 1e9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient vectors\n",
    "\n",
    "Let's look at the delta in gradients at the kinks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [n for n, _ in run.model.named_parameters()]\n",
    "\n",
    "exp_avg_sq_grad_deltas = []\n",
    "\n",
    "kink_steps = highlight_steps\n",
    "\n",
    "for step in kink_steps:\n",
    "    i = steps.index(step)\n",
    "\n",
    "    opt_state_dict_curr = optimizer_state_dicts[i]\n",
    "\n",
    "    for (layer, g_curr) in opt_state_dict_curr[\"state\"].items():\n",
    "        exp_avg_sq_grad_deltas.append({\n",
    "            \"step\": step,\n",
    "            \"layer\": layer,\n",
    "            \"layer_name\": list(model.state_dict().keys())[layer],\n",
    "            \"exp_avg_sq_grad_sq_norm\": ((g_curr[\"exp_avg_sq\"]) ** 2).sum().item()\n",
    "        })\n",
    "\n",
    "\n",
    "exp_avg_sq_grad_deltas = pd.DataFrame(exp_avg_sq_grad_deltas)\n",
    "total_exp_avg_sq_grad_deltas = exp_avg_sq_grad_deltas.groupby('step').sum()\n",
    "exp_avg_sq_grad_deltas['exp_avg_sq_norm'] = exp_avg_sq_grad_deltas['exp_avg_sq_grad_sq_norm'] ** 0.5\n",
    "\n",
    "for step in kink_steps:\n",
    "    exp_avg_sq_grad_deltas.loc[exp_avg_sq_grad_deltas['step'] == step, 'exp_avg_sq_norm'] /= total_exp_avg_sq_grad_deltas.loc[step, 'exp_avg_sq_grad_sq_norm'] ** 0.5\n",
    "\n",
    "avg_exp_avg_sq_grad_deltas = exp_avg_sq_grad_deltas.groupby('step').mean()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "sns.lineplot(data=exp_avg_sq_grad_deltas, x=\"step\", y=\"exp_avg_sq_norm\", hue=\"layer_name\", palette=\"tab10\", ax=ax, alpha=0.5, legend=True)\n",
    "sns.lineplot(data=avg_exp_avg_sq_grad_deltas, x=\"step\", y=\"exp_avg_sq_norm\", ax=ax, color=BRED)\n",
    "ax.set_ylabel(\"Gradient Norm\")\n",
    "ax.set_xlabel(\"Step\")\n",
    "ax.set_title(\"Exponentially averaged gradient norms by Layer and Step\")\n",
    "# ax.legend().remove()\n",
    "\n",
    "plot_transitions(ax, TRANSITIONS, limit=True)\n",
    "\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_xlim(100, 500_000)   \n",
    "\n",
    "for step in highlight_steps:\n",
    "    print(\"=\" * 20 + f\" Step {step} \" + \"=\" * 20)\n",
    "    print(exp_avg_sq_grad_deltas.loc[exp_avg_sq_grad_deltas['step'] == step, ['layer_name', 'exp_avg_sq_norm']].sort_values(by='exp_avg_sq_norm', ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per-token LLCs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per-token Essential Dynamics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structural indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contributions from different layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contributions = []\n",
    "prev_state_dict = models[0].state_dict()\n",
    "\n",
    "for step, model in zip(steps[1:], models[1:]):\n",
    "    _contributions = []\n",
    "\n",
    "    for layer, param in model.state_dict().items():\n",
    "        w_sq_sum = (param ** 2).sum().item()\n",
    "        w_delta_sq_sum = ((param - prev_state_dict[layer]) ** 2).sum().item()\n",
    "        w_delta_sq_sum_normalized = w_delta_sq_sum / w_sq_sum\n",
    "\n",
    "        if w_sq_sum == float(\"inf\"):\n",
    "            continue\n",
    "\n",
    "        _contributions.append({\n",
    "            \"step\": step,\n",
    "            \"layer\": layer, \n",
    "            \"w_sq_sum\": w_sq_sum,\n",
    "            \"w_delta_sq_sum\": w_delta_sq_sum,\n",
    "            \"w_delta_sq_sum_normalized\": w_delta_sq_sum_normalized,\n",
    "            \"numel\": param.numel(),\n",
    "        })\n",
    "\n",
    "    total_w_delta_sq_sum = sum([c[\"w_delta_sq_sum\"] for c in _contributions])\n",
    "\n",
    "    for c in _contributions:\n",
    "        c[\"w_delta_sq_sum_frac\"] = (c[\"w_delta_sq_sum\"] / total_w_delta_sq_sum) ** 0.5\n",
    "\n",
    "    contributions.extend(_contributions)\n",
    "    prev_state_dict = model.state_dict()\n",
    "\n",
    "contributions = pd.DataFrame(contributions)\n",
    "contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = contributions.layer.unique()\n",
    "embed_layers = [layers[0], layers[1]]\n",
    "block0_layers = [layers[i] for i in range(2, 2 + 9)]\n",
    "block1_layers = [layers[i] for i in range(11, 11 + 9)]\n",
    "unembed_layers = [layers[i] for i in range(11 + 9, len(layers))]\n",
    "\n",
    "groupings = [embed_layers, block0_layers, block1_layers, unembed_layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(len(groupings), figsize=(10, 20))\n",
    "contributions[\"layer_name\"] = [\".\".join(n.split(\".\")[1:]) for n in contributions.layer]\n",
    "\n",
    "for ax, grouping in zip(axes, groupings):\n",
    "    sns.lineplot(data=contributions.loc[contributions.layer.isin(grouping)], x=\"step\", y=\"w_delta_sq_sum_frac\", hue=\"layer_name\", palette=\"deep\", ax=ax, alpha=0.8)\n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5), ncol=1, frameon=False)\n",
    "\n",
    "    # ax.legend().remove()\n",
    "    ax.set_xscale('log')\n",
    "\n",
    "\n",
    "# ax.set_yscale('log')\n",
    "plot_transitions(axes, TRANSITIONS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hessians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyhessian\n",
    "from pyhessian import hessian # Hessian computation\n",
    "\n",
    "xs, ys = xs.to('cpu'), ys.to('cpu')\n",
    "\n",
    "class ModelWrapper(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return self.model(inputs[0], inputs[1])\n",
    "    \n",
    "ref_model = ModelWrapper(deepcopy(models[-1]).to('cpu'))\n",
    "hessian_comp = hessian(ref_model, F.mse_loss, data=((xs, ys), ys), cuda=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_eig_wrapper(*args, eigenvectors=True, **kwargs):\n",
    "    # Call the new torch.linalg.eig function\n",
    "    eigenvalues, eigenvecs = torch.linalg.eig(*args, **kwargs)\n",
    "    \n",
    "    # Format the output to mimic the old torch.eig\n",
    "    # torch.eig used to return a tensor with [real, imaginary] parts for eigenvalues\n",
    "    # torch.linalg.eig returns a tensor of complex numbers for eigenvalues\n",
    "    eigenvalues_real = eigenvalues.real\n",
    "    eigenvalues_imag = eigenvalues.imag\n",
    "\n",
    "    eigenvalues_combined = torch.stack((eigenvalues_real, eigenvalues_imag), dim=-1)\n",
    "    return eigenvalues_combined, eigenvecs\n",
    "\n",
    "# Monkey patch the torch.eig function in the pyhessian module\n",
    "torch.eig = torch_eig_wrapper \n",
    "\n",
    "density_eigen, density_weight = hessian_comp.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From PyHessian\n",
    "\n",
    "def density_generate(eigenvalues,\n",
    "                     weights,\n",
    "                     num_bins=10000,\n",
    "                     sigma_squared=1e-5,\n",
    "                     overhead=0.01):\n",
    "\n",
    "    eigenvalues = np.array(eigenvalues)\n",
    "    weights = np.array(weights)\n",
    "\n",
    "    lambda_max = np.mean(np.max(eigenvalues, axis=1), axis=0) + overhead\n",
    "    lambda_min = np.mean(np.min(eigenvalues, axis=1), axis=0) - overhead\n",
    "\n",
    "    grids = np.linspace(lambda_min, lambda_max, num=num_bins)\n",
    "    sigma = sigma_squared * max(1, (lambda_max - lambda_min))\n",
    "\n",
    "    num_runs = eigenvalues.shape[0]\n",
    "    density_output = np.zeros((num_runs, num_bins))\n",
    "\n",
    "    for i in range(num_runs):\n",
    "        for j in range(num_bins):\n",
    "            x = grids[j]\n",
    "            tmp_result = gaussian(eigenvalues[i, :], x, sigma)\n",
    "            density_output[i, j] = np.sum(tmp_result * weights[i, :])\n",
    "    density = np.mean(density_output, axis=0)\n",
    "    normalization = np.sum(density) * (grids[1] - grids[0])\n",
    "    density = density / normalization\n",
    "    return density, grids\n",
    "\n",
    "\n",
    "def gaussian(x, x0, sigma_squared):\n",
    "    return np.exp(-(x0 - x)**2 /\n",
    "                  (2.0 * sigma_squared)) / np.sqrt(2 * np.pi * sigma_squared)\n",
    "\n",
    "def get_esd_plot(eigenvalues, weights, ax=None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "    density, grids = density_generate(eigenvalues, weights)\n",
    "    ax.semilogy(grids, density + 1.0e-7)\n",
    "    ax.set_ylabel('Density', fontsize=14, labelpad=10)\n",
    "    ax.set_xlabel('Eigenvalue', fontsize=14, labelpad=10)\n",
    "    # plt.axis([np.min(eigenvalues) - 1, np.max(eigenvalues) + 1, None, None])\n",
    "    ax.set_xscale('symlog')\n",
    "    plt.tight_layout()\n",
    "\n",
    "get_esd_plot(density_eigen, density_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_evals = []\n",
    "hessian_traces = []\n",
    "\n",
    "xs = xs.to('cpu')\n",
    "ys = ys.to('cpu')\n",
    "\n",
    "for model in tqdm.tqdm(models):\n",
    "    model = model.to('cpu')\n",
    "    ref_model = ModelWrapper(model)\n",
    "    hessian_comp = hessian(ref_model, F.mse_loss, data=((xs, ys), ys), cuda=False)\n",
    "\n",
    "    _top_evals, _ = hessian_comp.eigenvalues(top_n=3)\n",
    "    trace = hessian_comp.trace()\n",
    "\n",
    "    top_evals.append(_top_evals)\n",
    "    hessian_traces.append(trace)\n",
    "\n",
    "    model.to('mps')\n",
    "\n",
    "xs = xs.to('mps')\n",
    "ys = ys.to('mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densities_over_time = []\n",
    "\n",
    "xs = xs.to('cpu')\n",
    "ys = ys.to('cpu')\n",
    "\n",
    "INIT_STAGE = 3\n",
    "kink_steps = highlight_steps[INIT_STAGE:]\n",
    "stage_labels = [t[2] + f\" Start ({s})\" for s, t in zip(kink_steps, TRANSITIONS[INIT_STAGE:])] + [TRANSITIONS[-1][2] + f\" End ({kink_steps[-1]})\"]\n",
    "models_subset = [steps_to_models[step] for step in kink_steps]\n",
    "\n",
    "for step, model, label in tqdm.tqdm(zip(kink_steps, models_subset, stage_labels), total=len(kink_steps)):\n",
    "    print(step)\n",
    "    model = model.to('cpu')\n",
    "    ref_model = ModelWrapper(model)\n",
    "    hessian_comp = hessian(ref_model, F.mse_loss, data=((xs, ys), ys), cuda=False)\n",
    "    density_eigen, density_weight = hessian_comp.density()\n",
    "    densities_over_time.append((density_eigen, density_weight))\n",
    "\n",
    "    get_esd_plot(density_eigen, density_weight)\n",
    "    plt.title(label)\n",
    "    plt.show()\n",
    "\n",
    "    model.to('mps')\n",
    "\n",
    "xs = xs.to('mps')\n",
    "ys = ys.to('mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(len(densities_over_time), figsize=(10, 5 * len(densities_over_time)))\n",
    "\n",
    "min_eigen = min([min(density_eigen[0]) for density_eigen, _ in densities_over_time])\n",
    "max_eigen = max([max(density_eigen[0]) for density_eigen, _ in densities_over_time])\n",
    "\n",
    "print(min_eigen, max_eigen)\n",
    "\n",
    "for step, label, ax, (density_eigen, density_weight) in tqdm.tqdm(zip(kink_steps, stage_labels, axes, densities_over_time), total=len(kink_steps)):\n",
    "    get_esd_plot(density_eigen, density_weight, ax=ax)\n",
    "    # ax.set_yscale('linear')\n",
    "    ax.set_xlim(min_eigen, max_eigen)\n",
    "    ax.set_title(label)\n",
    "\n",
    "fig.set_facecolor('white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restricted Hessians\n",
    "\n",
    "Let's look at the Hessians within a few specific layers of the model. This will make it possible to study the full Hessian. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def compute_hessian_layer(model, loss, layer=None):\n",
    "    \"\"\"\n",
    "    Compute the Hessian matrix for a specific layer of a neural network model.\n",
    "\n",
    "    :param model: The neural network model (PyTorch).\n",
    "    :param loss_fn: The loss function.\n",
    "    :param input_tensor: Input tensor for the model.\n",
    "    :param target_tensor: Target tensor for computing the loss.\n",
    "    :param layer_name: The name of the layer for which to compute the Hessian.\n",
    "    :return: The Hessian matrix for the specified layer.\n",
    "    \"\"\"\n",
    "    # Ensure model is in eval mode for consistent forward pass\n",
    "    model.eval()\n",
    "\n",
    "    if layer is None:\n",
    "        layer = lambda m: [p for n, p in m.named_parameters() if not torch.any(torch.isnan(p))]\n",
    "\n",
    "    if isinstance(layer, str):\n",
    "        layer = lambda m: [p for n, p in m.named_parameters() if not torch.any(torch.isnan(p)) and layer in n]\n",
    "\n",
    "    # Get the parameters of the specified layer\n",
    "    layer_params = layer(model)\n",
    "\n",
    "    if not layer_params:\n",
    "        raise ValueError(f\"No parameters found for layer: {layer_name}\")\n",
    "\n",
    "    # Flatten the parameters and compute the first gradient\n",
    "    grads = torch.autograd.grad(loss, layer_params, create_graph=True)\n",
    "    grads_flatten = torch.cat([g.view(-1) for g in grads])\n",
    "\n",
    "    hessian = []\n",
    "\n",
    "    # Compute second derivatives (Hessian)\n",
    "    for grad in tqdm.tqdm(grads_flatten):\n",
    "        grad_grads = torch.autograd.grad(grad, layer_params, retain_graph=True)\n",
    "        grad_grads_flatten = torch.cat([g.view(-1) for g in grad_grads]).detach()\n",
    "        hessian.append(grad_grads_flatten)\n",
    "\n",
    "    # Convert the list of gradients to a tensor (Hessian matrix)\n",
    "    hessian = torch.stack(hessian)\n",
    "\n",
    "    return hessian\n",
    "\n",
    "# Example usage (assuming a model, loss function, input_tensor, target_tensor, and layer_name are defined)\n",
    "# hessian_matrix = compute_hessian_layer(model, loss_fn, input_tensor, target_tensor, layer_name)\n",
    "# print(hessian_matrix)\n",
    "\n",
    "# Note: This function doesn't execute the computation as it requires a specific model, loss function, input and target tensors, and layer name.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hessians_over_time = []\n",
    "hessian_evals_over_time = []\n",
    "hessian_evecs_over_time = []\n",
    "\n",
    "xs, ys = xs.to('cpu'), ys.to('cpu')\n",
    "\n",
    "def get_layer(model):\n",
    "    return list(model.token_sequence_transformer.blocks[BLOCK_IDX].attention.parameters())\n",
    "\n",
    "for step, model, label in tqdm.tqdm(zip(kink_steps, models_subset, stage_labels), total=len(kink_steps)):\n",
    "    model.to('cpu') \n",
    "    print(step)\n",
    "\n",
    "    model.zero_grad()\n",
    "    model.eval()\n",
    "\n",
    "    y_hats = model(xs, ys)\n",
    "    loss = F.mse_loss(y_hats, ys)\n",
    "    hessian = compute_hessian_layer(model, loss, get_layer)\n",
    "\n",
    "    evals, evecs = torch.linalg.eig(hessian)\n",
    "\n",
    "    hessians_over_time.append(hessian)\n",
    "    hessian_evals_over_time.append(evals)\n",
    "    hessian_evecs_over_time.append(evecs)\n",
    "\n",
    "    print(evals)\n",
    "    abs_evals = torch.abs(evals)\n",
    "    \n",
    "    # Plot eigenvalue density\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    ax.hist(abs_evals, bins=100, log=True)\n",
    "    plt.show()\n",
    "    \n",
    "    model.to('mps')\n",
    "\n",
    "xs = xs.to('mps')\n",
    "ys = ys.to('mps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametric Essential Dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try this for restricted subsets of weights as well\n",
    "\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "def extract_weights_over_checkpoints(models: Iterable[nn.Module], extract_weights: Callable = lambda m: [p.flatten() for p in m.parameters()], normalize=False):\n",
    "    for model in models:\n",
    "        weights = torch.cat(extract_weights(model)).detach().cpu().numpy()\n",
    "\n",
    "        if normalize:\n",
    "            weights /= np.linalg.norm(weights)\n",
    "\n",
    "        yield weights\n",
    "\n",
    "\n",
    "\n",
    "def get_pca_weights_trace(models: Iterable[nn.Module], extract_weights: Callable = lambda m: [p.flatten() for p in m.parameters()], num_components=3, normalize=False) -> Dict[str, Tuple[PCA, np.ndarray]]:\n",
    "    weights = np.array([w for w in extract_weights_over_checkpoints(models, extract_weights, normalize=normalize)])\n",
    "\n",
    "    pca = PCA(n_components=num_components)\n",
    "    weights_reduced = pca.fit_transform(weights)\n",
    "\n",
    "    return weights_reduced, pca\n",
    "\n",
    "all_weights, weights_pca = get_pca_weights_trace(models, num_components=3, normalize=False)\n",
    "\n",
    "plot_multiple_slices(\n",
    "    steps, \n",
    "    all_weights, \n",
    "    weights_pca, \n",
    "transitions,\n",
    "\n",
    "    transitions_of_steps,\n",
    "    connect_dots=True, \n",
    "    save=None,\n",
    ")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_embedding_weights = lambda m: [p.flatten() for p in m.token_sequence_transformer.token_embedding.parameters()]\n",
    "extract_unembedding_weights = lambda m: [p.flatten() for p in m.token_sequence_transformer.unembedding[1].parameters()]\n",
    "extract_embedding_unembedding_weights = lambda m: [p.flatten() for p in m.token_sequence_transformer.token_embedding.parameters()] + [p.flatten() for p in m.token_sequence_transformer.unembedding[1].parameters()]\n",
    "extract_block_0_weights = lambda m: [p.flatten() for p in m.token_sequence_transformer.blocks[0].parameters()]\n",
    "extract_block_1_weights = lambda m: [p.flatten() for p in m.token_sequence_transformer.blocks[1].parameters()]\n",
    "extract_lns = lambda m: [m.state_dict()[f\"{ln}.{part}\"] for ln in layer_norms for part in [\"weight\", \"bias\"]]\n",
    "extract_mlp_0 = lambda m: [p.flatten() for p in m.token_sequence_transformer.blocks[0].compute[0].parameters()] + [p.flatten() for p in m.token_sequence_transformer.blocks[0].compute[2].parameters()]\n",
    "extract_mlp_1 = lambda m: [p.flatten() for p in m.token_sequence_transformer.blocks[1].compute[0].parameters()] + [p.flatten() for p in m.token_sequence_transformer.blocks[1].compute[2].parameters()]\n",
    "extract_attn_0 = lambda m: [p.flatten() for p in m.token_sequence_transformer.blocks[0].attention.attention.parameters()]\n",
    "extract_attn_1 = lambda m: [p.flatten() for p in m.token_sequence_transformer.blocks[1].attention.attention.parameters()]\n",
    "\n",
    "extract_weights_fns = {\n",
    "    \"Embedding & Unembedding\": extract_embedding_unembedding_weights, \n",
    "    \"Unembedding\": extract_unembedding_weights, \n",
    "    \"Embedding\": extract_embedding_weights, \n",
    "    \"Block 0\": extract_block_0_weights, \n",
    "    \"Block 1\": extract_block_1_weights, \n",
    "    \"Layer norms\": extract_lns,\n",
    "    \"MLP 0\": extract_mlp_0,\n",
    "    \"MLP 1\": extract_mlp_1,\n",
    "    \"Attention 0\": extract_attn_0,\n",
    "    \"Attention 1\": extract_attn_1,\n",
    "}\n",
    "\n",
    "for label, extract_weights in extract_weights_fns.items():\n",
    "    print(label)\n",
    "\n",
    "    for normalize in [False, True]:\n",
    "        print(f\"Normalize: {normalize}\")\n",
    "        subset_weights, weights_pca = get_pca_weights_trace(models, num_components=3, extract_weights=extract_weights, normalize=normalize)\n",
    "\n",
    "        plot_multiple_slices(\n",
    "            steps, \n",
    "            subset_weights, \n",
    "            weights_pca, \n",
    "            highlight_steps,\n",
    "            transitions_of_steps,\n",
    "            connect_dots=True, \n",
    "            save=None,\n",
    "        )\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = run.checkpointer.file_ids\n",
    "embedding_matrices = []  # Shape: (64, 5): 64 vectors x (1 y dim + 4 x dims)\n",
    "\n",
    "for model in models:\n",
    "    embedding_matrices.append(model.state_dict()['token_sequence_transformer.token_embedding.weight'])\n",
    "\n",
    "\n",
    "embedding_vec_x_norms = [vec.norm(dim=1) for vec in embedding_matrices]  # (64,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA explained Variance over time\n",
    "pcas = []\n",
    "\n",
    "for model in models:\n",
    "    embed = model.token_sequence_transformer.token_embedding.weight.detach().cpu().numpy()\n",
    "    pca = PCA(n_components=embed.shape[1])\n",
    "    proj = pca.fit_transform(embed)[:,:3]\n",
    "    pcas.append((proj, pca))\n",
    "\n",
    "explained_variances = [{\"value\": value, \"index\": idx, \"step\": step} for step, (_, pca) in zip(steps, pcas) for idx, value in enumerate(pca.explained_variance_ratio_)]\n",
    "explained_variances = pd.DataFrame(explained_variances)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.lineplot(data=explained_variances, x=\"step\", y=\"value\", hue=\"index\", palette=\"viridis\", ax=ax)\n",
    "ax.legend(title=\"Component\", loc='upper left')\n",
    "ax.set_xscale('log')\n",
    "ax.set_title(\"Explained Variance of Embedding Vector PCA over Time\")\n",
    "ax.set_ylabel(\"Explained Variance\")\n",
    "ax.set_xlabel(\"Step, $t$\")\n",
    "\n",
    "fig.set_facecolor('white')\n",
    "plot_transitions(ax, TRANSITIONS, limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the final PCA\n",
    "\n",
    "def compute_explained_variance(pca, embed):\n",
    "    proj = pca.transform(embed)\n",
    "\n",
    "    # Step 4 and 5: Compute variance of projected data and total variance\n",
    "    variance_projected = np.var(proj, axis=0)\n",
    "    total_variance = np.sum(variance_projected)\n",
    "\n",
    "    # Step 6: Calculate explained variance ratio\n",
    "    explained_variance_ratio = variance_projected / total_variance\n",
    "\n",
    "    return explained_variance_ratio\n",
    "\n",
    "explained_variances_rel_last_pca = [{\"value\": value, \"index\": idx, \"step\": step} for step, embed in zip(steps, embedding_matrices) for idx, value in enumerate(compute_explained_variance(pcas[-1][-1], embed.detach().cpu().numpy()))]\n",
    "explained_variances_rel_last_pca = pd.DataFrame(explained_variances_rel_last_pca)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.lineplot(data=explained_variances_rel_last_pca, x=\"step\", y=\"value\", hue=\"index\", palette=\"viridis\", ax=ax)\n",
    "ax.legend(title=\"Component\", loc='upper left')\n",
    "\n",
    "ax.set_xscale('log')\n",
    "ax.set_title(\"Explained Variance of Embedding Vector PCA over Time\")\n",
    "ax.set_ylabel(\"Explained Variance\")\n",
    "ax.set_xlabel(\"Step, $t$\")\n",
    "\n",
    "fig.set_facecolor('white')\n",
    "\n",
    "plot_transitions(ax, TRANSITIONS, limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's project embedding vectors onto these pca components and track their evolution\n",
    "last_pca = pcas[-1][-1]\n",
    "transformed = [last_pca.transform(embed.detach().cpu().numpy()) for embed in embedding_matrices]\n",
    "transition_middles = [get_nearest_step((t[0] + t[1]) * 0.5) for t in TRANSITIONS]\n",
    "\n",
    "fig, axes = plt.subplots(1, len(transition_middles), figsize=(20, 5))\n",
    "\n",
    "min_x, max_x = 0, 0\n",
    "min_y, max_y = 0, 0\n",
    "\n",
    "for ax, middle in zip(axes, transition_middles):\n",
    "    middle_idx = steps.index(middle)\n",
    "    middle_embeddings = transformed[middle_idx]\n",
    "    sns.scatterplot(data=pd.DataFrame(middle_embeddings), x=0, y=1, ax=ax)\n",
    "    ax.set_title(f\"Step {middle}\")\n",
    "\n",
    "    min_x = min(min_x, middle_embeddings[:, 0].min())\n",
    "    max_x = max(max_x, middle_embeddings[:, 0].max())\n",
    "    min_y = min(min_y, middle_embeddings[:, 1].min())\n",
    "    max_y = max(max_y, middle_embeddings[:, 1].max())\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xlim(min_x * 1.25, max_x * 1.25)\n",
    "    ax.set_ylim(min_y * 1.25, max_y * 1.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "# Assuming 'pcas', 'embedding_matrices', 'TRANSITIONS', and 'steps' are defined as in your context.\n",
    "\n",
    "last_pca = pcas[-1][-1]\n",
    "transformed = [last_pca.transform(embed.detach().cpu().numpy()) for embed in embedding_matrices]\n",
    "transition_middles = [get_nearest_step((t[0] + t[1]) * 0.5) for t in TRANSITIONS]\n",
    "\n",
    "min_x, max_x = min([t[:, 0].min() for t in transformed]), max([t[:, 0].max() for t in transformed])\n",
    "min_y, max_y = min([t[:, 1].min() for t in transformed]), max([t[:, 1].max() for t in transformed])\n",
    "\n",
    "# Set up the figure.\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "plt.xlim(min_x * 1.25, max_x * 1.25)\n",
    "plt.ylim(min_y * 1.25, max_y * 1.25)\n",
    "scat = ax.scatter([], [])\n",
    "\n",
    "# Update function for the animation.\n",
    "def update(frame):\n",
    "    middle_embeddings = transformed[frame]\n",
    "    ax.clear()\n",
    "    ax.set_xlim(min_x * 1.25, max_x * 1.25)\n",
    "    ax.set_ylim(min_y * 1.25, max_y * 1.25)\n",
    "    ax.set_title(f\"Step {steps[frame]}\")\n",
    "    sns.scatterplot(data=pd.DataFrame(middle_embeddings), x=0, y=1, ax=ax)\n",
    "\n",
    "# Create the animation.\n",
    "ani = FuncAnimation(fig, update, frames=range(len(steps)), repeat=False)\n",
    "\n",
    "# To save the animation, you can use the following line:\n",
    "ani.save(FIGURES / 'M1-embed.mp4', writer='ffmpeg', fps=1)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unembedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unembeddings = []\n",
    "\n",
    "for step, model in zip(steps, models):\n",
    "    for subset in [\"weight\", \"bias\"]:\n",
    "        layer = f\"ln.{subset}\"\n",
    "        for i, param in enumerate(getattr(model.token_sequence_transformer.unembedding[0], subset)):\n",
    "            unembeddings.append({\"p\": param.item(), \"step\": step, \"layer\": layer, \"i\": i})\n",
    "\n",
    "        layer = f\"linear.{subset}\"\n",
    "        layer_param = getattr(model.token_sequence_transformer.unembedding[1], subset)\n",
    "        if subset == \"weight\":\n",
    "            layer_param = layer_param[0, :]\n",
    "            for i, param in enumerate(layer_param):\n",
    "                unembeddings.append({\"p\": param.item(), \"step\": step, \"layer\": layer, \"i\": i})\n",
    "        else:\n",
    "            layer_param = layer_param[0]\n",
    "            unembeddings.append({\"p\": layer_param.item(), \"step\": step, \"layer\": layer, \"i\": 0})\n",
    "\n",
    "\n",
    "unembeddings = pd.DataFrame(unembeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(20, 10))\n",
    "\n",
    "for i, layer in enumerate([\"ln\", \"linear\"]):\n",
    "    for j, layer_subset in enumerate([\"weight\", \"bias\"]):\n",
    "        sns.lineplot(data=unembeddings.loc[unembeddings.layer == f\"{layer}.{layer_subset}\"], x=\"step\", y=\"p\", hue=\"i\", palette=\"viridis\", ax=axes[i, j], alpha=0.25)\n",
    "        axes[i, j].legend().remove()\n",
    "        axes[i, j].set_xscale('log')\n",
    "        axes[i, j].set_title(f\"{layer}.{layer_subset}\")\n",
    "\n",
    "        axes[i, j].set_xlim(200, 500000)\n",
    "\n",
    "\n",
    "fig.suptitle(\"Unembedding Weights over Time\", fontsize=20)\n",
    "\n",
    "plot_transitions(axes, TRANSITIONS);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given $z$, the activations in the residual stream right before the unembedding, a 64-dimensional vector (per token). \n",
    "\n",
    "The unembedding performs the following operation: \n",
    "\n",
    "$$\n",
    "\\pi_y \\left[ W_U \\cdot \\left( \\frac{z-\\mathbb E[z]}{\\sqrt{\\mathbb V[z] + \\epsilon}} * \\gamma + \\beta \\right) + b_U \\right].\n",
    "$$\n",
    "\n",
    "This can be rewritten as follows:\n",
    "\n",
    "$$\n",
    "\\left((W_U)_{[0, :]} * \\gamma \\right) \\cdot \\left(\\frac{z-\\mathbb E[z]}{\\sqrt{\\mathbb V[z] + \\epsilon}}\\right) + \\left((W_U)_{[0, :]} \\cdot \\beta\\right) + (b_U)_{[0]}\n",
    "$$\n",
    "\n",
    "Let's look at these \"reduced\" weights instead:\n",
    "$$\n",
    "\\tilde W_U = (W_U)_{[0, :]} * \\gamma,\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\tilde b_U = \\left((W_U)_{[0, :]} \\cdot \\beta\\right) + (b_U)_{[0]}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do you get around the $\\mathbb E[z]$? (For now, assume that $\\mathbb V[z]=1-\\epsilon$).\n",
    "Answer: You make sure that $\\mathbb E[z] = 0$. \n",
    "\n",
    "Let's look at two possible implementations:\n",
    "\n",
    "**1: One-hot $z$**\n",
    "\n",
    "Suppose $z$ contains mostly balanced white noise. The signal (which we'll read the final prediction from) is contained in a single dimension $j$. \n",
    "Then, from the perspective of the average, we can view $z$ as a 1-hot vector, \n",
    "\n",
    "$$\n",
    "z_i = z_j \\delta_{ij}.\n",
    "$$\n",
    "\n",
    "Then, the average is\n",
    "\n",
    "$$\n",
    "\\mathbb E[z] = \\frac{1}{d_E} \\sum_{j=1}^{d_E} z_j = \\frac{1}{M} z_i,\n",
    "$$\n",
    "\n",
    "where $d_E=64$ is the dimension of the embedding / residual stream, and \n",
    "\n",
    "$$\n",
    "z - \\mathbb E[z] =  z_j \\left(1 - \\frac{1}{d_E}\\right) \\delta_{ij}.\n",
    "$$\n",
    "\n",
    "By setting $\\gamma_j = \\frac{d_E}{d_E-1}$, and we're able to read out the prediction. \n",
    "\n",
    "**2: Balanced $z$**\n",
    "\n",
    "Again, assume that most components of $z$ contain balanced white noise. This time, however, we assume the signal is contained in two dimensions, $j$ and $k$. Assume that the signal is encoded with opposite magnitudes:\n",
    "\n",
    "$$\n",
    "z_i = z_j (\\delta_{ij} - \\delta_{ik}).\n",
    "$$\n",
    "\n",
    "Then, the average is:\n",
    "\n",
    "$$\n",
    "\\mathbb E[z] = z_j \\left(1 - 1\\right) / d_E = 0.\n",
    "$$\n",
    "\n",
    "**During B2, we see a transition from (2) to (1).**\n",
    "\n",
    "And if you look back further, we see additional transitions of this kind, where we have two negatively encoded signals that collapse together. \n",
    "\n",
    "Okay but why?\n",
    "\n",
    "**Now, let's reintroduce the $\\mathbb V[z]$ term.**\n",
    "\n",
    "The problem with this term is that the input $x$ does not have a fixed norm, so the variance depends on $\\mathbb V[x]$. \n",
    "The key observation is that we can set several extra dimensions in the residual stream to values that are arbitraily large in value. \n",
    "\n",
    "That is, by increasing the variance of the white noise contributions, we can suppress the contribution of the variance of the input and set $\\mathbb V[z]$ to an arbitrary fixed value $v$ that we can cancel out with $\\gamma$. \n",
    "\n",
    "Because (2) has the signal redundantly encoded, the contribution from $\\mathbb V[x]$ is larger. So we can reduce the loss by changing to (1). \n",
    "But this also increases the degeneacy! As soon as $z_k$ no longer contains a signal, it can freely mix with all the other white noise contributions. We move from a set of $O(d_E-2)$ symmetries to a set of $O(d_E-1)$ symmetries.\n",
    "\n",
    "Unfortunately, this transition doesn't have a Bayesian antecedent. Or does it? Remember, the $\\gamma_i$ in the layer norm are initialized at $1$. So it's still very much possible that we have an \"A-B\" transition in which both loss and learning coefficient decrease in exchange for a significant increase in the prior contribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_unembeddings = []\n",
    "\n",
    "for step, model in zip(steps, models):\n",
    "    reduced_weight = model.token_sequence_transformer.unembedding[1].weight[0, :] * model.token_sequence_transformer.unembedding[0].weight\n",
    "    reduced_bias = model.token_sequence_transformer.unembedding[1].weight[0, :] @ model.token_sequence_transformer.unembedding[0].bias + model.token_sequence_transformer.unembedding[1].bias[0]\n",
    "\n",
    "    for i, param in enumerate(reduced_weight):\n",
    "        reduced_unembeddings.append({\"p\": param.item(), \"subset\": \"weight\", \"step\": step,  \"i\": i})\n",
    "\n",
    "    reduced_unembeddings.append({\"p\": reduced_bias.item(), \"subset\": \"bias\", \"step\": step,  \"i\": 0})\n",
    "\n",
    "reduced_unembeddings = pd.DataFrame(reduced_unembeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(20, 5))\n",
    "\n",
    "\n",
    "ax = axes[0]\n",
    "sns.lineplot(data=reduced_unembeddings.loc[reduced_unembeddings.subset == \"weight\"], x=\"step\", y=\"p\", hue=\"i\", palette=\"viridis\", ax=ax, alpha=0.25)\n",
    "ax.set_title(f\"{layer}.{layer_subset}\")\n",
    "\n",
    "ax = axes[1]\n",
    "sns.lineplot(data=reduced_unembeddings.loc[reduced_unembeddings.subset == \"bias\"], x=\"step\", y=\"p\", hue=\"i\", palette=\"viridis\", ax=ax)\n",
    "\n",
    "for ax in axes:\n",
    "    ax.legend().remove()\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_title(f\"Reduced {layer_subset}\")\n",
    "    ax.set_xlim(200, 500000)\n",
    "\n",
    "plot_transitions(axes, TRANSITIONS);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero ablations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_stats = []\n",
    "\n",
    "for step, model in zip(steps, models):\n",
    "    state_dict = model.state_dict()\n",
    "\n",
    "    bias_stats.append({\n",
    "        \"step\": step,\n",
    "        \"postn_embedding_norm\": state_dict[\"token_sequence_transformer.postn_embedding.weight\"].norm().item(),\n",
    "        \"unembedding_ln_bias_norm\": state_dict[\"token_sequence_transformer.unembedding.0.bias\"].norm().item(),    \n",
    "    })\n",
    "\n",
    "bias_stats = pd.DataFrame(bias_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postn_embeddings = []\n",
    "unembedding_biases = []\n",
    "\n",
    "for step, model in zip(steps, models):\n",
    "    state_dict = model.state_dict()\n",
    "\n",
    "    _postn_embedding = state_dict[\"token_sequence_transformer.postn_embedding.weight\"]\n",
    "\n",
    "    for i, p in enumerate(_postn_embedding):\n",
    "        postn_embeddings.append({\n",
    "            \"step\": step,\n",
    "            \"postn_embedding_0\": p[0].item(),\n",
    "            \"idx\": i,\n",
    "            \"postn_embedding_x_std\": p[::2].std().item(),\n",
    "            \"postn_embedding_x_mean\": p[::2].mean().item(),\n",
    "            \"postn_embedding_y_std\": p[1::2].std().item(),\n",
    "            \"postn_embedding_y_mean\": p[1::2].mean().item(),\n",
    "        })\n",
    "\n",
    "    _unembedding_bias = state_dict[\"token_sequence_transformer.unembedding.0.bias\"]\n",
    "    for i, p in enumerate(_unembedding_bias):\n",
    "        unembedding_biases.append({\n",
    "            \"step\": step,\n",
    "            \"unembedding_bias\": p.item(),\n",
    "            \"idx\": i\n",
    "        })\n",
    "\n",
    "postn_embeddings = pd.DataFrame(postn_embeddings)\n",
    "unembedding_biases = pd.DataFrame(unembedding_biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(20, 2))\n",
    "\n",
    "axes[0].matshow(models[-1].token_sequence_transformer.postn_embedding.weight[:, ::2].T.detach().cpu().numpy(), aspect=\"auto\")\n",
    "axes[1].matshow(models[-1].token_sequence_transformer.postn_embedding.weight[:, 1::2].T.detach().cpu().numpy(), aspect=\"auto\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "ax.matshow(models[-1].token_sequence_transformer.unembedding[0].bias.reshape((1, 64)).detach().cpu().numpy(), aspect=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(20, 5))\n",
    "\n",
    "ax = axes[0]\n",
    "# sns.lineplot(data=bias_stats, x=\"step\", y=\"postn_embedding_norm\", ax=ax)\n",
    "sns.lineplot(data=postn_embeddings, x=\"step\", y=\"postn_embedding_0\", hue=\"idx\", palette=\"gray\", ax=ax, alpha=0.5)\n",
    "\n",
    "ax.set_xscale(\"log\")\n",
    "\n",
    "ax = axes[1]\n",
    "# sns.lineplot(data=bias_stats, x=\"step\", y=\"unembedding_ln_bias_norm\", ax=ax)\n",
    "sns.lineplot(data=unembedding_biases, x=\"step\", y=\"unembedding_bias\", hue=\"idx\", palette=\"gray\", ax=ax, alpha=0.5)\n",
    "ax.set_xscale(\"log\")\n",
    "\n",
    "plot_transitions(axes, TRANSITIONS, limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import patches\n",
    "from icl.model import to_token_sequence, from_predicted_token_sequence\n",
    "\n",
    "class EmbedUnembedOnlyV2(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.to_token_sequence = to_token_sequence\n",
    "        self.token_embedding = model.token_sequence_transformer.token_embedding\n",
    "        self.positional_embedding = model.token_sequence_transformer.postn_embedding\n",
    "        self.unembedding = model.token_sequence_transformer.unembedding\n",
    "        self.from_predicted_token_sequence = from_predicted_token_sequence\n",
    "\n",
    "    def forward(self, xs, ys):\n",
    "        tokens = self.to_token_sequence(xs, ys)\n",
    "\n",
    "        T = tokens.shape[1]\n",
    "        x = self.token_embedding(tokens) # + self.positional_embedding.weight.T[:T, :]\n",
    "        # Set everything to zero except for dimensions 46 and 51\n",
    "        # embedded[:, :, :46] = 0\n",
    "        # embedded[:, :, 47:51] = 0\n",
    "        # embedded[:, :, 52:] = 0\n",
    "\n",
    "        x = self.unembedding[0](x)\n",
    "        unembedded = self.unembedding[1](x)\n",
    "\n",
    "        # raise ValueError(\"Done\")\n",
    "    \n",
    "        return self.from_predicted_token_sequence(unembedded)\n",
    "\n",
    "\n",
    "# embed_unembed_only_model = EmbedUnembedOnly(run.model)\n",
    "\n",
    "def get_embed_unembed_with_bias(model, multiplier=1.):\n",
    "    eu_model = EmbedUnembedOnlyV2(model).to('cpu')\n",
    "\n",
    "    w = np.zeros(4)\n",
    "    basis = torch.eye(4, device=\"cpu\") * multiplier\n",
    "    ys = torch.zeros(1, 1, 1, device=\"cpu\") \n",
    "\n",
    "    for i in range(4):\n",
    "        w[i] = eu_model(basis[i].unsqueeze(0).unsqueeze(0), ys)[0].item()\n",
    "\n",
    "    return w\n",
    "\n",
    "\n",
    "embed_unembed_with_bias = [\n",
    "    get_embed_unembed_with_bias(model, 10)\n",
    "    for model in models\n",
    "]\n",
    "\n",
    "print(embed_unembed_with_bias[0].shape, task_embed.shape)\n",
    "\n",
    "cossims = [\n",
    "    (v @ task_np) / (np.linalg.norm(v) * np.linalg.norm(task_np)) for v in embed_unembed_with_bias\n",
    "]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "ax.plot(run.checkpointer.file_ids, cossims)\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_xlabel(\"step\")\n",
    "ax.set_ylabel(r\"Cosine similarity with $w_1$\")\n",
    "ax.set_title(\"Effective weight using only embedding (token only), unembedding (linear only), with biases\")\n",
    "\n",
    "# plt.legend(loc='lower left')\n",
    "plot_transitions(ax, TRANSITIONS)\n",
    "fig.set_facecolor('white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[0].state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from icl.analysis.slt import prepend_keys\n",
    "\n",
    "layer_norms = [\n",
    "    \"token_sequence_transformer.unembedding.0\",\n",
    "    \"token_sequence_transformer.blocks.0.layer_norms.0\",\n",
    "    \"token_sequence_transformer.blocks.0.layer_norms.1\",\n",
    "    \"token_sequence_transformer.blocks.1.layer_norms.0\",\n",
    "    \"token_sequence_transformer.blocks.1.layer_norms.1\",\n",
    "]\n",
    "\n",
    "list(model.state_dict().keys())\n",
    "\n",
    "def get_ln(model, key):\n",
    "    return (model.state_dict()[f'{key}.weight'], model.state_dict()[f'{key}.bias'])\n",
    "\n",
    "unembedding_lns = [get_ln(model, 'token_sequence_transformer.unembedding.0') for model in models]\n",
    "block_1_attn_lns =  [get_ln(model, 'token_sequence_transformer.blocks.0.layer_norms.0') for model in models]\n",
    "block_1_mlp_lns =  [get_ln(model, 'token_sequence_transformer.blocks.0.layer_norms.1') for model in models]\n",
    "block_2_attn_lns =  [get_ln(model, 'token_sequence_transformer.blocks.1.layer_norms.0') for model in models]\n",
    "block_2_mlp_lns =  [get_ln(model, 'token_sequence_transformer.blocks.1.layer_norms.1') for model in models]\n",
    "\n",
    "def ln_norm(weight, bias):\n",
    "    return torch.norm(weight).detach().cpu().numpy()\n",
    "\n",
    "def ln_norm_std(weight, bias):\n",
    "    return torch.std(weight.abs()).detach().cpu().numpy()\n",
    "\n",
    "unembedding_ln_norms = [ln_norm(weight, bias) for weight, bias in unembedding_lns]\n",
    "block_1_attn_ln_norms = [ln_norm(weight, bias) for weight, bias in block_1_attn_lns]\n",
    "block_1_mlp_ln_norms = [ln_norm(weight, bias) for weight, bias in block_1_mlp_lns]\n",
    "block_2_attn_ln_norms = [ln_norm(weight, bias) for weight, bias in block_2_attn_lns]\n",
    "block_2_mlp_ln_norms = [ln_norm(weight, bias) for weight, bias in block_2_mlp_lns]\n",
    "\n",
    "unembedding_ln_norms_std = np.array([ln_norm_std(weight, bias) for weight, bias in unembedding_lns])\n",
    "block_1_attn_ln_norms_std = np.array([ln_norm_std(weight, bias) for weight, bias in block_1_attn_lns])\n",
    "block_1_mlp_ln_norms_std = np.array([ln_norm_std(weight, bias) for weight, bias in block_1_mlp_lns])\n",
    "block_2_attn_ln_norms_std = np.array([ln_norm_std(weight, bias) for weight, bias in block_2_attn_lns])\n",
    "block_2_mlp_ln_norms_std = np.array([ln_norm_std(weight, bias) for weight, bias in block_2_mlp_lns])\n",
    "\n",
    "def frac_nonzero(weight, eps=1e-1):\n",
    "    return (weight.abs() > eps).float().mean().detach().cpu().numpy()\n",
    "\n",
    "unembedding_ln_norm_nonzero = [frac_nonzero(weight) for weight, bias in unembedding_lns]\n",
    "block_1_attn_ln_norm_nonzero = [frac_nonzero(weight) for weight, bias in block_1_attn_lns]\n",
    "block_1_mlp_ln_norm_nonzero = [frac_nonzero(weight) for weight, bias in block_1_mlp_lns]\n",
    "block_2_attn_ln_norm_nonzero = [frac_nonzero(weight) for weight, bias in block_2_attn_lns]\n",
    "block_2_mlp_ln_norm_nonzero = [frac_nonzero(weight) for weight, bias in block_2_mlp_lns]\n",
    "\n",
    "ln_stats = []\n",
    "\n",
    "def get_stats(weight):\n",
    "    return {\n",
    "        \"norm\": weight.norm().item(),\n",
    "        \"norm_std\": weight.abs().std().item(),\n",
    "        \"std\": weight.std().item(),\n",
    "        \"mean\": weight.mean().item(),\n",
    "        \"max\": weight.max().item(),\n",
    "        \"min\": weight.min().item(),\n",
    "    }\n",
    "    \n",
    "\n",
    "for step, model in zip(steps, models):\n",
    "    for layer in [\"unembedding.0\", \"blocks.0.layer_norms.0\", \"blocks.0.layer_norms.1\", \"blocks.1.layer_norms.0\", \"blocks.1.layer_norms.1\"]:\n",
    "        weight, bias = get_ln(model, f\"token_sequence_transformer.{layer}\")\n",
    "\n",
    "        ln_stats.append({\n",
    "            \"step\": step,\n",
    "            \"layer\": layer,\n",
    "            \"layer_pretty\": layer.replace(\"_\", \" \").title(),\n",
    "            **prepend_keys(get_stats(weight), \"weight\"),\n",
    "            **prepend_keys(get_stats(bias), \"bias\"),\n",
    "        })\n",
    "\n",
    "ln_stats = pd.DataFrame(ln_stats)\n",
    "ln_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(20, 6))\n",
    "\n",
    "# Fill between using the std\n",
    "for i, type_ in enumerate([\"weight\", \"bias\"]):\n",
    "    sns.lineplot(data=ln_stats, x=\"step\", y=f\"{type_}/norm\", hue=\"layer\", palette=\"deep\", ax=axes[i])\n",
    "\n",
    "    for layer in ln_stats.layer.unique():\n",
    "        layer_ln_stats = ln_stats.loc[ln_stats.layer == layer]\n",
    "        axes[i].fill_between(steps, layer_ln_stats[f\"{type_}/norm\"] - layer_ln_stats[f\"{type_}/norm_std\"], layer_ln_stats[f\"{type_}/norm\"] + layer_ln_stats[f\"{type_}/norm_std\"], alpha=0.2)\n",
    "\n",
    "for ax in axes.flatten():\n",
    "    ax.legend(title=\"Layer\", loc='lower left')\n",
    "    plot_transitions(ax, TRANSITIONS)\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "    # ax.set_xlim(100, 500_000)\n",
    "\n",
    "axes[0].set_title(\"Layer Norm Weight Norms over Time\")\n",
    "axes[0].set_title(\"Layer Norm Bias Norms over Time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lns = {\n",
    "    \"Unembedding\": unembedding_lns,\n",
    "    \"Block 1 Attention\": block_1_attn_lns,\n",
    "    \"Block 1 MLP\": block_1_mlp_lns,\n",
    "    \"Block 2 Attention\": block_2_attn_lns,\n",
    "    \"Block 2 MLP\": block_2_mlp_lns,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(len(all_lns), 2, figsize=(20, 30))\n",
    "\n",
    "for i, (name, lns) in enumerate(all_lns.items()):\n",
    "    axes[i, 0].plot(steps, np.array([w.detach().cpu().numpy() for w, b in lns]), alpha=0.25)\n",
    "    axes[i, 1].plot(steps, np.array([b.detach().cpu().numpy() for w, b in lns]), alpha=0.25)\n",
    "\n",
    "    axes[i, 0].set_title(f\"{name} LN Weight\")\n",
    "    axes[i, 1].set_title(f\"{name} LN Bias\")\n",
    "\n",
    "plot_transitions(axes, TRANSITIONS)\n",
    "\n",
    "for ax in axes.flatten():\n",
    "    ax.set_xscale('log')\n",
    "    # ax.set_yscale('symlog')\n",
    "    ax.set_xlim(100, 500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"Unembed\", \"Block 1 Attn\", \"Block 1 MLP\", \"Block 2 Attn\", \"Block 2 MLP\"]\n",
    "\n",
    "for i, lns in enumerate([unembed_lns, block_1_attn_lns, block_1_mlp_lns, block_2_attn_lns, block_2_mlp_lns]):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(20, 5))\n",
    "\n",
    "    label = labels[i]\n",
    "    lns_df = pd.DataFrame([{\"step\": step, \"idx\": i, \"weight\": weight.item(), \"bias\": bias.item()} for step, (weights, biases) in zip(steps, lns) for i, (weight, bias) in enumerate(zip(weights, biases))])\n",
    "\n",
    "    ax = axes[0]\n",
    "    # inset_ax_1 = ax.inset_axes([0.1, 0.1, 0.4, 0.4])\n",
    "\n",
    "    sns.lineplot(data=lns_df, x=\"step\", y=\"weight\", color=PRIMARY, ax=ax)\n",
    "    # sns.lineplot(data=lns_df, x=\"step\", y=\"weight\", hue=\"idx\", palette=\"gray\", ax=inset_ax_1, alpha=0.1)\n",
    "    ax.set_title(f\"{label} Layer Norm Weights over Time\")\n",
    "    ax.set_ylabel(\"$u_i$\")\n",
    "    ax.set_xlim(100, 500_000)\n",
    "    \n",
    "    ax = axes[1]\n",
    "    # inset_ax_2 = ax.inset_axes([0.1, 0.1, 0.4, 0.4])\n",
    "\n",
    "    sns.lineplot(data=lns_df, x=\"step\", y=\"bias\", color=PRIMARY, ax=ax)\n",
    "    # sns.lineplot(data=lns_df, x=\"step\", y=\"bias\", hue=\"idx\", palette=\"gray\", ax=inset_ax_2, alpha=0.1)\n",
    "    ax.set_title(f\"{label} Layer Norm Biases over Time\")\n",
    "    ax.set_ylabel(\"$\\mathrm{unembed bias}_i$\")\n",
    "    ax.set_xlim(100, 500_000)\n",
    "    \n",
    "    plot_transitions(axes, TRANSITIONS, limit=True)\n",
    "    # plot_transitions(np.array([inset_ax_1, inset_ax_2]), TRANSITIONS, limit=True)\n",
    "\n",
    "    for ax in axes:\n",
    "        ax.set_xlabel(\"Step, $t$\")\n",
    "        ax.set_xscale('log')\n",
    "        \n",
    "    # for ax in [inset_ax_1, inset_ax_2]:\n",
    "    #     ax.legend().remove()\n",
    "\n",
    "    # for ax in [*axes, inset_ax_1, inset_ax_2]:\n",
    "    #     ax.set_xscale('log')\n",
    "\n",
    "    fig.set_facecolor('white')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention Entropies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from typing import List, Union, Iterable, Optional\n",
    "from torchtyping import TensorType\n",
    "from devinfra.utils.iterables import map_nested\n",
    "\n",
    "from icl.experiments.utils import iter_models\n",
    "from devinfra.utils.iterables import flatten_dict\n",
    "\n",
    "from icl.train import Run\n",
    "\n",
    "def compute_attention_entropies(attn: TensorType[\"B\", \"H\", \"2K\", \"2K\"]):\n",
    "    \"\"\"\n",
    "    Computes the entropy of each token in each head, averaged across the batch, \n",
    "    then averages this over heads. \n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # Threshold attention weights to avoid log(0)\n",
    "    log_attention = torch.where(attn > 0, torch.log(attn), torch.tensor(0.0).to(attn.device))\n",
    "    entropy_per_token = - torch.sum(attn * log_attention, dim=-1).mean(dim=0).squeeze(-1) # TensorType[\"H\", \"2K\"]\n",
    "\n",
    "    num_heads, num_tokens = entropy_per_token.shape\n",
    "\n",
    "    entropy_per_head = entropy_per_token.mean(dim=-1) # TensorType[\"H\"]\n",
    "    entropy = entropy_per_head.mean() # TensorType[]    \n",
    "    \n",
    "    # Each token computes entropy over a variable context length, so we normalize by the maximum possible entropy\n",
    "    # for a token with a fixed context length.\n",
    "\n",
    "    max_entropy_per_token = torch.log2(torch.arange(1, num_tokens + 1).to(attn.device)) # TensorType[\"H\", \"2K\"]\n",
    "    max_entropy_per_token[0] = 1. # Special case for the first token to avoid dividing by 0\n",
    "\n",
    "    entropy_per_token_normalized = entropy_per_token / max_entropy_per_token\n",
    "    entropy_per_head_normalized = entropy_per_token_normalized.mean(dim=-1) # TensorType[\"H\"]\n",
    "    entropy_normalized = entropy_per_head_normalized.mean() # TensorType[]    \n",
    "\n",
    "    results: Dict[str, Union[torch.Tensor, Dict[str, torch.Tensor]]] = {\"mean\": entropy, \"mean_normalized\": entropy_normalized}\n",
    "\n",
    "    for i in range(num_heads):\n",
    "        head_results = {\"mean\": entropy_per_head[i], \"mean_normalized\": entropy_per_head_normalized[i]}\n",
    "\n",
    "        for j in range(num_tokens):\n",
    "            head_results[f\"token_{j}\"] = entropy_per_token[i, j]\n",
    "            head_results[f\"token_{j}_normalized\"] = entropy_per_token_normalized[i, j]\n",
    "\n",
    "        results[f\"head_{i}\"] = head_results\n",
    "\n",
    "    return map_nested(lambda x: convert_tensor(x, \"np\"), results)\n",
    "\n",
    "\n",
    "def get_attention_entropies_trace(\n",
    "    steps: List[int],\n",
    "    models: Iterable[nn.Module],\n",
    "    xs: torch.Tensor,\n",
    "    ys: torch.Tensor,\n",
    "    **paths,\n",
    "):\n",
    "    results = defaultdict(list)\n",
    "    reverse_paths = {v: k for k, v in paths.items()}\n",
    "\n",
    "    for activations in extract_activations_over_checkpoints(models, xs, ys, *paths.values(), return_type=\"pt\"):\n",
    "        for k, v in activations.items():\n",
    "            if k == \"\":\n",
    "                continue\n",
    "            path = reverse_paths[k]\n",
    "            results[path].append(compute_attention_entropies(v))\n",
    "\n",
    "    values = []\n",
    "\n",
    "    for i in range(len(steps)):\n",
    "        value = {}\n",
    "\n",
    "        for block in results.keys():\n",
    "            value[block] = results[block][i]\n",
    "        \n",
    "        value[\"step\"] = steps[i]\n",
    "        values.append(flatten_dict(value, flatten_lists=True))\n",
    "\n",
    "    return pd.DataFrame(values)\n",
    "\n",
    "\n",
    "num_blocks = run.config.task_config.num_layers\n",
    "num_heads = run.config.task_config.num_heads\n",
    "num_tokens = run.config.task_config.max_examples * 2\n",
    "\n",
    "\n",
    "attn_entropies = get_attention_entropies_trace(\n",
    "    run.checkpointer.file_ids,\n",
    "    models, \n",
    "    xs, \n",
    "    ys, \n",
    "    **{f\"block_{b}\": f\"token_sequence_transformer.blocks.{b}.attention.attention_softmax\" for b in range(num_blocks)}\n",
    ")\n",
    "\n",
    "# run_attn_entropy_slug = \"attn-S-\" + run.config.to_slug(delimiter=\"-\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention_patterns(df: pd.DataFrame, num_blocks: int, num_heads: int, num_tokens: int, title=\"\", save: Optional[str] = None, figsize=(20, 25), logx=False, logy=False, metric=\"mean\", label=\"Entropy\"):\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    plt.suptitle(label + \"\\n\" + title)\n",
    "\n",
    "    num_cols = num_blocks * 2\n",
    "    num_rows = 1 + 1 + num_heads\n",
    "\n",
    "    fig.set_facecolor('white')\n",
    "\n",
    "    # Create subplot for mean entropy of first two blocks\n",
    "    ax0 = plt.subplot2grid((num_rows, num_cols), (0, 0), colspan=num_cols)\n",
    "    block_cmap = sns.color_palette(\"viridis\", num_blocks)\n",
    "\n",
    "    for b in range(num_blocks):\n",
    "        ax0.plot(df.step, df[f\"block_{b}/{metric}\"], label=f\"block_{b}\", color=block_cmap[b])\n",
    "\n",
    "    ax0.set_title(\"Blocks\")\n",
    "    ax0.set_xlabel(\"Step\")\n",
    "    ax0.set_ylabel(label)\n",
    "    ax0.legend()\n",
    "\n",
    "    plot_transitions(ax0, TRANSITIONS, limit=True)\n",
    "\n",
    "    # Create subplots for each block, showing entropy in different heads\n",
    "    ax1 = [plt.subplot2grid((num_rows, num_cols), (1, i), colspan=1) for i in range(num_blocks * 2)]\n",
    "    head_cmap = sns.color_palette(\"viridis\", num_heads)\n",
    "        \n",
    "    for b in range(num_blocks):\n",
    "        for x_or_y in (1, 0):\n",
    "            _ax1 = ax1[2 * b + x_or_y]\n",
    "            _ax1.set_title(f\"Block {b} {'x' if not x_or_y else 'y'}\")\n",
    "            _ax1.set_xlabel(\"Step\")\n",
    "            _ax1.set_ylabel(label)\n",
    "            for h in range(num_heads):\n",
    "                series = df[f\"block_{b}/head_{h}/{'x' if not x_or_y else 'y'}/{metric}\"]\n",
    "                _ax1.plot(df.step, series, label=f\"Head {h}\", color=head_cmap[h])\n",
    "\n",
    "    ax1[0].legend()\n",
    "    plot_transitions(ax1, TRANSITIONS, limit=True)\n",
    "\n",
    "    # Create subplots for each head in each block, detailing entropy for each token\n",
    "    ax2 = [plt.subplot2grid((num_rows, num_cols), (i//(num_cols) + 2, i%(num_cols))) for i in range(num_heads * num_blocks * 2)]\n",
    "    ax_idx = 0\n",
    "    token_cmap = sns.color_palette(\"viridis\", num_tokens)\n",
    "\n",
    "\n",
    "    for h in range(num_heads):\n",
    "        for b in range(num_blocks):\n",
    "            for x_or_y in (1, 0):\n",
    "                ax2[ax_idx].set_title(f\"Block {b} Head {h}\")\n",
    "                ax2[ax_idx].set_xlabel(\"Step\")\n",
    "                ax2[ax_idx].set_ylabel(label)\n",
    "\n",
    "                for t in range(1-int(x_or_y), num_tokens, 2):\n",
    "                    series = df[f\"block_{b}/head_{h}/token_{t}/{metric}\"]\n",
    "                    ax2[ax_idx].plot(df.step, series, label=f\"Token {t}\", color=token_cmap[t])\n",
    "                    \n",
    "                ax_idx += 1\n",
    "\n",
    "    ax2[0].legend()\n",
    "    ax2[1].legend()\n",
    "\n",
    "    plot_transitions(ax2, TRANSITIONS, limit=True)\n",
    "\n",
    "    for ax in [ax0, *ax1, *ax2]:\n",
    "        if logx:\n",
    "            ax.set_xscale(\"log\")\n",
    "        if logy:\n",
    "            ax.set_yscale(\"log\")\n",
    "\n",
    "        ax.set_xlim(100, 500_000)\n",
    "        \n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "    if save:\n",
    "        parent_dir = os.path.dirname(save)\n",
    "        if not os.path.exists(parent_dir):\n",
    "            os.makedirs(parent_dir)\n",
    "        plt.savefig(save)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for normalized in (True,): # False):\n",
    "    plot_attention_patterns(\n",
    "        attn_entropies, \n",
    "        num_blocks=num_blocks, \n",
    "        num_heads=num_heads, \n",
    "        num_tokens=num_tokens, \n",
    "        title=run.config.to_latex(), \n",
    "        save=FIGURES / (f\"{MODEL_ID}-attn-entropy-normalized-{normalized}\" + \".png\"),\n",
    "        figsize=(25, 25),\n",
    "        normalized=normalized,\n",
    "        logx=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention Variability\n",
    "See how much the attention weights vary between different samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_attention_variability(attn: TensorType[\"B\", \"H\", \"2K\", \"2K\"]):\n",
    "    \"\"\"\n",
    "    Computes the variability of the attention pattern of each head across the batch.\n",
    "    \"\"\"\n",
    "\n",
    "    results: Dict[str, Union[float, Dict[str, float]]] = {}\n",
    "\n",
    "    variability = attn.std(dim=0).mean(dim=-1).squeeze(-1) # TensorType[\"H\", \"2K\"]\n",
    "\n",
    "    num_batches, num_heads, num_tokens, _ = attn.shape\n",
    "\n",
    "    self_attn = torch.zeros(num_heads, num_tokens, device=attn.device)\n",
    "    prev_token_attn = torch.zeros(num_heads, num_tokens, device=attn.device)\n",
    "    x_tokens_attn = torch.zeros(num_heads, num_tokens, device=attn.device)\n",
    "    y_tokens_attn = torch.zeros(num_heads, num_tokens, device=attn.device)\n",
    "\n",
    "    for b in range(num_batches):\n",
    "        for h in range(num_heads):\n",
    "            self_attn[h] += attn[b, h, :, :].diagonal()\n",
    "            prev_token_attn[h, 1:] += attn[b, h, :, :].diagonal(-1)\n",
    "            x_tokens_attn[h] += attn[b, h, :, 0::2].sum(dim=-1)\n",
    "            y_tokens_attn[h] += attn[b, h, :, 1::2].sum(dim=-1)\n",
    "\n",
    "    self_attn /= num_batches\n",
    "    prev_token_attn /= num_batches\n",
    "    x_tokens_attn /= num_batches\n",
    "    y_tokens_attn /= num_batches\n",
    "\n",
    "    results[\"variability\"] = variability.mean().item()\n",
    "    results[\"self_attn\"] = self_attn.mean().item()\n",
    "    results[\"prev_token_attn\"] = prev_token_attn.mean().item()\n",
    "    results[\"x_tokens_attn\"] = x_tokens_attn.mean().item()\n",
    "    results[\"y_tokens_attn\"] = y_tokens_attn.mean().item()\n",
    "\n",
    "    for i in range(num_heads):  \n",
    "        head_variability = variability[i]\n",
    "        head_self_attn = self_attn[i]\n",
    "        head_prev_token_attn = prev_token_attn[i]\n",
    "        head_x_tokens_attn = x_tokens_attn[i]\n",
    "        head_y_tokens_attn = y_tokens_attn[i]\n",
    "\n",
    "        head_results = {\n",
    "            \"variability\": head_variability.mean().item(),\n",
    "            \"self_attn\": head_self_attn.mean().item(),\n",
    "            \"prev_token_attn\": head_prev_token_attn.mean().item(),\n",
    "            \"x_tokens_attn\": head_x_tokens_attn.mean().item(),\n",
    "            \"y_tokens_attn\": head_y_tokens_attn.mean().item(),\n",
    "        }\n",
    "\n",
    "        for x_or_y in (1, 0):\n",
    "            head_half_results = dict(\n",
    "                variability = head_variability[x_or_y::2].mean().item(),\n",
    "                self_attn = head_self_attn[x_or_y::2].mean().item(),\n",
    "                prev_token_attn = head_prev_token_attn[x_or_y::2].mean().item(),\n",
    "                x_tokens_attn = head_x_tokens_attn[x_or_y::2].mean().item(),\n",
    "                y_tokens_attn = head_y_tokens_attn[x_or_y::2].mean().item()\n",
    "            )\n",
    "\n",
    "            head_results[\"x\" if not x_or_y else \"y\"] = head_half_results\n",
    "\n",
    "            for j in range(x_or_y, num_tokens, 2):\n",
    "                head_results[f\"token_{j}/variability\"] = head_variability[j].item()\n",
    "                head_results[f\"token_{j}/self_attn\"] = self_attn[i, j].item()\n",
    "                head_results[f\"token_{j}/prev_token_attn\"] = prev_token_attn[i, j].item()\n",
    "                head_results[f\"token_{j}/x_tokens_attn\"] = x_tokens_attn[i, j].item()\n",
    "                head_results[f\"token_{j}/y_tokens_attn\"] = y_tokens_attn[i, j].item()\n",
    "\n",
    "        results[f\"head_{i}\"] = head_results\n",
    "\n",
    "    return map_nested(lambda x: convert_tensor(x, \"np\"), results)\n",
    "\n",
    "\n",
    "def get_attention_variabilities(\n",
    "    steps: List[int],\n",
    "    models: Iterable[nn.Module],\n",
    "    xs: torch.Tensor,\n",
    "    ys: torch.Tensor,\n",
    "    **paths,\n",
    "):\n",
    "    results = defaultdict(list)\n",
    "    reverse_paths = {v: k for k, v in paths.items()}\n",
    "\n",
    "    for activations in extract_activations_over_checkpoints(models, xs, ys, *paths.values(), return_type=\"pt\"):\n",
    "        for k, v in activations.items():\n",
    "            if k == \"\":\n",
    "                continue\n",
    "            path = reverse_paths[k]\n",
    "            results[path].append(compute_attention_variability(v))\n",
    "\n",
    "    values = []\n",
    "\n",
    "    for i in tqdm.trange(len(steps)):\n",
    "        value = {}\n",
    "\n",
    "        for block in results.keys():\n",
    "            value[block] = results[block][i]\n",
    "        \n",
    "        value[\"step\"] = steps[i]\n",
    "        values.append(flatten_dict(value, flatten_lists=True))\n",
    "\n",
    "    return pd.DataFrame(values)\n",
    "\n",
    "attn_variabilities = get_attention_variabilities(\n",
    "    run.checkpointer.file_ids,\n",
    "    models, \n",
    "    xs, \n",
    "    ys, \n",
    "    **{f\"block_{b}\": f\"token_sequence_transformer.blocks.{b}.attention.attention_softmax\" for b in range(num_blocks)}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in range(2):\n",
    "    attn_variabilities[f\"block_{b}/self_attn\"] = attn_variabilities[f\"block_{b}/self_attn_mean\"] \n",
    "    attn_variabilities[f\"block_{b}/prev_token_attn\"] = attn_variabilities[f\"block_{b}/prev_token_attn_mean\"]\n",
    "    attn_variabilities[f\"block_{b}/x_tokens_attn\"] = attn_variabilities[f\"block_{b}/x_tokens_attn_mean\"]\n",
    "    attn_variabilities[f\"block_{b}/y_tokens_attn\"] = attn_variabilities[f\"block_{b}/y_tokens_attn_mean\"]\n",
    "\n",
    "attn_variabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for title, metric in zip((\"Self attention\", \"Previous token attention\", \"X tokens attention\", \"Y tokens attention\"), (\"self_attn\", \"prev_token_attn\", \"x_tokens_attn\", \"y_tokens_attn\")):\n",
    "    plot_attention_patterns(\n",
    "        attn_variabilities, \n",
    "        num_blocks=num_blocks, \n",
    "        num_heads=num_heads, \n",
    "        num_tokens=num_tokens, \n",
    "        save=FIGURES / (f\"{MODEL_ID}-attn-self-attn\" + \".png\"),\n",
    "        figsize=(25, 25),\n",
    "        logx=True,\n",
    "        metric=metric,\n",
    "        title=run.config.to_latex(), \n",
    "        label=title\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perturb attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highlight_steps = [get_nearest_step(s) for s in [t[0] for t in TRANSITIONS] + [TRANSITIONS[-1][1]]]\n",
    "steps_to_models = dict(zip(steps, models))\n",
    "print(highlight_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import patches\n",
    "import statsmodels.api as sm\n",
    "\n",
    "NUM_PERTURBATIONS = 5\n",
    "EPS_LIMIT = 5\n",
    "NUM_POINTS = 100\n",
    "# epsilons = np.logspace(-5, np.log10(EPS_LIMIT), 50, base=10)\n",
    "# epsilons = np.array(list(reversed((-epsilons).tolist())) + [0.0] + epsilons.tolist())\n",
    "epsilons = np.linspace(-3 * EPS_LIMIT, 3 * EPS_LIMIT, NUM_POINTS)\n",
    "\n",
    "xs, ys = xs.to('mps'), ys.to('mps')\n",
    "\n",
    "BLOCK_IDX = 1\n",
    "INIT_STAGE = 2\n",
    "kink_steps = highlight_steps[INIT_STAGE:]\n",
    "stage_labels = [t[2] + f\" Start ({s})\" for s, t in zip(kink_steps, TRANSITIONS[INIT_STAGE:])] + [TRANSITIONS[-1][2] + f\" End ({kink_steps[-1]})\"]\n",
    "models_subset = [steps_to_models[step] for step in kink_steps]\n",
    "\n",
    "labels = [\"$L$\", r\"$\\delta L/\\delta \\epsilon$\", r\"$\\delta^2 L/\\delta \\epsilon^2$\"]\n",
    "stage_handles = [patches.Patch(color=c, label=l) for c, l in zip(sns.color_palette(\"viridis\", len(stage_labels)), stage_labels)]\n",
    "\n",
    "layer_type = \"Attention\"\n",
    "LAYER = f\"Block {BLOCK_IDX + 1} {layer_type}\"\n",
    "\n",
    "def get_layer(model):\n",
    "    if layer_type == \"Attention\":\n",
    "        return model.token_sequence_transformer.blocks[BLOCK_IDX].attention.attention.weight\n",
    "    elif layer_type == \"MLP\":\n",
    "        return model.token_sequence_transformer.blocks[BLOCK_IDX].compute[0].weight\n",
    "    elif layer_type == \"MLP Projection\":\n",
    "        return model.token_sequence_transformer.blocks[BLOCK_IDX].compute[2].weight\n",
    "    elif layer_type == \"All Weights\":\n",
    "        return {k: v for k, v in model.state_dict().items() if not torch.any(torch.isnan(v))}\n",
    "    \n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "all_perturbed_losses = []\n",
    "\n",
    "for i in range(NUM_PERTURBATIONS):\n",
    "    perturbed_losses = []\n",
    "    layer = get_layer(models[-1])\n",
    "\n",
    "    if isinstance(layer, dict):\n",
    "        perturbation = {k: torch.randn_like(v) for k, v in layer.items()}\n",
    "        perturbation_norm = sum([v.norm() ** 2 for v in perturbation.values()]) ** 0.5\n",
    "        perturbation = {k: v / perturbation_norm for k, v in perturbation.items()}\n",
    "\n",
    "    else:\n",
    "        perturbation = torch.randn_like(layer)\n",
    "        perturbation = perturbation / perturbation.norm()\n",
    "\n",
    "    for step, model in tqdm.tqdm(zip(kink_steps, models_subset), total=len(kink_steps)):\n",
    "        model.to('mps')\n",
    "        for epsilon in epsilons:\n",
    "            m = deepcopy(model)\n",
    "            with torch.no_grad():\n",
    "                layer = get_layer(m)\n",
    "    \n",
    "                if isinstance(layer, dict):\n",
    "                    layer = {k: v + epsilon * perturbation[k] for k, v in layer.items()}\n",
    "                    m.load_state_dict(layer)\n",
    "                else:\n",
    "                    layer += epsilon * perturbation\n",
    "                    \n",
    "                ys_pred = m(xs, ys)\n",
    "                perturbed_losses.append({\"step\": step, \"log_step\": np.log(step+1), \"loss\": F.mse_loss(ys_pred, ys).item(), \"epsilon\": epsilon})\n",
    "\n",
    "    perturbed_losses = pd.DataFrame(perturbed_losses)\n",
    "    \n",
    "    for step in kink_steps:\n",
    "        min_loc = perturbed_losses.loc[perturbed_losses.step == step].loss.idxmin()\n",
    "        eps_at_min = perturbed_losses.loc[perturbed_losses.step == step].epsilon[min_loc]\n",
    "        perturbed_losses.loc[perturbed_losses.step == step, \"epsilon_normalized\"] = perturbed_losses.loc[perturbed_losses.step == step].epsilon - eps_at_min\n",
    "\n",
    "    min_loss_by_step = perturbed_losses.groupby(\"step\").loss.min()\n",
    "\n",
    "    perturbed_losses[\"loss_normalized\"] = perturbed_losses.apply(lambda x: x.loss - min_loss_by_step[x.step], axis=1)\n",
    "    perturbed_losses[\"loss_normalized_slope\"] = d_dt(perturbed_losses.epsilon, perturbed_losses.loss_normalized)\n",
    "    perturbed_losses[\"loss_normalized_curvature\"] = d_dt(perturbed_losses.epsilon, perturbed_losses.loss_normalized_slope)\n",
    "    perturbed_losses[\"perturbation_idx\"] = i\n",
    "\n",
    "    all_perturbed_losses.append(perturbed_losses)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "    \n",
    "    sns.lineplot(data=perturbed_losses.loc[perturbed_losses.epsilon_normalized.abs() < EPS_LIMIT], x=\"epsilon_normalized\", y=\"loss_normalized\", hue=\"log_step\", palette=\"viridis\", ax=axes[0])\n",
    "    sns.lineplot(data=perturbed_losses.loc[perturbed_losses.epsilon_normalized.abs() < EPS_LIMIT], x=\"epsilon_normalized\", y=\"loss_normalized_slope\", hue=\"log_step\", palette=\"viridis\", ax=axes[1])\n",
    "    sns.lineplot(data=perturbed_losses.loc[perturbed_losses.epsilon_normalized.abs() < EPS_LIMIT], x=\"epsilon_normalized\", y=\"loss_normalized_curvature\", hue=\"log_step\", palette=\"viridis\", ax=axes[2])\n",
    "\n",
    "    for ax, label in zip(axes, labels):\n",
    "        ax.set_xlabel(r\"$\\epsilon$\")\n",
    "        ax.set_ylabel(label)    \n",
    "        # ax.set_xscale('symlog')\n",
    "        ax.legend().remove()    \n",
    "        # ax.set_xlim(-EPS_LIMIT, EPS_LIMIT)\n",
    "        \n",
    "    ax.legend(stage_labels, handles=stage_handles, title=\"Checkpoint\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "    ax.axhline(0, color=\"black\", linestyle=\"--\")\n",
    "    plt.suptitle(f\"{LAYER} Perturbation {i+ 1}\")\n",
    "    fig.set_facecolor('white')\n",
    "    plt.show()\n",
    "\n",
    "all_perturbed_losses = pd.concat(all_perturbed_losses).sort_values(\"epsilon_normalized\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "# avg_perturbed_losses = all_perturbed_losses.groupby([\"step\", \"epsilon_normalized\"]).mean().reset_index()\n",
    "# std_perturbed_losses = all_perturbed_losses.groupby([\"step\", \"epsilon_normalized\"]).std().reset_index()\n",
    "\n",
    "# for ax, key in zip(axes, [\"loss_normalized\", \"loss_normalized_slope\", \"loss_normalized_curvature\"]):\n",
    "#     sns.lineplot(data=avg_perturbed_losses, x=\"epsilon_normalized\", y=key, hue=\"log_step\", palette=\"viridis\", ax=ax)\n",
    "#     ax.fill_between(avg_perturbed_losses.epsilon_normalized, avg_perturbed_losses[key] - std_perturbed_losses[key], avg_perturbed_losses[key] + std_perturbed_losses[key], alpha=0.2)\n",
    "\n",
    "sns.lineplot(data=all_perturbed_losses.loc[all_perturbed_losses.epsilon_normalized.abs() < EPS_LIMIT], x=\"epsilon_normalized\", y=\"loss_normalized\", hue=\"log_step\", palette=\"viridis\", ax=axes[0])\n",
    "sns.lineplot(data=all_perturbed_losses.loc[all_perturbed_losses.epsilon_normalized.abs() < EPS_LIMIT], x=\"epsilon_normalized\", y=\"loss_normalized_slope\", hue=\"log_step\", palette=\"viridis\", ax=axes[1])\n",
    "sns.lineplot(data=all_perturbed_losses.loc[all_perturbed_losses.epsilon_normalized.abs() < EPS_LIMIT], x=\"epsilon_normalized\", y=\"loss_normalized_curvature\", hue=\"log_step\", palette=\"viridis\", ax=axes[2])\n",
    "\n",
    "for ax, label in zip(axes, labels):\n",
    "    ax.set_xlabel(r\"$\\epsilon$\")\n",
    "    ax.set_ylabel(label)    \n",
    "    ax.legend().remove()\n",
    "    # ax.set_xscale('symlog')\n",
    "    # ax.set_xlim(-EPS_LIMIT, EPS_LIMIT)\n",
    "\n",
    "ax.axhline(0, color=\"black\", linestyle=\"--\")\n",
    "ax.legend(stage_labels, handles=stage_handles, title=\"Checkpoint\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.suptitle(LAYER)\n",
    "fig.set_facecolor('white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(NUM_PERTURBATIONS):\n",
    "    perturbed_losses = all_perturbed_losses.loc[all_perturbed_losses.perturbation_idx == i]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "    \n",
    "    sns.lineplot(data=perturbed_losses.loc[perturbed_losses.epsilon_normalized.abs() < EPS_LIMIT], x=\"epsilon_normalized\", y=\"loss_normalized\", hue=\"log_step\", palette=\"viridis\", ax=axes[0])\n",
    "    sns.lineplot(data=perturbed_losses.loc[perturbed_losses.epsilon_normalized.abs() < EPS_LIMIT], x=\"epsilon_normalized\", y=\"loss_normalized_slope\", hue=\"log_step\", palette=\"viridis\", ax=axes[1])\n",
    "    sns.lineplot(data=perturbed_losses.loc[perturbed_losses.epsilon_normalized.abs() < EPS_LIMIT], x=\"epsilon_normalized\", y=\"loss_normalized_curvature\", hue=\"log_step\", palette=\"viridis\", ax=axes[2])\n",
    "\n",
    "    for ax, label in zip(axes, labels):\n",
    "        ax.set_xlabel(r\"$\\epsilon$\")\n",
    "        ax.set_ylabel(label)    \n",
    "        ax.legend().remove()    \n",
    "        # ax.set_xlim(-EPS_LIMIT, EPS_LIMIT)\n",
    "        \n",
    "    ax.legend(stage_labels, handles=stage_handles, title=\"Checkpoint\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "    ax.axhline(0, color=\"black\", linestyle=\"--\")\n",
    "    plt.suptitle(\"Perturbation \" + str(i))\n",
    "    fig.set_facecolor('white')\n",
    "    plt.show()\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "# avg_perturbed_losses = all_perturbed_losses.groupby([\"step\", \"epsilon_normalized\"]).mean().reset_index()\n",
    "# std_perturbed_losses = all_perturbed_losses.groupby([\"step\", \"epsilon_normalized\"]).std().reset_index()\n",
    "\n",
    "# for ax, key in zip(axes, [\"loss_normalized\", \"loss_normalized_slope\", \"loss_normalized_curvature\"]):\n",
    "#     sns.lineplot(data=avg_perturbed_losses, x=\"epsilon_normalized\", y=key, hue=\"log_step\", palette=\"viridis\", ax=ax)\n",
    "#     ax.fill_between(avg_perturbed_losses.epsilon_normalized, avg_perturbed_losses[key] - std_perturbed_losses[key], avg_perturbed_losses[key] + std_perturbed_losses[key], alpha=0.2)\n",
    "\n",
    "sns.lineplot(data=all_perturbed_losses.loc[all_perturbed_losses.epsilon_normalized.abs() < EPS_LIMIT], x=\"epsilon_normalized\", y=\"loss_normalized\", hue=\"log_step\", palette=\"viridis\", ax=axes[0])\n",
    "sns.lineplot(data=all_perturbed_losses.loc[all_perturbed_losses.epsilon_normalized.abs() < EPS_LIMIT], x=\"epsilon_normalized\", y=\"loss_normalized_slope\", hue=\"log_step\", palette=\"viridis\", ax=axes[1])\n",
    "sns.lineplot(data=all_perturbed_losses.loc[all_perturbed_losses.epsilon_normalized.abs() < EPS_LIMIT], x=\"epsilon_normalized\", y=\"loss_normalized_curvature\", hue=\"log_step\", palette=\"viridis\", ax=axes[2])\n",
    "\n",
    "for ax, label in zip(axes, labels):\n",
    "    ax.set_xlabel(r\"$\\epsilon$\")\n",
    "    ax.set_ylabel(label)    \n",
    "    ax.legend().remove()\n",
    "    # ax.set_xscale('symlog')\n",
    "    # ax.set_xlim(-EPS_LIMIT, EPS_LIMIT)\n",
    "\n",
    "ax.axhline(0, color=\"black\", linestyle=\"--\")\n",
    "ax.legend(stage_labels, handles=stage_handles, title=\"Checkpoint\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "fig.set_facecolor('white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perturbed_losses[\"loss_normalized\"] -= 1e-3\n",
    "# perturbed_losses[\"loss_normalized\"] += 1e-3\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "sns.lineplot(data=perturbed_losses.loc[perturbed_losses.step > 1], x=\"epsilon\", y=\"loss_normalized\", hue=\"log_step\", palette=\"viridis\", ax=ax, alpha=0.8)\n",
    "\n",
    "# ax.set_xscale('symlog')\n",
    "# ax.set_yscale('log')    \n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.set_xlabel(r\"$\\epsilon$\")\n",
    "ax.set_title(f\"Loss vs. Perturbation for Layer {BLOCK_IDX+1} at Different Steps\")\n",
    "ax.legend(title=\"Step\", loc='upper left')\n",
    "\n",
    "ax.set_xlim(-1, 1)\n",
    "ax.set_ylim(0.0008, 0.05)\n",
    "# ax.set_ylim(-0.001, 5)\n",
    "# ax.set_xscale('symlog')\n",
    "ax.set_yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, len(highlight_steps), figsize=(40, 4))\n",
    "\n",
    "train_lim = 15\n",
    "\n",
    "# Now let's try to fit a quadratic to the loss \n",
    "for i, (ax, step) in enumerate(zip(axes, highlight_steps)):\n",
    "    print(step)\n",
    "    perturbed_losses_subset = perturbed_losses.loc[(perturbed_losses.step == step)]\n",
    "    perturbed_losses_subset[\"epsilon2\"] = perturbed_losses_subset.epsilon ** 2\n",
    "    perturbed_losses_subset[\"epsilon4\"] = perturbed_losses_subset.epsilon ** 4\n",
    "    perturbed_losses_train_subset = perturbed_losses_subset.loc[(perturbed_losses.epsilon.abs() < train_lim)]\n",
    "\n",
    "    quadratic = sm.OLS.from_formula(\"loss_normalized ~ epsilon2\", data=perturbed_losses_train_subset).fit()\n",
    "\n",
    "    quartic = sm.OLS.from_formula(\"loss_normalized ~ epsilon4\", data=perturbed_losses_train_subset).fit()\n",
    "\n",
    "    sns.lineplot(data=perturbed_losses_subset, x=\"epsilon\", y=\"loss_normalized\", ax=ax, label=\"Loss\")\n",
    "    sns.lineplot(data=perturbed_losses_subset, x=\"epsilon\", y=quadratic.predict(perturbed_losses_subset[\"epsilon2\"]), ax=ax, label=\"Quadratic\")\n",
    "    sns.lineplot(data=perturbed_losses_subset, x=\"epsilon\", y=quartic.predict(perturbed_losses_subset[\"epsilon4\"]), ax=ax, label=\"Quartic\")\n",
    "    ax.set_title(f\"Step {step}\")\n",
    "    ax.set_xlabel(\"$\\epsilon$\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "\n",
    "    ax.set_ylim(perturbed_losses_subset.loss_normalized.min(), perturbed_losses_subset.loss_normalized.max())\n",
    "    ax.set_yscale('log')\n",
    "    # ax.set_xscale('symlog')\n",
    "\n",
    "    ax.fill_between([-train_lim, train_lim], [perturbed_losses_subset.loss_normalized.min(), perturbed_losses_subset.loss_normalized.min()], [perturbed_losses_subset.loss_normalized.max(), perturbed_losses_subset.loss_normalized.max()], alpha=0.1, color=\"gray\")\n",
    "    ax.set_xlim(-train_lim * 1.5, train_lim * 1.5)\n",
    "\n",
    "print(quadratic.summary())\n",
    "print(quartic.summary())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hessian_vector_product(model, loss, vector_u, get_parameters=None):\n",
    "    \"\"\"\n",
    "    Compute the product of the Hessian matrix with a vector u (Hu) for a neural network model.\n",
    "\n",
    "    :param model: The neural network model (PyTorch).\n",
    "    :param loss: The loss. Should not be detached\n",
    "    :param vector_u: The vector u for which to compute Hu.\n",
    "    :return: The product Hu.\n",
    "    \"\"\"\n",
    "    get_parameters = get_parameters or (lambda model: model.parameters())\n",
    "\n",
    "    # Zero gradients (if any exist)\n",
    "    model.zero_grad()\n",
    "\n",
    "    # First backward pass to compute the gradient g\n",
    "    grads = torch.autograd.grad(loss, get_parameters(model), create_graph=True)\n",
    "    # Flatten the gradients and vector u\n",
    "    grads_flatten = torch.cat([g.view(-1) for g in grads])\n",
    "    vector_u_flatten = torch.cat([v.view(-1) for v in vector_u])\n",
    "\n",
    "    # Compute dot product between gradients and vector u\n",
    "    grad_u_dot = torch.dot(grads_flatten, vector_u_flatten)\n",
    "\n",
    "    # Second backward pass to compute Hu\n",
    "    hessian_vector_product = torch.autograd.grad(grad_u_dot, get_parameters(model))\n",
    "\n",
    "    return hessian_vector_product\n",
    "\n",
    "\n",
    "# Example usage (assuming a model, loss function, input_tensor, target_tensor, and vector_u are defined)\n",
    "# hu_product = compute_hessian_vector_product(model, loss_fn, input_tensor, target_tensor, vector_u)\n",
    "# print(hu_product)\n",
    "\n",
    "# Note: This function doesn't execute the computation as it requires a specific model, loss function, input and target tensors, and vector u."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLOCK_IDX = 0\n",
    "\n",
    "layer_type = \"All Weights\"\n",
    "LAYER = f\"Block {BLOCK_IDX + 1} {layer_type}\"\n",
    "\n",
    "def get_layer_params(model):\n",
    "    if layer_type == \"Attention\":\n",
    "        return model.token_sequence_transformer.blocks[BLOCK_IDX].attention.attention.parameters()\n",
    "    elif layer_type == \"MLP\":\n",
    "        return model.token_sequence_transformer.blocks[BLOCK_IDX].compute[0].parameters()\n",
    "    elif layer_type == \"MLP Projection\":\n",
    "        return model.token_sequence_transformer.blocks[BLOCK_IDX].compute[2].parameters()\n",
    "    elif layer_type == \"MLP with Projection\":\n",
    "        return model.token_sequence_transformer.blocks[BLOCK_IDX].compute.parameters()\n",
    "    elif layer_type == \"All Weights\":\n",
    "        return (p for p in model.parameters() if not torch.any(torch.isnan(p)))\n",
    "\n",
    "torch.manual_seed(0)\n",
    "xs, ys = xs.to('cpu'), ys.to('cpu')\n",
    "\n",
    "uHus = []\n",
    "\n",
    "def list_dot(a, b):\n",
    "    return sum([x.view(-1) @ y.view(-1) for x, y in zip(a, b)])\n",
    "\n",
    "for i in range(5):\n",
    "    models[-1].to('cpu')\n",
    "    perturbation = [torch.randn_like(p.to('cpu'), device='cpu') for p in get_layer_params(models[-1])]\n",
    "    peturbation_norm = (sum([p.norm() ** 2 for p in perturbation]) ** 0.5)\n",
    "    perturbation_norm = perturbation_norm.to('cpu')\n",
    "    perturbation = [p / perturbation_norm for p in perturbation]\n",
    "\n",
    "    for step, model in tqdm.tqdm(zip(steps, models), total=len(steps)):\n",
    "        model.to('cpu')\n",
    "        ys_pred = model(xs, ys)\n",
    "        loss = F.mse_loss(ys_pred, ys)\n",
    "        hvp = compute_hessian_vector_product(model, loss, perturbation, get_parameters=get_layer_params)\n",
    "        uHus.append({\"value\": list_dot(perturbation, hvp).item(), \"step\": step, \"i\": i})\n",
    "        model.to(DEVICE)\n",
    "\n",
    "uHus = pd.DataFrame(uHus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "\n",
    "# ax.set_yscale('log')\n",
    "sns.lineplot(data=uHus, x=\"step\", y=\"value\", hue=\"i\", ax=ax)\n",
    "ax.legend(loc='upper right')\n",
    "plot_transitions(ax, TRANSITIONS)\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim(0, 500_000)\n",
    "ax.set_title(f\"$u^T H u$ for {LAYER}\")\n",
    "\n",
    "axin = ax.inset_axes([0.075, 0.5, 0.4, 0.4])\n",
    "sns.lineplot(data=uHus, x=\"step\", y=\"value\", hue=\"i\", ax=axin)\n",
    "axin.set_xlim(10000, 500_000)\n",
    "axin.set_ylim(1e-5, 1e-2)\n",
    "axin.set_xscale('log')\n",
    "axin.set_yscale('log')\n",
    "plot_transitions(axin, TRANSITIONS, limit=True)\n",
    "\n",
    "axin.legend().remove()\n",
    "\n",
    "xs, ys = xs.to(DEVICE), ys.to(DEVICE)\n",
    "\n",
    "for _ax in [axin, ax]:\n",
    "    _ax.set_xlabel(\"Step\")\n",
    "    _ax.set_ylabel(\"$u^T H u$\")\n",
    "\n",
    "fig.set_facecolor('white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qkv(model):\n",
    "    return (\n",
    "        model.attention(torch.eye(model.embed_size, device=model.attention.weight.device))\n",
    "        .view(model.num_heads, 3 * model.head_size)\n",
    "        .split(model.head_size, dim=-1)\n",
    "    )\n",
    "\n",
    "attention_layers = []\n",
    "\n",
    "for step, model in zip(steps, models):\n",
    "    state_dict = model.state_dict()\n",
    "\n",
    "    for i in range(num_blocks):\n",
    "        q, k, v = qkv(model.token_sequence_transformer.blocks[i].attention).detach().cpu().numpy()\n",
    "        a = q @ k.T / np.sqrt(model.head_size)\n",
    "\n",
    "        attention_layers.append({\n",
    "            \"step\": step,\n",
    "            \"block\": i,\n",
    "            \"a\": a,\n",
    "            \"v\": v\n",
    "        })\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activations\n",
    "\n",
    "from devinfra.utils.seed import set_seed\n",
    "\n",
    "DEVICE = 'mps'\n",
    "\n",
    "# Gonna override activations sorry.\n",
    "losses_over_time = []\n",
    "outputs_over_time = []\n",
    "activation_stats_over_time = []\n",
    "\n",
    "train_xs_noise, train_ys_noise = run.evaluator.pretrain_xs, run.evaluator.pretrain_ys\n",
    "\n",
    "pretrain_dist_noiseless = run.config.task_config.pretrain_dist_factory().to(\n",
    "    DEVICE\n",
    ")\n",
    "pretrain_dist_noiseless.var = 0.\n",
    "\n",
    "set_seed(run.config.task_config.true_seed)\n",
    "\n",
    "train_xs, train_ys = pretrain_dist_noiseless.get_batch(8, 1024)\n",
    "\n",
    "# assert torch.allclose(train_xs, train_xs_noise)\n",
    "\n",
    "resid_stream_layers = [\n",
    "    \"token_sequence_transformer.token_embedding\",\n",
    "    \"token_sequence_transformer.blocks.0.resid_after_attn\",\n",
    "    \"token_sequence_transformer.blocks.0\",\n",
    "    \"token_sequence_transformer.blocks.1.resid_after_attn\",\n",
    "    \"token_sequence_transformer.blocks.1\"\n",
    "]\n",
    "\n",
    "act_stats_over_time = []\n",
    "\n",
    "for step, model in tqdm.tqdm(zip(steps, models)):\n",
    "    hooked_model = hook(model)\n",
    "    output, act = hooked_model.run_with_cache(train_xs, train_ys)\n",
    "    outputs_over_time.append(output)\n",
    "    losses_over_time.append(nn.MSELoss()(output, train_ys).item())\n",
    "    \n",
    "    for layer in resid_stream_layers:\n",
    "        #print(act[layer].shape)\n",
    "        act_stats_over_time.append({\n",
    "            'mean': act[layer].mean().item(),  # mean over batch, over tokens, over activations\n",
    "            'abs_mean': act[layer].mean(dim=-1).abs().mean().item(),  # mean over batch and tokens of abs mean over activations\n",
    "            'var': act[layer].var().item(),  # var over batch, over tokens, over activations\n",
    "            'batch_var_of_mean': act[layer].var(dim=-1).mean().item(),  # mean over batch and tokens of var over activations\n",
    "            'batch_var_of_var': act[layer].var(dim=-1).var().item(),  # var over batch and tokens of var over activations\n",
    "            'max': act[layer].max().item(),\n",
    "            'min': act[layer].min().item(),\n",
    "            \"step\": step, \n",
    "            \"layer\": layer,\n",
    "            \"layer_idx\": resid_stream_layers.index(layer)\n",
    "        })\n",
    "\n",
    "act_stats_over_time = pd.DataFrame(act_stats_over_time)\n",
    "act_stats_over_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# act_stats_over_time = act_stats_over_time[act_stats_over_time[\"step\"] > 0]\n",
    "\n",
    "more_metrics_to_plot = [\n",
    "    (\"$\\overline{|\\mathrm{mean}[z^{(l)}_t]|}$\", \"abs_mean\", {}),\n",
    "#    (\"Mean over batch, token index, and activation index of residual stream activations\", \"std\", {}),\n",
    "    (\"$\\overline{\\mathrm{var}[z^{(l)}_t]}$\", \"batch_var_of_mean\", {}),\n",
    "#    (\"Std over batch and token index of std within residual stream activations\", \"batch_std_of_std\", {}),\n",
    "]\n",
    "\n",
    "layers = act_stats_over_time[\"layer\"].unique()\n",
    "slopes = np.zeros((len(layers), len(run.checkpointer.file_ids[1:])))\n",
    "\n",
    "slopes_list = []\n",
    "\n",
    "for (_, key, _) in more_metrics_to_plot:\n",
    "    for j, layer in enumerate(layers):\n",
    "        values = act_stats_over_time.loc[act_stats_over_time[\"layer\"] == layer][key].values\n",
    "        slopes[j, :] = d_dlogt(run.checkpointer.file_ids[1:], values)\n",
    "\n",
    "    slopes_list.extend([{\"layer\": layer, \"step\": step, key: slopes[j, step_idx]} for j, layer in enumerate(layers) for step_idx, step in enumerate(run.checkpointer.file_ids[1:]) for slope in slopes])\n",
    "\n",
    "slopes_df = pd.DataFrame(slopes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, len(more_metrics_to_plot), figsize=(20, 6))\n",
    "\n",
    "axes = np.array([axes])\n",
    "# act_stats_over_time = act_stats_over_time[act_stats_over_time[\"step\"] > 0]\n",
    "\n",
    "for i, (metric_name, key, kwargs) in enumerate(more_metrics_to_plot):\n",
    "    sns.lineplot(ax=axes[0, i], data=act_stats_over_time, x=\"step\", y=key, hue='layer', palette='viridis')\n",
    "\n",
    "    axes[0, i].set_title(metric_name + \" over Time\")\n",
    "    axes[0, i].set_xlabel('Time Steps')\n",
    "    axes[0, i].set_ylabel(metric_name)\n",
    "    axes[0, i].set_yscale('log')\n",
    "\n",
    "    # sns.lineplot(ax=axes[1, i], data=slopes_df, x=\"step\", y=key, hue='layer', palette='viridis')\n",
    "    # axes[1, i].set_title(str_d_dlogt(metric_name) + \" over Time\")\n",
    "    # axes[1, i].set_xlabel('Time Steps')\n",
    "    # axes[1, i].set_ylabel(str_d_dlogt(metric_name))\n",
    "    # axes[1, i].set_yscale('symlog')\n",
    "\n",
    "    # sns.lineplot(ax=axes[1, i], data=slopes_df, x=\"step\", y=key, hue='layer', palette='viridis')\n",
    "    # axes[1, i].set_title(metric_name + \" Slope over Time\")\n",
    "    # axes[1, i].set_xlabel('Time Steps')\n",
    "    # axes[1, i].set_ylabel(metric_name + \" Slope\")\n",
    "\n",
    "\n",
    "for ax in axes.flatten():\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xlim(100, 500_000)\n",
    "\n",
    "axes[0, 0].legend(title=\"Layer\")\n",
    "axes[0, 1].legend().remove()\n",
    "plot_transitions(axes, transitions=TRANSITIONS)\n",
    "fig.tight_layout()\n",
    "fig.set_facecolor(\"white\")\n",
    "\n",
    "# axes[1, 0].set_ylim(-10, 10)\n",
    "# axes[1, 1].set_ylim(-5, 5)\n",
    "\n",
    "# Show the plots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mechanistic Interpretability"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
