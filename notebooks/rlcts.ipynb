{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RLCT estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jesse/Projects/icl/.venv/lib/python3.9/site-packages/pydantic/_internal/_fields.py:127: UserWarning: Field \"model_seed\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from devinterp.slt.sampler import Sampler, SamplerConfig\n",
    "from devinterp.evals import SamplerEvaluator\n",
    "from devinterp.ops.storage import CheckpointerConfig\n",
    "from devinterp.optim.optimizers import OptimizerConfig\n",
    "\n",
    "from icl.config import get_config\n",
    "from icl.evals import ICLEvaluator\n",
    "from icl.utils import set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size: 256\n",
      "checkpointer_config:\n",
      "  bucket_name: devinterp\n",
      "  device: cpu\n",
      "  local_root: null\n",
      "  project_dir: icl/ntasks-64-task-a0acbd-opt-f7c569-sched-c4766a\n",
      "criterion: cross_entropy\n",
      "device: cpu\n",
      "eval_batch_size: 2048\n",
      "logger_config:\n",
      "  entity: null\n",
      "  metrics: null\n",
      "  out_file: null\n",
      "  project: null\n",
      "  run_id: null\n",
      "  stdout: false\n",
      "  use_df: false\n",
      "num_steps: 500000\n",
      "num_training_samples: 128000000\n",
      "optimizer_config:\n",
      "  betas: !!python/tuple\n",
      "  - 0.9\n",
      "  - 0.999\n",
      "  elasticity: null\n",
      "  lr: 0.001\n",
      "  momentum: null\n",
      "  noise_level: null\n",
      "  num_samples: null\n",
      "  optimizer_type: Adam\n",
      "  temperature: null\n",
      "  weight_decay: 0.0\n",
      "scheduler_config:\n",
      "  T_max: null\n",
      "  anneal_strategy: linear\n",
      "  cycle_momentum: false\n",
      "  div_factor: 249999.0\n",
      "  eta_min: null\n",
      "  final_div_factor: 249999.0\n",
      "  gamma: null\n",
      "  last_epoch: -1\n",
      "  lr_lambda: null\n",
      "  max_lr: 0.001\n",
      "  milestones: null\n",
      "  pct_start: 0.5\n",
      "  scheduler_type: OneCycleLR\n",
      "  step_size: null\n",
      "  total_steps: 500000\n",
      "task_config:\n",
      "  embed_size: 128\n",
      "  max_examples: 16\n",
      "  mlp_size: 128\n",
      "  model_seed: 0\n",
      "  noise_variance: 0.25\n",
      "  num_heads: 2\n",
      "  num_layers: 8\n",
      "  num_tasks: 64\n",
      "  pretrain_seed: 0\n",
      "  sampling_seed: 0\n",
      "  task_size: 8\n",
      "  true_seed: 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jesse/Projects/devinterp/devinterp/utils.py:47: UserWarning: Number of steps in int_logspace is not 100, got 91.\n",
      "  warnings.warn(\n",
      "/Users/Jesse/Projects/devinterp/devinterp/utils.py:47: UserWarning: Number of steps in int_logspace is not 50, got 47.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "config = get_config(task_config={\"num_tasks\": 64})\n",
    "\n",
    "import yaml\n",
    "print(yaml.dump(config.model_dump()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the checkpoints\n",
    "checkpointer = config.checkpointer_config.factory().sync()\n",
    "checkpointer.file_ids = sorted([int(x) for x in checkpointer.file_ids])\n",
    "checkpointer.file_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pretrain/mse': 8.867645263671875,\n",
       " 'pretrain/delta_dmmse': tensor(7.3911),\n",
       " 'pretrain/delta_ridge': tensor(5.8186),\n",
       " 'pretrain/token/0': 8.977218627929688,\n",
       " 'pretrain/token/1': 8.977317810058594,\n",
       " 'pretrain/token/2': 8.686665534973145,\n",
       " 'pretrain/token/3': 8.426115989685059,\n",
       " 'pretrain/token/4': 8.815361022949219,\n",
       " 'pretrain/token/5': 8.985779762268066,\n",
       " 'pretrain/token/6': 8.918869018554688,\n",
       " 'pretrain/token/7': 9.33285140991211,\n",
       " 'pretrain/token/8': 8.752054214477539,\n",
       " 'pretrain/token/9': 8.697751998901367,\n",
       " 'pretrain/token/10': 8.631465911865234,\n",
       " 'pretrain/token/11': 8.951107025146484,\n",
       " 'pretrain/token/12': 8.75244140625,\n",
       " 'pretrain/token/13': 9.560930252075195,\n",
       " 'pretrain/token/14': 8.623815536499023,\n",
       " 'pretrain/token/15': 8.792564392089844,\n",
       " 'true/mse': 8.72768783569336,\n",
       " 'true/delta_dmmse': tensor(5.5109),\n",
       " 'true/delta_ridge': tensor(5.7320),\n",
       " 'true/token/0': 8.675100326538086,\n",
       " 'true/token/1': 8.348591804504395,\n",
       " 'true/token/2': 8.403005599975586,\n",
       " 'true/token/3': 8.80765151977539,\n",
       " 'true/token/4': 9.27450942993164,\n",
       " 'true/token/5': 8.79576301574707,\n",
       " 'true/token/6': 8.93708610534668,\n",
       " 'true/token/7': 8.615152359008789,\n",
       " 'true/token/8': 8.555869102478027,\n",
       " 'true/token/9': 8.482467651367188,\n",
       " 'true/token/10': 8.969528198242188,\n",
       " 'true/token/11': 8.727495193481445,\n",
       " 'true/token/12': 8.446076393127441,\n",
       " 'true/token/13': 8.816120147705078,\n",
       " 'true/token/14': 8.847317695617676,\n",
       " 'true/token/15': 8.941282272338867}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialise model\n",
    "model = config.task_config.model_factory().to(config.device)\n",
    "\n",
    "# initialise 'pretraining' data source (for training on fixed task set)\n",
    "pretrain_dist = config.task_config.pretrain_dist_factory().to(config.device)\n",
    "\n",
    "# initialise 'true' data source (for evaluation, including unseen tasks)\n",
    "true_dist = config.task_config.true_dist_factory().to(config.device)\n",
    "\n",
    "# initialise evaluations\n",
    "evaluator = ICLEvaluator(\n",
    "    pretrain_dist=pretrain_dist,\n",
    "    true_dist=true_dist,\n",
    "    max_examples=config.task_config.max_examples,\n",
    "    eval_batch_size=config.eval_batch_size,\n",
    ")\n",
    "\n",
    "# Load model\n",
    "# model.load_state_dict(checkpointer[-1][\"model\"])\n",
    "\n",
    "evaluator(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() missing 1 required positional argument: 'ys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 21\u001b[0m\n\u001b[1;32m      1\u001b[0m sampler \u001b[39m=\u001b[39m SamplerConfig(\n\u001b[1;32m      2\u001b[0m     optimizer_config\u001b[39m=\u001b[39mOptimizerConfig(\n\u001b[1;32m      3\u001b[0m         optimizer_type\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSGLD\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m     torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mTensorDataset(evaluator\u001b[39m.\u001b[39mpretrain_xs, evaluator\u001b[39m.\u001b[39mpretrain_ys),    \n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     20\u001b[0m rlct_evaluator \u001b[39m=\u001b[39m SamplerEvaluator\u001b[39m.\u001b[39mcreate_rlct_evaluator(sampler)\n\u001b[0;32m---> 21\u001b[0m evals \u001b[39m=\u001b[39m rlct_evaluator(model, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m     22\u001b[0m evals\n",
      "File \u001b[0;32m~/Projects/devinterp/devinterp/evals.py:148\u001b[0m, in \u001b[0;36mSamplerEvaluator.__call__\u001b[0;34m(self, model, optimizer, scheduler)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\n\u001b[1;32m    143\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    144\u001b[0m     model: nn\u001b[39m.\u001b[39mModule,\n\u001b[1;32m    145\u001b[0m     optimizer: torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mOptimizer,\n\u001b[1;32m    146\u001b[0m     scheduler: Optional[LRScheduler],\n\u001b[1;32m    147\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, Any]:\n\u001b[0;32m--> 148\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msampler\u001b[39m.\u001b[39;49msample(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobservables, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msummary_fn)\n",
      "File \u001b[0;32m~/Projects/devinterp/devinterp/slt/sampler.py:111\u001b[0m, in \u001b[0;36mSampler.sample\u001b[0;34m(self, observables, summary_fn)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[39mfor\u001b[39;00m i, (xs, ys) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39mrange\u001b[39m(num_steps), itertools\u001b[39m.\u001b[39mcycle(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloader)):\n\u001b[1;32m    110\u001b[0m     \u001b[39mfor\u001b[39;00m j, model \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mensemble):\n\u001b[0;32m--> 111\u001b[0m         yhats \u001b[39m=\u001b[39m model(xs)\n\u001b[1;32m    112\u001b[0m         losses \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcriterion(yhats, ys, reduction\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnone\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    113\u001b[0m         loss \u001b[39m=\u001b[39m losses\u001b[39m.\u001b[39mmean()\n",
      "File \u001b[0;32m~/Projects/icl/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() missing 1 required positional argument: 'ys'"
     ]
    }
   ],
   "source": [
    "sampler = SamplerConfig(\n",
    "    optimizer_config=OptimizerConfig(\n",
    "        optimizer_type=\"SGLD\",\n",
    "        lr=1e-5,\n",
    "        noise_level=1.,\n",
    "        temperature=\"adaptive\",\n",
    "        num_samples=len(evaluator.pretrain_xs),\n",
    "        elasticity=1.,\n",
    "    ),\n",
    "    criterion=\"mse_loss\",\n",
    "    num_burnin_steps=0,\n",
    "    num_draws_per_chain=100,\n",
    "    num_steps_bw_draws=100,\n",
    "    num_chains=5,\n",
    ").factory(\n",
    "    model, \n",
    "    torch.utils.data.TensorDataset(evaluator.pretrain_xs, evaluator.pretrain_ys),    \n",
    ")\n",
    "\n",
    "rlct_evaluator = SamplerEvaluator.create_rlct_evaluator(sampler)\n",
    "evals = rlct_evaluator(model, None, None)\n",
    "evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 8])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from icl.tasks import DiscreteTaskDistribution\n",
    "\n",
    "dist = DiscreteTaskDistribution(8, 4)\n",
    "dist.sample_tasks(20).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.41481709480285645, 0.021686553955078125, 0.13994932174682617)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing required modules\n",
    "import torch\n",
    "from torch.utils import data\n",
    "import time\n",
    "\n",
    "# Defining classes for the two methods\n",
    "\n",
    "# Method 1: Generate tasks on-the-fly\n",
    "class Method1:\n",
    "    def __init__(self, task_size: int, num_tasks: int, device='cuda'):\n",
    "        self.task_size = task_size\n",
    "        self.num_tasks = num_tasks\n",
    "        self.device = device\n",
    "        self.generator = torch.Generator(device=self.device)\n",
    "\n",
    "    def sample_task(self, idx: int):\n",
    "        self.generator.manual_seed(idx)\n",
    "        return torch.normal(\n",
    "            mean=0.,\n",
    "            std=1.,\n",
    "            size=(self.task_size,),\n",
    "            generator=self.generator,\n",
    "            device=self.device,\n",
    "        )\n",
    "\n",
    "    def sample_tasks(self, n: int):\n",
    "        task_selection = torch.randint(\n",
    "            high=self.num_tasks,\n",
    "            size=(n,),\n",
    "            device=self.device,\n",
    "        )\n",
    "        return torch.stack([\n",
    "            self.sample_task(int(i))\n",
    "            for i in task_selection\n",
    "        ])\n",
    "\n",
    "# Method 2: Pre-generate all tasks\n",
    "class Method2:\n",
    "    def __init__(self, task_size: int, num_tasks: int, device='cuda'):\n",
    "        self.task_size = task_size\n",
    "        self.num_tasks = num_tasks\n",
    "        self.device = device\n",
    "        self.tasks = torch.normal(\n",
    "            mean=0.,\n",
    "            std=1.,\n",
    "            size=(self.num_tasks, self.task_size),\n",
    "            device=self.device,\n",
    "        )\n",
    "\n",
    "    def sample_tasks(self, n: int):\n",
    "        task_selection = torch.randint(\n",
    "            high=self.num_tasks,\n",
    "            size=(n,),\n",
    "            device=self.device,\n",
    "        )\n",
    "        return self.tasks[task_selection]\n",
    "\n",
    "\n",
    "# Save pre-generated tasks to disk\n",
    "class Method3_Save:\n",
    "    def __init__(self, task_size: int, num_tasks: int, filename='tasks.pt', device='cpu'):\n",
    "        self.task_size = task_size\n",
    "        self.num_tasks = num_tasks\n",
    "        self.device = device\n",
    "        self.filename = filename\n",
    "        self.tasks = torch.normal(\n",
    "            mean=0.,\n",
    "            std=1.,\n",
    "            size=(self.num_tasks, self.task_size),\n",
    "            device=self.device,\n",
    "        )\n",
    "        torch.save(self.tasks, self.filename)\n",
    "\n",
    "# DataLoader for reading tasks from disk\n",
    "class DiskTaskDataset(data.Dataset):\n",
    "    def __init__(self, filename):\n",
    "        self.tasks = torch.load(filename)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tasks)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.tasks[index]\n",
    "\n",
    "# Parameters\n",
    "task_size = 1000\n",
    "num_tasks = 10000\n",
    "n_sample = 128\n",
    "n_trials = 100\n",
    "device = 'cpu'\n",
    "\n",
    "# Initialize objects\n",
    "method1 = Method1(task_size, num_tasks, device)\n",
    "method2 = Method2(task_size, num_tasks, device)\n",
    "\n",
    "# Timing Method 1\n",
    "start_time = time.time()\n",
    "for _ in range(n_trials):\n",
    "    tasks1 = method1.sample_tasks(n_sample)\n",
    "end_time = time.time()\n",
    "time_method1 = end_time - start_time\n",
    "\n",
    "# Timing Method 2\n",
    "start_time = time.time()\n",
    "for _ in range(n_trials):\n",
    "    tasks2 = method2.sample_tasks(n_sample)\n",
    "end_time = time.time()\n",
    "time_method2 = end_time - start_time\n",
    "\n",
    "# Initialize and save tasks to disk\n",
    "method3_save = Method3_Save(task_size, num_tasks//10)\n",
    "\n",
    "# Create DataLoader\n",
    "filename = 'tasks.pt'\n",
    "batch_size = n_sample  # Number of random samples in one batch\n",
    "\n",
    "# Timing Method 3\n",
    "start_time = time.time()\n",
    "for _ in range(n_trials):\n",
    "    torch.load(filename)\n",
    "\n",
    "end_time = time.time()\n",
    "time_method3 = end_time - start_time\n",
    "\n",
    "time_method1, time_method2, time_method3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/Projects/icl/.venv/lib/python3.9/site-packages/pydantic/_internal/_fields.py:127: UserWarning: Field \"model_seed\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'entity': 'devinterp',\n",
       " 'method': 'grid',\n",
       " 'name': 'icl-config-sweep',\n",
       " 'parameters': {'eval_batch_size': {'value': 2048},\n",
       "  'task_config': {'parameters': {'embed_size': {'value': 128},\n",
       "    'max_examples': {'value': 16},\n",
       "    'mlp_size': {'value': 128},\n",
       "    'model_seed': {'value': 0},\n",
       "    'noise_variance': {'value': 0.25},\n",
       "    'num_heads': {'value': 2},\n",
       "    'num_layers': {'value': 8},\n",
       "    'num_tasks': {'values': [1,\n",
       "      2,\n",
       "      4,\n",
       "      8,\n",
       "      16,\n",
       "      32,\n",
       "      64,\n",
       "      128,\n",
       "      256,\n",
       "      512,\n",
       "      1024,\n",
       "      2048,\n",
       "      4096,\n",
       "      8192,\n",
       "      16384,\n",
       "      32768,\n",
       "      65536,\n",
       "      131072,\n",
       "      262144,\n",
       "      524288,\n",
       "      1048576]},\n",
       "    'pretrain_seed': {'value': 1},\n",
       "    'sampling_seed': {'value': 3},\n",
       "    'task_size': {'value': 8},\n",
       "    'true_seed': {'value': 2}}}},\n",
       " 'program': 'icl',\n",
       " 'project': 'icl'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "import wandb\n",
    "\n",
    "from icl.config import ICLConfig\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "from pprint import pp\n",
    "\n",
    "\n",
    "SWEEP_ID = \"devinterp/icl/qoe1mlpn\"\n",
    "api = wandb.Api()\n",
    "sweep = api.sweep(SWEEP_ID)\n",
    "sweep.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
