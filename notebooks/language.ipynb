{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pickle\n",
    "from collections import Counter\n",
    "\n",
    "import tqdm \n",
    "from icl.constants import DEVICE, DATA\n",
    "from icl.language.model import get_model\n",
    "from icl.language.utils import translate_int_to_str\n",
    "\n",
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000000/5000000 [00:47<00:00, 106344.43it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "validation_set_idxs = np.random.choice(5_000_000, size=10_000, replace=False)\n",
    "validation_set = []\n",
    "\n",
    "with open(DATA / \"train-5m.jsonl\", \"r\") as f:\n",
    "    for i, line in tqdm.tqdm(enumerate(f), total=5_000_000):\n",
    "        if i in validation_set_idxs:\n",
    "            content = json.loads(line)['contents']\n",
    "            tokens = model.tokenizer(content)['input_ids']\n",
    "\n",
    "            if len(tokens) > 1024:\n",
    "                tokens = tokens[:1024]\n",
    "\n",
    "            validation_set.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "client = boto3.client('s3')\n",
    "\n",
    "with open(DATA / 'tokens-10k.pkl', 'wb') as f:\n",
    "    pickle.dump(validation_set, f)\n",
    "\n",
    "with open(DATA / 'tokens-10k.pkl','rb') as f:\n",
    "    client.upload_fileobj(f, 'devinterp', f'other/language/tokens-10k.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA / 'tokens-10k.pkl','rb') as f:\n",
    "    validation_set = pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:06<00:00, 1515.79it/s]\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 5000\n",
    "vocab = np.arange(vocab_size)\n",
    "total_trigrams = Counter()\n",
    "total_trigrams_per_row = Counter()\n",
    "\n",
    "for tokens in tqdm.tqdm(validation_set):\n",
    "    trigrams_in_row = set()\n",
    "\n",
    "    for i in range(len(tokens)-2):\n",
    "        trigram = tuple(tokens[i:i+3])\n",
    "        total_trigrams[trigram] += 1\n",
    "        trigrams_in_row.add(trigram)\n",
    "\n",
    "    for token in trigrams_in_row:\n",
    "        total_trigrams_per_row[token] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique trigrams in validation set: 2038645\n",
      "Number of unique trigrams with count > 1: 502141\n",
      "Number of unique trigrams with count > 2: 272505\n",
      "Number of unique trigrams that show up in > 1 rows: 432513\n",
      "Number of unique trigrams that show up in > 2 rows: 234870\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of unique trigrams in validation set:\", len(total_trigrams))\n",
    "print(\"Number of unique trigrams with count > 1:\", len([t for t in total_trigrams if total_trigrams[t] > 1]))\n",
    "print(\"Number of unique trigrams with count > 2:\", len([t for t in total_trigrams if total_trigrams[t] > 2]))\n",
    "print(\"Number of unique trigrams that show up in > 1 rows:\", len([t for t in total_trigrams if total_trigrams_per_row[t] > 1]))\n",
    "print(\"Number of unique trigrams that show up in > 2 rows:\", len([t for t in total_trigrams if total_trigrams_per_row[t] > 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ian refuge \t\t\t ('ian', ' ref', 'uge')\n",
      ", we've \t\t\t (',', ' we', \"'ve\")\n",
      "tool in \t\t\t ('t', 'ool', ' in')\n",
      "eld. \t\t\t ('e', 'ld', '.')\n",
      "� t \t\t\t ('�', ' ', 't')\n",
      "ue, The \t\t\t ('ue', ',', ' The')\n",
      "ion.\n",
      " \t\t\t ('ion', '.', '\\n')\n",
      " day I  \t\t\t (' day', ' I', ' ')\n",
      " off on  \t\t\t (' off', ' on', ' ')\n",
      "an entirely \t\t\t ('an', ' entire', 'ly')\n",
      " put his foot \t\t\t (' put', ' his', ' foot')\n",
      " in Japanese Pat \t\t\t (' in', ' Japanese', ' Pat')\n",
      "ain.\n",
      " \t\t\t ('ain', '.', '\\n')\n",
      "bot of \t\t\t ('b', 'ot', ' of')\n",
      "orn the \t\t\t ('orn', ' ', 'the')\n",
      " sound,  \t\t\t (' sound', ',', ' ')\n",
      " an eight \t\t\t (' ', 'an', ' eight')\n",
      "\n",
      "Clay \t\t\t ('\\n', 'Cl', 'ay')\n",
      "ed Wil \t\t\t ('ed', ' W', 'il')\n",
      " Bonn \t\t\t (' B', 'on', 'n')\n",
      " Nora \t\t\t (' N', 'or', 'a')\n",
      "branded \t\t\t ('br', 'and', 'ed')\n",
      "a. As \t\t\t ('a', '.', ' As')\n",
      " been fired \t\t\t (' been', ' f', 'ired')\n",
      "th-old \t\t\t ('th', '-', 'old')\n",
      " or ass \t\t\t (' or', ' ', 'ass')\n",
      " skin rash \t\t\t (' skin', ' r', 'ash')\n",
      " the break \t\t\t (' ', 'the', ' break')\n",
      " outline of \t\t\t (' out', 'line', ' of')\n",
      "venue,  \t\t\t ('venue', ',', ' ')\n",
      " his wife were \t\t\t (' his', ' wife', ' were')\n",
      "com,  \t\t\t ('com', ',', ' ')\n",
      " Railro \t\t\t (' R', 'ail', 'ro')\n",
      ", re- \t\t\t (',', ' re', '-')\n",
      " in commercial \t\t\t (' in', ' commer', 'cial')\n",
      "ured while  \t\t\t ('ured', ' while', ' ')\n",
      " party. But \t\t\t (' party', '.', ' But')\n",
      " would arg \t\t\t (' would', ' ', 'arg')\n",
      "tops, \t\t\t ('t', 'ops', ',')\n",
      "times  \t\t\t ('t', 'imes', ' ')\n",
      " are gl \t\t\t (' ', 'are', ' gl')\n",
      "the Sher \t\t\t ('the', ' S', 'her')\n",
      "ing his political \t\t\t ('ing', ' his', ' political')\n",
      "ade routes \t\t\t ('ade', ' rout', 'es')\n",
      "s campus \t\t\t ('s', ' camp', 'us')\n",
      " asymm \t\t\t (' ', 'asy', 'mm')\n",
      "\n",
      "\n",
      "\n",
      "* \t\t\t ('\\n\\n', '\\n', '*')\n",
      ", clin \t\t\t (',', ' cl', 'in')\n",
      "�s press \t\t\t ('�', 's', ' press')\n",
      "the new H \t\t\t ('the', ' new', ' H')\n",
      "ccompan \t\t\t ('cc', 'omp', 'an')\n",
      "conomic H \t\t\t ('conom', 'ic', ' H')\n",
      "enny W \t\t\t ('enn', 'y', ' W')\n",
      "the network  \t\t\t ('the', ' network', ' ')\n",
      " was predicted \t\t\t (' was', ' predict', 'ed')\n",
      " district of K \t\t\t (' district', ' of', ' K')\n",
      "ah, which \t\t\t ('ah', ',', ' which')\n",
      " and Ind \t\t\t (' ', 'and', ' Ind')\n",
      " past week. \t\t\t (' past', ' week', '.')\n",
      ", nep \t\t\t (',', ' ne', 'p')\n",
      "and distort \t\t\t ('and', ' dist', 'ort')\n",
      " Venerable \t\t\t (' V', 'ener', 'able')\n",
      " in only  \t\t\t (' in', ' only', ' ')\n",
      ". The children \t\t\t ('.', ' The', ' children')\n",
      "a former g \t\t\t ('a', ' former', ' g')\n",
      " mirror \t\t\t (' m', 'ir', 'ror')\n",
      "and conclud \t\t\t ('and', ' con', 'clud')\n",
      " tug \t\t\t (' ', 't', 'ug')\n",
      " Conversation \t\t\t (' Con', 'vers', 'ation')\n",
      " In tr \t\t\t (' In', ' ', 'tr')\n",
      "S\n",
      "\n",
      " \t\t\t ('S', '\\n', '\\n')\n",
      " her career  \t\t\t (' her', ' career', ' ')\n",
      "the harmony \t\t\t ('the', ' harm', 'ony')\n",
      "en, The \t\t\t ('en', ',', ' The')\n",
      "an unlike \t\t\t ('an', ' un', 'like')\n",
      " guard th \t\t\t (' guard', ' ', 'th')\n",
      "racting  \t\t\t ('ract', 'ing', ' ')\n",
      "y)  \t\t\t ('y', ')', ' ')\n",
      " back from  \t\t\t (' back', ' from', ' ')\n",
      "at duty \t\t\t ('at', ' d', 'uty')\n",
      " United States from \t\t\t (' United', ' States', ' from')\n",
      "Morgan \t\t\t ('M', 'or', 'gan')\n",
      " verses  \t\t\t (' vers', 'es', ' ')\n",
      "law, \t\t\t ('l', 'aw', ',')\n",
      " a desc \t\t\t (' ', 'a', ' desc')\n",
      " by JP \t\t\t (' by', ' J', 'P')\n",
      ",\" said K \t\t\t (',\"', ' said', ' K')\n",
      " next year  \t\t\t (' next', ' year', ' ')\n",
      " grand jury \t\t\t (' grand', ' j', 'ury')\n",
      "ured more  \t\t\t ('ured', ' more', ' ')\n",
      "chilles \t\t\t ('ch', 'ill', 'es')\n",
      "us, which \t\t\t ('us', ',', ' which')\n",
      "\n",
      "The drug \t\t\t ('\\n', 'The', ' drug')\n",
      "ache and \t\t\t ('ache', ' ', 'and')\n",
      " last year of \t\t\t (' last', ' year', ' of')\n",
      ". Second \t\t\t ('.', ' Sec', 'ond')\n",
      "ess was  \t\t\t ('ess', ' was', ' ')\n",
      "ountries  \t\t\t ('ount', 'ries', ' ')\n",
      " is under investigation \t\t\t (' is', ' under', ' investigation')\n",
      " innovations \t\t\t (' inn', 'ov', 'ations')\n",
      "essed in \t\t\t ('ess', 'ed', ' in')\n",
      "to Belg \t\t\t ('to', ' Bel', 'g')\n"
     ]
    }
   ],
   "source": [
    "common_trigrams = {t for t in total_trigrams if total_trigrams_per_row[t] > 2}\n",
    "\n",
    "for i, t in enumerate(common_trigrams):\n",
    "    strs = tuple(translate_int_to_str(t, model))\n",
    "    print(\"\".join(strs), \"\\t\\t\\t\", tuple(translate_int_to_str(t, model)))\n",
    "    if i > 100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n"
     ]
    }
   ],
   "source": [
    "common_trigrams_counts = Counter()\n",
    "num_total_trigrams = 0\n",
    "num_included_trigrams = 0\n",
    "\n",
    "def count_to_freq(counter, num_total):\n",
    "    indices = list(counter.keys())\n",
    "    values = list(counter.values())\n",
    "\n",
    "    # Convert to Tensors\n",
    "    indices_tensor = torch.tensor(indices).t()  # Transpose to get 2D tensor for indices\n",
    "    values_tensor = torch.tensor(values) / num_total\n",
    "\n",
    "    # Create sparse tensor\n",
    "    sparse_tensor = torch.sparse_coo_tensor(indices_tensor, values_tensor, size=(5000, 5000, 5000))\n",
    "    return sparse_tensor\n",
    "\n",
    "last_freq = count_to_freq(total_trigrams, num_total_trigrams)\n",
    "\n",
    "def sparse_allclose(sparse_tensor1, sparse_tensor2, atol=1e-8, rtol=1e-5):\n",
    "    # Check if both have the same number of non-zero elements\n",
    "    if sparse_tensor1._nnz() != sparse_tensor2._nnz():\n",
    "        print(f\"Number of non-zero elements not equal ({sparse_tensor1._nnz()}, {sparse_tensor2._nnz()})\")\n",
    "        return False\n",
    "    \n",
    "    # Sort indices and values\n",
    "    sparse_tensor1 = sparse_tensor1.coalesce()\n",
    "    sparse_tensor2 = sparse_tensor2.coalesce()\n",
    "\n",
    "    # Compare indices\n",
    "    if not torch.equal(sparse_tensor1.indices(), sparse_tensor2.indices()):\n",
    "        print(f\"Indices not equal ({len(sparse_tensor1.indices())}, {len(sparse_tensor2.indices())})\")\n",
    "        return False\n",
    "\n",
    "    # Compare values with tolerance\n",
    "    diff = torch.abs(sparse_tensor1.values() - sparse_tensor2.values())\n",
    "    print(\"Diff norm:\", diff.norm())\n",
    "    return torch.all(diff <= atol + rtol * torch.abs(sparse_tensor2.values()))\n",
    "\n",
    "\n",
    "print(\"Loading dataset...\")\n",
    "with open(DATA / 'train-5m.jsonl', 'rb') as f:\n",
    "    for i, row in tqdm.tqdm(enumerate(f.readlines()), total=5_000_000):\n",
    "        tokens = model.tokenizer(json.loads(row)['contents'])['input_ids']\n",
    "        \n",
    "        for j in range(len(tokens)-2):\n",
    "            num_total_trigrams += 1\n",
    "            trigram = tuple(tokens[j:j+3])\n",
    "            \n",
    "            if trigram in common_trigrams:\n",
    "                common_trigrams_counts[trigram] += 1\n",
    "                num_included_trigrams += 1\n",
    "\n",
    "        if i > 0 and i % 10_000 == 0:\n",
    "            freq = count_to_freq(common_trigrams_counts, num_included_trigrams)\n",
    "\n",
    "            if sparse_allclose(last_freq, freq, atol=0, rtol=1e-5):\n",
    "                print(\"Early stopping at row\", i)\n",
    "                break\n",
    "\n",
    "            last_freq = freq\n",
    "\n",
    "print(\"Number of trigrams in dataset:\", num_total_trigrams)\n",
    "print(\"Number of trigrams in dataset that are 'common':\", num_included_trigrams)\n",
    "print(\"Percentage of trigrams in dataset that are 'common':\", num_included_trigrams / num_total_trigrams)\n",
    "\n",
    "# Top 100 trigrams\n",
    "\n",
    "for i, t in enumerate(common_trigrams_counts.most_common(100)):\n",
    "    strs = tuple(translate_int_to_str(t[0], model))\n",
    "    print(\"\".join(strs), \"\\t\\t\\t\", tuple(translate_int_to_str(t[0], model)), \"\\t\\t\\t\", t[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
